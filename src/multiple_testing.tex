\section{Множественная проверка гипотез}

В большинстве ситуаций выше гипотезы проверялись по одной, хотя зачастую на практике встаёт необходимость проверять множество гипотез. Вот лишь некоторые примеры:
\begin{itemize}
    \item Проверка гипотез об изменении метрик при A/B-тестировании, коих обычно несколько десятков или сотен;
    \item Применение к одной и той же выборке критериев согласия с целью нахождения семейства распределений, которому принадлежит истинное;
    \item Вспомогательные проверки, которые нужны для применения более мощных критериев при более ограничительных условиях (например, проверка нормальности, независимости, равенства дисперсий и т.д.);
    \item etc.
\end{itemize}
Каждый критерий имеет некоторый уровень значимости $\alpha$, что означает вероятность $\le \alpha$ ошибки I рода для одной конкретной гипотезы. Однако вероятность хотя бы одного отвержения верной гипотезы куда выше. Данный нюанс иллюстрирует следующий

\begin{example}
    В разделе \ref{ttest} обсуждался способ проверки однородности двух независимых выборок при условии их нормальности с помощью применения двух критериев: сначала проверялось равенство дисперсий посредством F-критерия, и если оно не отвергается, то применяется t-тест для случая равенства дисперсий. Для начала реализуем F-критерий, который, к сожалению, не имеется в scipy:
    \begin{minted}{python}
def f_test(x, y):
    n, m = len(x), len(y)
    statistic = np.var(x, ddof=1) / np.var(y, ddof=1)
    pvalue = 1 - 2 * abs(sps.f(n - 1, m - 1).cdf(statistic) - 0.5)
    return (statistic, pvalue)
    \end{minted}
    Каждый критерий будет проверятся на уровне значимости $\alpha = 0.05$. С помощью симуляции одинаково распределённых выборок оценим ошибку I рода, которая заключается в отвержении хотя одной из проверяемых гипотез.
    \begin{minted}{python}
n_iter = 100000
n, m = 30, 30
x = sps.norm.rvs(size=(n_iter, n))
y = sps.norm.rvs(size=(n_iter, m))
reject_cnt = 0
alpha = 0.05
for i in range(n_iter):
    pvalue1 = f_test(x[i], y[i])[1]
    pvalue2 = sps.ttest_ind(x[i], y[i])[1]
    reject_cnt += max((pvalue1 < alpha), (pvalue2 < alpha))
print(reject_cnt / n_iter)
    \end{minted}
    \begin{lstlisting}
0.10286
    \end{lstlisting}
Ожидаемо, ошибка I рода составила примерно $0.1$, что в два раза больше того, что мы хотели.
\end{example}
В случае проверки сотен или даже тысяч гипотез ситуация становится ещё более плачевной. Цель сей главы --- ознакомиться со способами проверять множество гипотез так, чтобы при любом раскладе (то есть при любом наборе истинных и ложных гипотез) вероятность хотя бы одного отвержения верной гипотезы была не больше установленного числа $\alpha$.

\subsection{Контроль FWER и нисходящие процедуры}

Для начала формально поставим задачу. Пусть имеется $m$ выборок $\mathbf X = \{X_i^{(j)}\}$, где $1 \le j \le m$, $1 \le i \le n_j$, которые, вообще говоря, могут быть зависимыми и даже совпадать. На проверку поставлено $m$ гипотез вида
\[
H_j\colon \mathsf{P}_{j} \in \mathcal{P}_j \vs H_j'\colon \mathsf{P}_{j} \not\in \mathcal{P}_j,
\]
среди которых выделим множество верных гипотез $M_0 = \{j\colon \mathsf{P}_{j} \in \mathcal{P}_j\}$, где $\mathcal{P}_j \subset \mathcal{P}$.

Нам необходимо построить $m$ критериев $S_1, \ldots, S_m$, где, как обычно, $\mathbf X^{(j)} \in S_j$ равносильно отвержению гипотезы $H_j$. Введём следующие обозначения для количества гипотез для различных категорий.

\begin{center}
\begin{tabular}{|c|c|c|c|}
    \hline
     & Верные & Ложные & Всего\\
     \hline
     Принятые & $U$ & $T$ & $m - R$\\
     \hline
     Отвергнутые & $V$ & $S$ & $R$ \\
     \hline
     Всего & $m_0$ & $m - m_0$ & $m$\\
     \hline
\end{tabular}
\end{center}

\begin{definition}
    \textit{Групповой вероятностью ошибки I рода} или FWER (от англ. \textsf{family-wise error rate}) называют величину
    \[
    \fwer = \mathsf{P}(V > 0),\;\;\; \mathsf{P} \in \mathcal{P}.
    \]
    Контроль FWER на уровне $\alpha$ означает, что $\fwer \le \alpha$ для любого $\mathsf{P} \in \mathcal{P}$, а стало быть, для любого набора верных гипотез $M_0$.
\end{definition}

Пусть $\alpha_1, \ldots, \alpha_m$ --- уровни значимости критериев $S_1, \ldots, S_m$ проверки гипотез $H_1, \ldots, H_m$ соответственно. Мы хотим их выбрать таким образом, чтобы $\fwer \le \alpha$.

\textbf{Метод Бонферрони} заключается в топорном уменьшении всех уровней значимости в $m$ раз: $\alpha_1 = \ldots = \alpha_m = \alpha / m$. Такое и вправду сработает:
\begin{gather*}
    \fwer = \pth[](V > 0) = \mathsf{P}\left(\bigcup_{j\in M_0} \{\text{$j$-ая гипотеза отвергается}\}\right) = \mathsf{P}\left(\bigcup_{j\in M_0} \left\{\mathbf X^{(j)} \in S_j\right\}\right) \le \\
    \le \sum_{j \in M_0} \pth[]\left(\mathbf X^{(j)} \in S_j\right) \le m_0 \cdot \frac{\alpha}{m} \le \alpha.
\end{gather*}

\begin{remark}
    Число $m$ в знаменателе можно заменить на любую другую оценку сверху на число верных гипотез $m_0$, если таковая у нас имеется. Например, если мы применяем критерии для проверки несовместных гипотез (то есть не могут быть одновременно верными две и более гипотезы), то уровни значимости можно оставить прежними.
\end{remark}

Данный способ хоть и прост, но чрезмерно наивен и не используется на практике в силу своей немощности: при большом $m$ он очень сильно уменьшает пороги $\alpha_j$, из-за чего отклонение от основной гипотезы должно быть чрезвычайно велико, чтобы быть обнаруженным, что бьёт по мощности.

\textbf{Метод Шидака} чуть более мощен, хотя он и требует независимости выборок $\mathbf X^{(j)}$. Он устанавливает $\alpha_1 = \ldots = \alpha_m = 1 - (1 - \alpha)^{1/m}$. Как можно догадаться, он выражает $\fwer$ через вероятность не объединения, а пересечения:
\[
\fwer = 1 - \pth[](V = 0) = 1 - \pth[]\left(\bigcap_{j \in M_0} \{\text{$j$-ая гипотеза не отвергается}\}\right) = 
\]
\[
= 1 - \pth[]\left(\bigcap_{j \in M_0} \{\mathbf X^{(j)} \not\in S_j\}\right) = 1 - \prod_{j \in M_0} \left(\mathbf X^{(j)} \not\in S_j\right) \le 1 - \left[(1 - \alpha)^{1/m}\right]^m = \alpha.
\]
Впрочем, при больших $m$ он ведёт себя почти так же, как и печально известный метод Бонферрони, поэтому данный способ тоже не шибко полезен.

Другой подход заключается в последовательном рассмотрении p-value критериев $p_1, \ldots, p_m$ в порядке очерёдности:
\[
p_{(1)} \le \ldots \le p_{(m)}.
\]
Для удобства обозначим соответствующие упорядоченным p-value гипотезы $H_{(1)}, \ldots, H_{(m)}$. Определим \textit{нисходящую процедуру} для уровней значимости $\alpha_1, \ldots, \alpha_m$ следующим образом:
\begin{itemize}
    \item Если $p_{(1)} > \alpha_1$, то принимаем все гипотезы $H_{(1)}, \ldots, H_{(m)}$ и останавливаемся, иначе отвергаем $H_{(1)}$ и продолжаем;
    \item Если $p_{(2)} > \alpha_2$, то принимаем все гипотезы $H_{(2)}, \ldots, H_{(m)}$ и останавливаемся, иначе отвергаем $H_{(2)}$ и продолжаем;
    \item И так далее.
\end{itemize}

Проще говоря, мы ищем минимальное такое $j$, при котором $p_{(j)} > \alpha_j$, и отвергаем все те гипотезы, номера которых в вариационном ряду меньше, чем $j$. Похоже, но наоборот, работает \textit{восходящая процедура}:
\begin{itemize}
    \item Если $p_{(m)} \le \alpha_m$, то отвергаем все гипотезы $H_{(1)}, \ldots, H_{(m)}$ и останавливаемся, иначе принимаем $H_{(m)}$ и продолжаем;
    \item Если $p_{(m-1)} \le \alpha_{m-1}$, то отвергаем все гипотезы $H_{(1)}, \ldots, H_{(m-1)}$ и останавливаемся, иначе принимаем $H_{(m-1)}$ и продолжаем;
    \item И так далее 
\end{itemize}

\begin{wrapfigure}{r}{0.6\textwidth}
    \centering
    \includegraphics[width=0.6\textwidth]{pic/step_up_down/step_up_down.pdf}
\end{wrapfigure}

Здесь уже мы ищем максимальное такое $j$, при котором $p_{(j)} \le \alpha_j$, и отвергаем все те гипотезы, номера которых в вариационном ряду не больше $j$. Принцип работы процедур можно изобразить на рисунке:

%\begin{figure}[H]
%    \centering
%    \includegraphics[width=0.8\textwidth]{pic/step_up_down/step_up_down.pdf}
%\end{figure}

Как можно видеть, нисходящая процедура более консервативна и начинает отклонять гипотезы с самых бесперспективных, по одной. Восходящая же не боится отвергнуть сразу охапку гипотез. О примерах восходящих процедур и их роли в множественной проверке гипотез мы поговорим в следующем разделе, а пока остановимся на нисходящих.

\textbf{Метод Холма} подразумевает использование нисходящей процедуры при
\[
\alpha_j = \frac{\alpha}{m - j + 1},
\]
то есть $\alpha_1 = \alpha / m, \alpha_2 = \alpha / (m-1), \ldots, \alpha_m = \alpha$. Данный метод мощнее, чем метод Бонферрони, так как уровни значимости больше, чем просто $\alpha/m$, что позволяет лучше отвергать гипотезы. Более того, при неимении дополнительной информации о наших выборках (например, их независимости) данный метод не улучшаем в плане мощности. Но что же насчёт вероятности ошибки I рода?

\begin{theorem}{}{}
    При заданных $\alpha_j$ метод Холма контролирует FWER на уровне значимости $\alpha$.
\end{theorem}

\begin{proof}
    Пусть во время процедуры какие-то верные гипотезы пришлось отвергнуть. Рассмотрим среди таковых гипотезу с наименьшим номером $j$ в вариационном ряду, то есть все предыдущие $j-1$ гипотезы были ложными. Всего ложных гипотез $m - m_0$ штук, поэтому $j - 1 \le m - m_0$, что даёт оценку $m_0 \le m - j + 1$. Это значит, что уровень значимости, на котором проверялась $j$-ая гипотеза, был равен $\alpha / (m - j + 1) \le \alpha / m_0$. С учётом того, что её отвергли, p-value для её проверки был $\le \alpha / m_0$. Подобное умозаключение позволяет свести доказательство к оцениванию вероятности объединения по всем верным гипотезам:
    \[
    \fwer = \pth[](V > 0) \le \pth[]\left(\bigcup_{l \in M_0} \{p_l \le \alpha / m_0\}\right) \le \sum_{l \in M_0} \pth[](p_l \le \alpha / m_0) \le m_0 \cdot \frac{\alpha}{m_0} = \alpha.
    \]
\end{proof}

Если же известна информация о независимости выборок $\mathbf X^{(j)}$, $1 \le j \le m$, то процедуру можно немного усилить в плане мощности, получив \textbf{метод Шидака-Холма}. Как можно догадаться из названия, он является комбинацией методов Холма и Шидака: для него уровень значимости определяется как
\[
\alpha_j = 1 - (1 - \alpha)^{\frac{1}{m-j+1}}.
\]
Аналогично методу Холма доказывается, что нисходящая процедура с данными уровнями значимости будет контролировать FWER на заданном уровне. Опять же, при больших $m$ отличий от обычного метода Холма мало, однако интерес представляет то, что данный метод наиболее мощный для независимых выборок.

\subsection{Контроль FDR и восходящие процедуры}

Не всегда необходимо так строго контролировать ошибку I рода, как это делают процедуры выше. В них мы боимся сделать хотя бы одно неверное отвержение, что сильно бьёт по способности процедур уметь отвергать гипотезы. Иногда именно такое умение и нужно, например, для множественной проверки важности признаков в линейной регрессии из примера \ref{important_features}, когда страх отвергнуть гипотезу о бесполезности признака может стоить нам выкидыванием действительно нужных. Компромисса можно достичь, контролируя следующую, более слабую величину, нежели FWER:

\begin{definition}
    \textit{Ожидаемой долей ложных отклонений гипотез} или FDR (от англ. \textsf{false discovery rate}) называют величину
    \[
    \fdr = \me[] \frac{V}{\max\{R, 1\}}.
    \]
    Контроль FDR на уровне $\alpha$ означает, что $\fdr \le \alpha$ для любого $\mathsf{P} \in \mathcal{P}$.
\end{definition}

Максимум в знаменателе взят для того, чтобы не делить на нуль в случае принятия всех гипотез. Данная характеристика действительно является более слабой по сравнению с FWER, что показывает следующее
\begin{proposition}
    $\fdr \le \fwer$.
\end{proposition}

\begin{proof}
    \begin{gather*}
        \fdr = \me[] \frac{V}{\max\{R, 1\}} = \me[] \left[ \frac{V}{\max\{R, 1\}} \cdot I(V > 0) \right] \le \me[] I(V > 0) = \pth[](V > 0) = \fwer.
    \end{gather*}
\end{proof}

Таким образом, контролирование FWER на заданном уровне значимости даёт нам контроль и FDR, что, вообще говоря, может не выполняться в обратную сторону, поэтому процедуры, контролирующие FDR, могут совершать больше ошибок I рода. 

Выше нам встречалась так называемая восходящая процедура, которая способна легко отвергать гипотезы. Рассмотрим некоторые её примеры.

\textbf{Метод Бенджамини-Иекутиели} применим в общем случае, когда о зависимостях между выборками неизвестно (в таком случае метод не улучшаем). Он основан на восходящей процедуре с
\[
\alpha_j = \frac{\alpha i}{m} \cdot \left(\sum_{l=1}^m \frac{1}{l}\right)^{-1}.
\]

Для независимых выборок можно применим более мощный \textbf{метод Бенджамини-Хохберга}, для которого уже
\[
\alpha_j = \frac{\alpha i}{m}.
\]

Можно показать, что выполняется следующее утверждение:
\begin{theorem}{}{}
    Два приведённых метода контролируют FDR на уровне $\alpha$.
\end{theorem}
Доказательство этого факта можно найти в \cite{fdr_control}.

\begin{example}
    Смоделируем набор из $m = 1000$ пар выборок $(\mathbf X^{(j)}, \mathbf Y^{(j)})$, которые независимы в совокупности, среди которых первые $m_0 = 600$ будут выбраны из одного распределения $\mathcal{N}(0, 1)$, а остальные $m - m_0$ пар будут содержать неоднородные выборки: $\mathbf X^{(j)}$ будет также взято из $\mathcal{N}(0, 1)$, а вот $\mathbf Y^{(j)}$ уже из $\mathcal{N}(1, 1)$. Мы хотим проверить $m$ гипотез о однородности пар выборок:
    \begin{minted}{python}
m, m_0 = 1000, 600
n = 30
x = sps.norm.rvs(size=(m, n))
y = np.concatenate([
    sps.norm.rvs(size=(m_0, n)),
    sps.norm(loc=1).rvs(size=(m - m_0, n))
])
is_true = np.array([True] * m_0 + [False] * (m - m_0))
pvalues = sps.ttest_ind(x, y, axis=1).pvalue
    \end{minted}
    Для удобства напишем функцию, которая будет применять к p-value выбранный метод и выводить статистику по принятым или отвергнутым гипотезам:
    \begin{minted}{python}
def multiple_ttest_results(pvalues, method, alpha=0.05):
    is_rejected = method(pvalues, alpha)
    U = (~is_rejected & is_true).sum()
    T = (~is_rejected & ~is_true).sum()
    V = (is_rejected & is_true).sum()
    S = (is_rejected & ~is_true).sum()
    f =\
"""         True False
Accepted {0:>4} {1:>5}
Rejected {2:>4} {3:>5}"""
    print(f.format(U, T, V, S))
    \end{minted}
    Сначала посмотрим, какие результаты получаются в случае прямолинейной проверки:
    \begin{minted}{python}
def straightforward(pvalues, alpha=0.05):
    return pvalues < alpha

multiple_ttest_results(pvalues, straightforward)
    \end{minted}
    \begin{lstlisting}
         True False
Accepted  571    18
Rejected   29   382
    \end{lstlisting}
    Ошибок I рода достаточно много, примерно одна двадцатая от всех истинных гипотез. Попробуем исправить ситуацию с помощью поправки Шидака, как-никак выборки у нас независимы:
    \begin{minted}{python}
def sidak(pvalues, alpha=0.05):
    m = len(pvalues)
    return pvalues < 1 - (1 - alpha) ** (1 / m)

multiple_ttest_results(pvalues, sidak)
    \end{minted}
    \begin{lstlisting}
         True False
Accepted  600   271
Rejected    0   129
    \end{lstlisting}
    Число ошибок I рода уменьшилось аж до нуля, так как вероятность увидеть здесь ненулевое значение довольно мала, не говоря уже о прежних конских цифрах. Однако мощность явно просела: мы стали принимать больше половины ложных гипотез, что никуда не годится. Можно улучшить ситуацию с помощью метода Шидака-Холма:
    \begin{minted}{python}
def sidak_holm(pvalues, alpha=0.05):
    m = len(pvalues)
    threshold = m
    sorted_pvalues = np.sort(pvalues)
    for i in range(m):
        if sorted_pvalues[i] > 1 - (1 - alpha) ** (1 / (m - i)):
            threshold = i
            break
    return np.argsort(np.argsort(pvalues)) < threshold

multiple_ttest_results(pvalues, sidak_holm)
    \end{minted}
    \begin{lstlisting}
         True False
Accepted  600   262
Rejected    0   138
    \end{lstlisting}
    Стало не особо лучше, зато всё ещё успешно контролируется FWER. Наконец испробуем метод Бенджамини-Хохберга:
    \begin{minted}{python}
def benjamini_hochberg(pvalues, alpha=0.05):
    m = len(pvalues)
    threshold = m
    sorted_pvalues = np.sort(pvalues)
    for i in range(m - 1, -1, -1):
        if sorted_pvalues[i] <= alpha * (i + 1) / m:
            threshold = i
            break
    return np.argsort(np.argsort(pvalues)) <= threshold

multiple_ttest_results(pvalues, benjamini_hochberg)
    \end{minted}
    \begin{lstlisting}
         True False
Accepted  590    36
Rejected   10   364
    \end{lstlisting}
    Теперь допускаются ошибки I рода (хоть и не в таких количествах, как в топорном способе), но мощность куда лучше, чем в предыдущих двух случаев.
\end{example}



