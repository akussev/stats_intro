\section{Корреляционный анализ}

Часто на практике представляется весьма полезным проверить, зависимы ли какие-то две характеристики. Представим, что для некоторых $n$ объектов есть признак $X$, их можно записать как вектор $(X_1, \ldots, X_n)$, а также признак $Y$, их можно записать как вектор $(Y_1, \ldots, Y_n)$. Таким образом, $(X_i, Y_i)$ является случайным вектором для всех $i$, который описывает пару характеристик для $i$-ого объекта (выборки с таким свойством ещё называют \textit{связанными}). Нас интересует, зависимы ли они, или, что эквивалентно, мы проверяем гипотезу о независимости:
\[
H_0\colon F_{X, Y}(x, y) = F_X(x)F_Y(y).
\]

\subsection{Коэффициенты корреляции}

Как известно, у независимости и корреляции есть некоторая связь (хотя между этими понятиями имеются и различия), поэтому логичным представляется исследовать корреляцию между элементами выборки, так как идейно и вычислительно это проще, чем проверять равенство выше для всех $x, y$. Для этого рассматривают всякие статистики с областью значений $[-1; 1]$, которые ознаменуют собой коррелированность выборок. Их обычно называют \textit{коэффициентами корреляции}. Рассмотрим некоторые из них.

\subsubsection{Коэффициент корреляции Пирсона}

Самое простое, что можно придумать, --- это взять <<выборочную корреляцию>>, то есть воспользоваться методом подстановки для функционала в лице корреляции.

\begin{definition}
    \textit{Коэффициентом корреляции Пирсона} называют следующую статистику:
    \[
    \widehat{\rho} = \frac{\sum_{i=1}^n (X_i - \overline{X})(Y_i - \overline{Y})}{\sqrt{\sum_{i=1}^n (X_i - \overline{X})^2 \sum_{i=1}^n (Y_i - \overline{Y})^2}}.
    \]
\end{definition}

Выбор такого коэффициента корреляции оправдывается тем, что в силу УЗБЧ и теоремы о наследовании сходимости доказывается, что
\[
    \widehat{\rho} \stackrel{\pth[]}{\longrightarrow} \rho(X_1, Y_1) = \frac{\cov(X_1, Y_1)}{\sqrt{\va[]X_1 \va[]Y_1}} = \mathsf{corr}(X_1, Y_1), \;\;\;n\to \infty.
\]
Обычно этот коэффициент используют в случае нормальности выборок: при таком допущении можно построить достаточно мощный критерий проверки некоррелируемости, который даёт следующая
\begin{theorem}[label=rho_disrt_under_norm]{}{}
Если нормально распределённые выборки $X$, $Y$ независимы и $n > 2$, то
    \begin{gather*}
        P(\widehat \rho) := \widehat{\rho}\sqrt{\frac{n-2}{1-\widehat{\rho}^2}} \sim T_{n-2}.
    \end{gather*}
\end{theorem}

Проверка гипотезы проводится следующим образом: если коэффициент $\widehat{\rho}$ близок к границам отрезка $[-1; 1]$, то это является поводом отклонить $H_0$. В условиях теоремы выше критерий уровня значимости $\alpha$ проверки гипотезы можно подставить в виде
\[
R = [-1; 1] \setminus (t_{\alpha/2}; t_{1-\alpha/2}),
\]
где $t_{p}$ --- $p$-квантиль прообраза распределения $T_{n-2}$ при действии отображения $P$.

Для удобства подсчёта можно пользоваться реализацией \href{https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.pearsonr.html}{\texttt{scipy.stats.pearsonr}}.

\subsubsection{Коэффициент корреляции Спирмэна}

Какие минусы у коэффициента выше? Во-первых, конечно, не все рассматриваемые выборки нормальны, хотя такое допущение встречается довольно часто. Самое неприятное -- низкая робастность, то есть неустойчивость статистики к выбросам, что особенно характерно для тех из них, которые основаны на выборочном среднем.

У нас уже встречались статистики, которые таким недостатком обладают в меньшей степени -- это порядковые статистики. В этой связи давайте прибегнем к так называемым \textit{ранговым критериям}, которые основываются на ранге --- номере элементов выборки, расположенных в порядке возрастания.

\begin{definition}
    Пусть $R_i$ и $S_j$ -- место в вариационном ряду для $X_i$ и $Y_j$ соответственно. \textit{Коэффициентом корреляции Спирмэна} называют следующую статистику:
    \[
    \rho_S = \frac{\sum_{i=1}^n (R_i - \overline{R})(S_i - \overline{S})}{\sqrt{\sum_{i=1}^n (R_i - \overline{R})^2 \sum_{i=1}^n (S_i - \overline{S})^2}}.
    \]
\end{definition}

\begin{example}
    Посмотрим, как данный коэффициент борется с выбросами. Рассмотрим выборку $(X_i, Y_i) \sim \mathcal{N}(0, E)$, в которой закрался выброс:
    \begin{figure}[H]
    \centering
    \begin{subfigure}{0.45\textwidth}
    \includegraphics[width=0.9\textwidth]{pic/correlation_outlier/correlation_outlier1.pdf} 
    \caption{Выборка из независимых компонент}
    \end{subfigure}
    \begin{subfigure}{0.45\textwidth}
    \includegraphics[width=0.9\textwidth]{pic/correlation_outlier/correlation_outlier2.pdf}
    \caption{То же самое, но с выбросом}
    \end{subfigure}
    \end{figure}
    
    Для левой выборки значения коэффициентов Пирсона и Спирмэна примерно равны $0.08$ и $0.06$ соответственно, что довольно мало и вполне отражает действительность. С правой выборкой всё несколько хуже: значение коэффициента Пирсона для неё равно $\widehat{\rho} \approx 0.81$, что катастрофически много (T-критерий выше явно отклоняет гипотезу о независимости). Но на коэффициент Спирмэна добавление выброса повлияет незначительно: ранги просто немного сдвинутся, что даст нам значение $\rho_S \approx 0.087$. Таким образом, сей коэффициент можно использовать для распределений, далёких от нормального.
\end{example}

Может возникнуть вопрос, а как вычислять ранги для выборки с повторяющимися элементами? Если считать, что функции распределения $F_X$ и $F_Y$ непрерывны, то всё хорошо, вероятность того, что какие-либо два элемента выборки совпадут, равна нулю, поэтому почти наверное такое упорядочивание однозначно. Если же в выборке встречаются одинаковые значения, то обычно используют средние ранги. Например, если выборка представляет собой набор $2, 5, 5, 7$, то их средние ранги равны соответственно $1, 2.5, 2.5, 4$. Такой подход сохраняет сумму всех рангов, а вот с суммой квадратов будут проблемы, поэтому некоторые вещи ниже для такой модели неприменимы. Чтобы с этим всем не возиться, для простоты будем всё-таки подразумевать, что функции распределения непрерывны.

Оформим все свойства в одном утверждении.

\begin{theorem}{}{}
Имеют место быть следующие свойства:
\begin{enumerate}
    \item Коэффициент корреляции Спирмэна можно переписать в виде
    \[
    \rho_S = 1 - \frac{6}{n^3-n} \sum_{i=1}^n (R_i - S_i)^2.
    \]
    \item При верности $H_0$ имеем $\me[]\rho_S = 0$, $\va[] \rho_S = \frac{1}{n-1}$, а также есть сходимость:
    \[
    \frac{\rho_S}{\sqrt{\va[] \rho_S}} \stackrel{d}{\longrightarrow} \mathcal{N}(0, 1).
    \]
    \item Коэффициент корреляции и в самом деле отражает корреляцию между элементами выборки, то есть $-1 \le \rho_S \le 1$, причём крайние значения достигаются.
\end{enumerate}
\end{theorem}
\begin{proof}
Первое утверждение проверяется непосредственно. Третье является следствием неравенства КБШ. Осталось найти матожидание и дисперсию сего коэффициента.

Во-первых, сделаем витающее в воздухе замечание: $R_1, \ldots, R_n$ есть ничто иное, как перестановка чисел $1, \ldots, n$, поэтому если мы встретим какое-либо симметричное выражение, зависящее от $R_i$, то мы всегда в нём сможем сделать замену. Так, например, $\sum R_i = \frac{n(n+1)}{2}$, а $\sum R^2_i = \frac{n(n+1)(2n+1)}{6}$. Во-вторых, при верности гипотезы $H_0$ величины $R_i$ и $S_j$ независимы при любых $i$, $j$, поэтому матожидание от их произведения раскладывается в произведение матожиданий. В свою очередь так как компоненты выборки независимы, то ранги могут образовывать любую перестановку равновероятно, откуда несложно посчитать $\me[]R_i = \me[]S_j = \frac{n+1}{2}$. С этими новыми знаниями посчитаем матожидание $\rho_S$:
\begin{gather*}
    \me[] \rho_S = \me[] \left(1 - \frac{6}{n^3-n}  \sum_{i=1}^n (R_i - S_i)^2\right) = \me[] \left(1 - \frac{6}{n^3-n}  \sum_{i=1}^n (R_i^2 - 2 R_i S_i + S_i^2)\right) = \\
    1 - \frac{6}{n^3-n} \cdot 2 \cdot \frac{n(n+1)(2n+1)}{6} + \frac{12}{n^3-n} \cdot n\me[]R_1 S_1 = 1 - \frac{4n+2}{n-1} + \frac{12}{n^2-1} \cdot \left(\frac{n+1}{2}\right)^2 = \\
    = \frac{-3n-3}{n-1} + 3 \cdot\frac{n+1}{n-1} = 0.
\end{gather*}

Отлично, теперь посмотрим на дисперсию. Так как прибавление константы на дисперсию не влияет, то оставим в формуле коэффициента только сумму произведений $R_iS_i$. Также нелишним будет посчитать матожидание квадрата ранга:
\[
\me[]R_1^2 = \sum_{i=1}^n i^2\cdot \pth[](R_1 = i) = \frac{1}{n} \sum_{i=1}^n i^2 = \frac{(n+1)(2n+1)}{6},
\]
и матожидание произведения двух разных рангов $R_i$ и $R_j$: различных способов выбрать значения для них теперь равно $n(n-1)$, и они также равновероятны. Поэтому
\begin{gather*}
    \me[]R_iR_j = \sum_{i\ne j} \frac{1}{n(n-1)} \cdot ij = \sum_{i, j=1}^n \frac{1}{n(n-1)} \cdot ij - \sum_{i=1}^n \frac{1}{n(n-1)} \cdot i^2 = \\
    =\frac{1}{n(n-1)}\cdot \frac{n^2(n+1)^2}{4} -  \frac{1}{n(n-1)} \cdot \frac{n(n+1)(2n+1)}{6} = \frac{(n+1)(3n+2)}{12}.
\end{gather*}
Теперь можем начинать жёстко считать дисперсию:
\begin{gather*}
    \va[] \rho_S = \frac{144}{(n^3-n)^2} \va[] \sum R_i S_i = \frac{144}{(n^3-n)^2} \left[\me[]\left(\sum R_i S_i\right)^2 - \left(\me[] \sum R_i S_i\right)^2 \right] = \\
    = \frac{144}{(n^3-n)^2} \left[\sum \me[]R_i^2 S_i^2 + \sum_{i\ne j}\me[]R_iS_iR_jS_j - \left(n\cdot\me[] R_1 S_1\right)^2 \right] = \\
    = \frac{144}{(n^3-n)^2} \left[n\cdot\me[]R_1^2 \cdot\me[]S_1^2 + n(n-1)\me[]R_1R_2\cdot \me[]S_1S_2 - \left(n\cdot\me[] R_1 \cdot \me[]S_1\right)^2 \right] =\\
    = \frac{144}{n(n^2-1)^2} \left[\frac{(n+1)^2(2n+1)^2}{36} + (n-1)\cdot \frac{(n+1)^2(3n+2)^2}{144} - n\cdot\frac{(n+1)^4}{16}\right] = \\
    = \frac{1}{n(n-1)^2}\left(4(2n+1)^2+(n-1)(3n+2)^2-9n(n+1)^2\right) = \frac{1}{n-1}.
\end{gather*}
\end{proof}



\subsubsection{Коэффициент корреляции Кендалла}

Схожую по идеологии ранжирования статистику ввёл М. Дж. Кендэлл. Только теперь мы смотрим на количество инверсий, которые образуются во второй выборке, если расположить их в порядке возрастания соответствующих элементов первой. То есть появляется некоторая мера неупорядоченности второй выборки относительно первой, и если выборки независимы, то логично предположить, что инверсий будет примерно столько же, сколько и правильно упорядоченных пар. Более формально:

\begin{definition}
    Будем говорить, что пары $(X_i, Y_i)$ и $(X_j, Y_j)$ \textit{согласованны} (считаем, что $1 \le i < j \le n$), если $X_i < X_j$ и $Y_i < Y_j$ или $X_i > X_j$ и $Y_i > Y_j$ (то есть $sign(X_j - X_i)(Y_j - Y_i) = 1$).
\end{definition}

Пусть для выборок $X$ и $Y$ величина $S$ есть число согласованных пар, а $R$ -- число несогласованных (по всем $1 \le i < j \le n$). При верности гипотезы они должны не слишком сильно отличаться, поэтому логично ввести следующую меру превышения согласованности над несогласованностью:

\[
T = S - R = \sum_{i<j} sign(X_j - X_i)(Y_j - Y_i).
\]

Понятное дело, что величина $T$ может меняться от $-\frac{n(n-1)}{2}$ до $\frac{n(n-1)}{2}$ (второй вариант характерен для выборок с полным согласием порядка, а первый -- наоборот, когда увеличение $X$ означает уменьшение $Y$). Поэтому логично нормировать полученную статистику, чтобы она лежала на отрезке $[-1; 1]$, как и все коэффициенты корреляции.

\begin{definition}
    \textit{Коэффициентом корреляции Кендалла} называют следующую статистику:
    \[
    \tau = \frac{2}{n(n-1)}\cdot T = \frac{2}{n(n-1)} \sum_{i < j} sign(X_i - X_j)\cdot sign(Y_i - Y_j)
    \]
\end{definition}

С учётом того, что $S+R=\frac{n(n-1)}{2}$, коэффициент корреляции можно переписать как
\[
\tau = 1 - \frac{4}{n(n-1)}R.
\]

Как и ранее, у неё можно найти среднее и дисперсию, по которым можно составить предельный закон. Мы приведём лишь численные значения, прийти к которым предлагается читателю в качестве упражнения.
\begin{theorem}{}{}
    При верности $H_0$ выполнено $\me[]\tau = 0$, $\va[] \tau = \frac{2(2n+5)}{9n(n-1)}$, и есть сходимость
    \[
    \frac{\tau}{\sqrt{\va[] \tau}} \stackrel{d}{\longrightarrow} \mathcal{N}(0, 1).
    \]
\end{theorem}

\subsection{Критерий $\chi^2$ и таблицы сопряжённости}

Одним из недостатков коэффициентов корреляции выше является их немощность при симметричности данных. На картинках ниже имеется явная зависимость между двумя признаками, однако коэффициенты на это никак не реагирует и выдают околонулевые значения.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\textwidth]{pic/symmetry/symmetry.pdf}
\end{figure}

Данную проблему можно решить и визуальным анализом, однако мы обсудим другой, более формальный способ, который является ещё одним аналогом критерия хи-квадрат. Вообще говоря, он предназначен для категориальных признаков, но по аналогии с обычным критерием хи-квадрат его можно применять и в общем случае.

Пусть признак $X$ принимает $m$ значений $x_1, \ldots, x_m$, а признак $Y$ --- $k$ значений $y_1, \ldots, y_k$. Имеется выборка $(X_i, Y_i)$ из $n$ наблюдений, для которой обозначим за $\nu_{ij}$ количество пар таких, что в них признак $X$ равен $x_i$, а $Y$ равен $y_j$, то есть
\[
\nu_{ij} = \sum_{l=1}^n I(X_l = x_i, Y_l = y_j).
\]

Полученные значения обычно записывают в таблицу, которую называют \textit{таблицей сопряжённости}. Введём обозначения $p_{ij} = \pth[](X_1 = x_i, Y_1 = y_j)$, $p_{i\bullet} = \pth[](X_1 = x_i) = \sum_{j} p_{ij}$ и аналогично $p_{\bullet j} = \pth[](Y_1 = y_j) = \sum_{i} p_{ij}$. Нулевая гипотеза о независимости $X$ и $Y$ равносильна равенствам
\[
p_{ij} = p_{i\bullet} p_{\bullet j}, \;\;\;i = 1, \ldots, m, \;\;\; j = 1, \ldots, k,  
\]
то есть имеет место принадлежность некоторой подповерхности $\Theta_0$ в исходном пространстве параметров $\Theta$. Легко посчитать её размерность --- $m+k-2$. Действительно, параметры $p_{1\bullet},\ldots p_{(m-1)\bullet}$, $p_{\bullet 1},\ldots p_{\bullet(k-1)}$ берутся произвольными (в рамках разумного), числа $p_{m \bullet} = 1 - p_{1\bullet} - \ldots - p_{(m-1)\bullet}$ и $p_{\bullet k} = 1 - p_{\bullet 1} - \ldots - p_{\bullet(k-1)}$ определяются по ним однозначно, откуда из формул выше получаем все $p_{ij}$.

Гипотезу такого вида можно проверить с помощью параметрического критерия $\chi^2$ из раздела \ref{complext_chi2_test}, для чего нужно найти ОМП при верности нулевой гипотезы. Функция правдоподобия будет равна
\[
f_{\mathbf p}(\mathbf x, \mathbf y) = \prod_{i=1}^m \prod_{j=1}^k p_{ij}^{\nu_{ij}} = \prod_{i=1}^m \prod_{j=1}^k (p_{i\bullet}p_{\bullet j})^{\nu_{ij}} = \prod_{i=1}^m p_{i\bullet}^{\nu_{i\bullet}} \cdot \prod_{j=1}^k p_{\bullet j}^{\nu_{\bullet j}},
\]
где $\nu_{i\bullet} = \sum_{j} \nu_{ij}$, $\nu_{\bullet j} = \sum_{i} \nu_{ij}$. Максимизируя каждый множитель по отдельности, получаем оценки $\widehat p_{i\bullet} = \nu_{i\bullet} / n$, $\widehat p_{\bullet j} = \nu_{\bullet j} / n$. Таким образом, по теореме \ref{complex_chi2_theorem} при независимости признаков имеется сходимость
\begin{equation}\label{chi2_contingency_stat}
	\chi^2(\mathbf X, \mathbf Y) = \sum_{i=1}^m \sum_{j=1}^k \frac{(\nu_{ij} - n\widehat p_{i\bullet} \widehat p_{\bullet j})^2}{n\widehat p_{i\bullet} \widehat p_{\bullet j}} = n \sum_{i=1}^m \sum_{j=1}^k \frac{(\nu_{ij} - \nu_{i\bullet} \nu_{\bullet j} / n)^2}{\nu_{i\bullet} \nu_{\bullet j}} \stackrel{d}{\longrightarrow} \chi^2_{(m-1)(k-1)},
\end{equation}
где $(m-1)(k-1) = mk - 1 - (m + k - 2)$ --- коразмерность $\Theta_0$ в $\Theta$.

\begin{example}
	В 1892 году в работе Фрэнсиса Гальтона \href{https://galton.org/books/finger-prints/index.htm}{<<Finger Prints>>} изучалась наследственность типов отпечатков пальца: в виде дуг, петлей и завитков. Для этого бралась выборка из 105 пар братьев и сестёр и сравнивался тип отпечатков пальцев в каждой паре~--- получился набор из 9 чисел, записанных в таблицу сопряжённости: по горизонтали берётся тип отпечатков у первого ребёнка из пары, по вертикали --- второго.
	\begin{center}
		\begin{tabular}{|c|c|c|c|}
		\hline
			 & Дуги & Петли & Завитки \\
			\hline
			Дуги & 5 & 12 & 2 \\
			\hline
			Петли & 4 & 42 & 15 \\
			\hline
			Завитки & 1 & 14 & 10 \\
			\hline
		\end{tabular}
	\end{center}
	
	Если предположить, что наследственность роли не играет, то зависимости быть не должно. Проверим эту гипотезу на уровне значимости 0.05 с помощью критерия $\chi^2$. Статистику \eqref{chi2_contingency_stat} можно посчитать и напрямую, но удобнее занести данные в Python и воспользоваться функцией \href{https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.chi2\_contingency.html}{\texttt{scipy.stats.chi2\_contingency}}. 
	\begin{minted}{python}
fraternal_obs = [
    [5, 12, 2],
    [4, 42, 15],
    [1, 14, 10]
]
sps.chi2_contingency(fraternal_obs).pvalue
	\end{minted}
	\begin{lstlisting}
0.024719148645087168
	\end{lstlisting}
	
	Таким образом, гипотеза о независимости данных признаков у братьев и сестёр отклоняется на взятом уровне значимости.
\end{example}

\subsection*{Задачи}

\begin{problem}
	Докажите теорему \ref{rho_disrt_under_norm}.
	
	\textit{Указание.} Найдите условное распределение $\widehat{\rho}$ при фиксированной выборке $\mathbf{X}$ и убедитесь, что оно одинаково при любом условии. В частности, отсюда будет следовать, что утверждение теоремы справедливо даже в случае ненормальности одной из выборок.
\end{problem}

