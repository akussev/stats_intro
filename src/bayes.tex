\section{Байесовский подход}\label{bayes_method}

\subsection{Мотивация}



Здесь мы собираемся не просто изучить новый подход в статистике, а постичь целую философию, новую парадигму мышления, противопоставляемая тому пониманию статистики, которому нас учили ранее.

Обычный статистический вывод построен на \textit{частотном} (или \textit{фреквентистском}) \textit{подходе} (от англ. \textsf{frequentism}). Ранее мы всегда предполагали, что модель (или параметры, которые её описывают) в реальности определена и фиксирована --- просто мы её не знаем. Единственный способ уменьшить неопределённость --- потреблять всё больше и больше наблюдений, которые в силу различных предельных законов должны с ростом выборки более точно описывать модель. Нам это позволяет сделать \textit{принцип статистической устойчивости частот}: с самых азов мы связывали вероятность с долей экспериментов, в которых событие осуществилось, отчего важную роль играет повторяемость эксперимента. В то же время неизвестные параметры детерминированные, а значит, к ним нельзя применить вероятностные суждения. Мы не могли ранее сказать что-то типа <<гипотеза верна с вероятностью 0.73>> или <<параметр больше 0 с вероятностью 0.42>>, так как всё это фиксированные константы.

В \textit{байесовском подходе} вероятность интерпретируется как субъективная оценка, степень уверенности которой может быть основана на нашем опыте или вере, она не обязана подкрепляться частотностью наблюдаемого события. Посему любая величина интерпретируется как случайная, что позволяет нам использовать статистический аппарат для извлечения выводов о неизвестных нам характеристиках. Наши предположения о неизвестном параметре мы заключаем в некотором распределении $\mathsf{Q}$ на множестве $\Theta$ (чаще всего под $\Theta$ будет подразумеваться множество из $\R^n$, поэтому эта мера определяется на борелевских подмножествах из $\mathcal{B}(\Theta)$).

Более формально, теперь мы работаем в новом вероятностном пространстве $$(\Theta\times\mathcal{X}, \mathcal{B}(\Theta) \otimes\mathcal{B}(\mathcal{X}), \widetilde{\pth[]}),$$ где $\mathcal{B}(\Theta) \otimes\mathcal{B}(\mathcal{X})$ -- прямое произведение $\sigma$-алгебр, а мера $\widetilde{\pth[]}$ задаётся обобщённой плотностью $\rho_{\theta, X}(t, \mathbf{x}) = q(t)\cdot \rho(\mathbf{x} | t)$. Обобщённая плотность $\rho(\mathbf{x} | t)$, как и ранее, отвечает за распределение выборки при фиксированном значении параметра, а новый персонаж, $q(t)$,~--- за распределение на множестве параметров.

\begin{definition}
    Плотность $q(t)$, $t \in \Theta$, называется \textit{априорной}.
\end{definition}

\textit{Априори} означает то, что эта плотность известна нам \textit{до} момента проведения наблюдения, то есть она является чем-то типа прикидки того, каким может быть параметр.

При этом когда наблюдение уже проведено, ясно, что наше мнение о параметре изменилось --- выборка подсказывает нам, в какую сторону нужно идти, чтобы оценить параметр. 

\begin{definition}
    Условное распределение параметра $\theta$ при условии выборки $X_1, \ldots, X_n$, чья плотность (напоминаем) может быть высчитана по формуле
    \[
    \rho(t | \mathbf{x}) = \frac{\rho_{\theta, X}(t, \mathbf{x})}{\rho(\mathbf{x})} = \frac{q(t) \rho(\mathbf{x} | t)}{\int_{\Theta} q(s) \rho(\mathbf{x}|s) \,d\mu(s)},
    \]
    называется \textit{апостериорной плотностью} параметра $\theta$.
\end{definition}

В этом ещё одно преимущество байесовского подхода: вместо обычной точечной оценки или доверительного интервала мы получаем целое распределение, из которого можно смастерить точечную оценку любыми удобными способами. Например, можно взять среднее значение по плотности, что есть попросту
$$\me[](\theta | \mathbf X) = \int_{\Theta} t\cdot \rho(t|\mathbf X)\,dt.$$
Обратите внимание, что так как УМО по определению является измеримым относительно $\mathbf X$, то $\me[](\theta | \mathbf X) = \phi(\mathbf X)$ для некоторой борелевской $\phi$, то есть она зависит только от элементов выборки.

\begin{definition}
    Оценка $\widehat{\theta} = \me[](\theta | \mathbf X)$ называется \textit{байесовской оценкой параметра $\theta$}.
\end{definition}

Польза полученной оценки проявляется в свете следующего подхода в сравнении оценок.

\begin{definition}
    Говорят, что оценка $\theta^*$ \textit{лучше оценки} $\widehat{\theta}$ \textit{в байесовском подходе с функцией потерь $g$}, если
    \[
    \int_{\Theta} \me[t] g(\theta^*, t) \,d\mathsf{Q}(t) < \int_{\Theta} \me[t] g(\widehat \theta, t)\, d\mathsf{Q}(t),
    \]
    где $\mathsf{Q}$ --- априорное распределение на множестве параметров $\Theta$.
\end{definition}

\begin{theorem}[label=bayes_is_the_best]{}{}
    Байесовская оценка является наилучшей в байесовском подходе с квадратичной функции потерь.
\end{theorem}

Другой, более простой вариант --- взять моду полученного распределения, то есть самое правдоподобное значение параметра (такую оценку иногда называют <<Байесом для бедных>>). Удобство такого метода заключается в ненадобности считать интеграл в знаменателе апостериорной плотности: он не зависит от параметра, поэтому максимизация $\rho(t | \mathbf{x})$ по $\theta$ равносильна максимизации $q(t) \rho(\mathbf{x} | t)$, что даёт оценку
\[
\theta^*(\mathbf X) = \argmax_{t \in \Theta} q(t) \rho(\mathbf{X} | t) = \argmax_{t \in \Theta} \ln{\left[q(t) \rho(\mathbf{X} | t)\right]} = \argmax_{t \in \Theta} \left[\ln{\rho(\mathbf{X} | t)} + \ln{q(t)}\right].
\]

Заметим, что полученная оценка очень напоминает ОМП, только на этот раз под знак $\argmax$ добавлен \textit{регуляризатор} $\ln{q(t)}$, которой накладывает дополнительные ограничения на параметр. Подобные регуляризационные свойства позволяют использовать байесовский подход при любых размерах выборки, в отличие от прежних методов, результаты которых актуальны лишь для достаточно большого набора данных.

\begin{example}\label{ridge_and_lasso}
Применим байесовский подход к модели гауссовской линейной регрессии $\mathbf X = Z\boldtheta + \epsilon$, где $\epsilon \sim \mathcal{N}(0, \sigma^2E)$ (см. главу \ref{regression}). Возьмём в качестве априорного распределения на вектор параметров $\boldtheta$ гауссовский вектор с независимыми компонентами $\mathcal{N}(0, \gamma^2 E_k)$. В нём формализовано наше желание быть вектору $\boldtheta$ не очень большим по норме: вероятностная масса у нормального распределения сконцентрирована как раз у начала координат, а насколько сильно~--- определяется параметром $\gamma^2$.

Более подробно, априорное распределение задаётся плотностью
\[
q(\mathbf t) \sim \exp\left(-\frac{1}{2\gamma^2}\|\mathbf t\|^2\right) = \exp\left(-\frac{1}{2\gamma^2}\mathbf t^T \mathbf t\right).
\]
Значит, апостериорному распределению соответствует
\[
\rho(\mathbf t|\mathbf{x}) \sim 
\exp\left(-\frac{1}{2\gamma^2}\mathbf t^T \mathbf t - \frac{1}{2\sigma^2} (\mathbf{x} - Z\mathbf t)^T (\mathbf{x} - Z\mathbf t)\right).
\]
Если мы попытаемся максимизировать эту плотность (то есть найти байесовскую оценку <<для бедных>>), то получим следующую задачу оптимизации:
\[
\|\mathbf X - Z \mathbf t\|^2 + \frac{\sigma^2}{\gamma^2} \| \mathbf t\|^2 \to \min_{\mathbf t}.
\]
Такой способ называется \textsf{Ridge regression}. Его преимущество в том, что мы <<штрафуем>> вектор $\boldtheta$ за излишне большие координаты, что позволяет получать более стабильные решения с меньшей дисперсией. Особенно отчётливо это станет видно, когда мы найдём соответствующую байесовскую оценку. Это можно сделать напрямую, решив задачу выше, но мы поступим более интеллектуально, найдя параметры $a$ и $\Sigma$ многомерного нормального распределения, отвечающего $\rho(\mathbf t|\mathbf{x})$. С одной стороны,
\[
\rho(\mathbf t|\mathbf{x}) \sim \exp\left[ \frac{1}{\sigma^2} \mathbf{x}^T Z\mathbf t - \frac{1}{2} \mathbf t^T \left( \frac{1}{\gamma^2} E + \frac{1}{\sigma^2} Z^T Z\right) \mathbf t\right].
\]
С другой, 
\[
\rho(\mathbf t|\mathbf{x}) \sim \exp\left(-\frac{1}{2} (\mathbf t-a)^T\Sigma^{-1}(\mathbf t-a)\right) \sim 
    \exp\left(a^T \Sigma^{-1} \mathbf t - \frac{1}{2} \mathbf t^T\Sigma^{-1} \mathbf t  \right).
\]
Получается, что
\[
\left\{
    \begin{aligned}
    \Sigma^{-1} &= \frac{1}{\gamma^2} E + \frac{1}{\sigma^2} Z^T Z,\\
    a^T \Sigma^{-1} &= \frac{1}{\sigma^2} \mathbf{x}^T Z.
    \end{aligned}
    \right.
\]
Транспонируя второе равенство (благо $\Sigma$ симметрична, и на неё это не повлияет) и подставляя туда первое, получаем оценку:
\[
\me[](\boldtheta|\mathbf X) = a(\mathbf X) = \left(Z^T Z + \frac{\sigma^2}{\gamma^2} E\right)^{-1} Z^T \mathbf X.
\]
Получили практически решение задачи обычной линейной регрессии, но теперь к матрице $Z^T Z$ добавляется единичная с некоторой константой. Это и позволяет получать более адекватную оценку в случае, если эта матрица близка к вырожденной. Это происходит из-за того, что добавление такой матрицы сдвигает все собственные числа $Z^T Z$ на $\frac{\sigma^2}{\gamma^2}$ вправо, отчего определитель, как произведение собственных чисел, отдаляется от нуля. 

Теперь возьмём следующее априорное распределение: компоненты вектора $\boldtheta$ независимы, $\theta_i \sim \laplaced(\lambda)$. У данного распределения более тяжёлые хвосты, поэтому такая модель лучше объясняет данные с выбросами. Имеем априорную плотность
\[
q(\mathbf t) \sim \exp\left(-\lambda\sum_{i=1}^k |t_i|\right) = \exp\left(-\lambda \|\mathbf t\|_1\right).
\]
Следовательно, апостериорная плотность имеет вид
\[
\rho(\mathbf t|\mathbf{x}) \sim 
\exp\left(-\lambda \|\mathbf t\|_1 - \frac{1}{2\sigma^2} (\mathbf{x} - Z\mathbf t)^T (\mathbf{x} - Z\mathbf t)\right).
\]
Аналитически получить формулу для байесовской оценки проблематично, зато можно приблизить моду данного распределения с помощью градиентного спуска. Соответствующую задачу оптимизации можно сформулировать так:
\[
\|\mathbf X - Z \mathbf t\|^2 + \frac{\sigma^2}{\lambda} \| \mathbf t\|_1 \to \min_{\mathbf t}
\]
Здесь имеется похожая регуляризация, что и в случае выше, но теперь мы пытаемся ограничить вектор параметров по $\|\cdot\|_1$-норме (так называемая \textsf{Lasso regression}). Такой подход помимо всего прочего обладает свойством <<отбора признаков>> (подробнее смотрите в курсе <<Машинного обучения>>).
\end{example}

\subsection{Выбор априорного распределения}

Звучит просто прекрасно. Но остаётся важный вопрос: а откуда нам брать это априорное распределение параметра? Как было сказано ранее, можно воспользоваться результатами прошлых наблюдений, но так можно сделать не всегда. Хочется иметь некоторый теоретический арсенал, позволяющий даже <<вслепую>> выбирать не очень уж плохие априорные распределения. Вот лишь некоторые способы.

\subsubsection{Сопряжённые семейства}

Было бы неплохо при переходе от априорного распределения к апостериорному получать не какую-то жесть, а что-то похожее на предыдущее распределение, хоть и с другими параметрами, что, к слову, поможет с дальнейшими вычислениями. Поэтому можно по распределению, которому подчиняется выборка, подобрать априорное распределение так, чтобы оно вместе с апостериорным лежали в одном семействе распределений.
\begin{definition}
    В таком случае семейство распределений, которому принадлежит $\mathsf{Q}$, называют \textit{сопряжённым семейству} $\{\pth\colon \theta \in \Theta\}$.
\end{definition}

Для примера рассмотрим выборку $X_1, \ldots, X_n$ из распределения $\bernd(\theta)$. Её совместная плотность равна
\[
\rho(\mathbf{x} | t) = t^{\sum x_i} (1 - t)^{n - \sum x_i}.
\]
Чтобы получить апостериорную плотность, надо домножить $\rho(\mathbf{x} | t)$ на априорную плотность и потом нормировать это произведение, деля на некоторый интеграл. Таким образом, $\rho(t | \mathbf{x})$ пропорциональна $q(t) \rho(\mathbf{x} | t)$, а стало быть, надо подобрать семейство для $q(t)$ таким образом, чтобы домножение на $\rho(\mathbf{x} | t)$ не выкидывало нас за границы этого семейства. Внимательно смотря на табличку известных распределений и находя там что-то со степенями $t$ и $(1 - t)$, можно прийти к выводу, что следует взять в качестве априорного распределения $\betad(\alpha, \beta)$, то есть положить
\[
q(t) = \frac{1}{B(\alpha, \beta)}t^{\alpha-1}(1-t)^{\beta-1} I(0 \le t \le 1).
\]
В таком случае
\[
\rho(t | \mathbf{x}) \sim t^{\alpha + \sum x_i - 1} (1-t)^{\beta + n - \sum x_i - 1} I(0 \le t \le 1),
\]
поэтому эта плотность отвечает бета-распределению с параметрами $\alpha + \sum x_i$ и $\beta + n - \sum x_i$.

Заметьте, что нам не надо находить коэффициент пропорциональности, то есть тот самый интеграл в знаменателе апостериорной плотности, так как при фиксированной выборке это просто какая-то константа, служащая для нормировки (чтобы интеграл от плотности был равен единице), и тем самым определяющаяся однозначно. А мы уже знаем одно распределение, плотность которого с точностью до константы равна правой части -- это и есть бета-распределение, а значит, именно ему равно апостериорное распределение. Ниже мы часто будем писать апостериорную плотность через значок $\sim$, забивая на все множители, которые не зависят от $t$.

Вспоминаем матожидание бета-распределения и находим байесовскую оценку
\[
\widehat{\theta} = \me[] (\theta | \mathbf X) = \int_{\Theta} t \rho(t | \mathbf X)\,d\mu(t) = \frac{\alpha + \sum X_i}{\left(\alpha + \sum X_i\right) + \left(\beta + n - \sum X_i\right)} = \frac{\alpha + \sum X_i}{\alpha + \beta + n}.
\]

\begin{example}\label{conjugate}
    Найдём сопряжённые семейства для ещё некоторых известных семейств распределений.
    \begin{itemize}
        \item Пусть $X_1, \ldots, X_n$ --- выборка из распределения $\ud(0, \theta)$. Имеем совместную плотность $\rho(\mathbf{x} | t) = t^{-n} I(0 < x_1, \ldots, x_n < t)$. Какое распределение имеет плотность от $t$, которая содержит степени $t$ и индикатор с оценкой $t$ снизу? Конечно же распределение Парето! Положим
\[
q(t) = \frac{ka^k}{t^{k+1}}I(t > a).
\]
В таком случае
\[
\rho_{\theta|\mathbf X}(t|\mathbf{x}) \sim \frac{1}{t^n}\cdot \frac{ka^k}{t^{k+1}} I(0 < x_1, \ldots, x_n, a < t) \sim \frac{1}{t^{n+k+1}} I(t > \max\{x_{(n)}, a\}).
\]
Следовательно, апостериорным распределением является $\paretod(n+k, \max\{x_{(n)}, a\})$. Тогда искомая байесовская оценка равна
\[
\me[](\theta|\mathbf X) = \int_{\max\{X_{(n)}, a\}}^{+\infty} \frac{(n+k)\cdot\max\{X_{(n)}, a\}^{n+k}}{t^{n+k}}\,dt = \frac{(n+k)\max\{X_{(n)}, a\}}{n+k-1}.
\]
При $\theta < a$ имеем плачевную ситуацию: элементы выборки не могут быть больше $a$, а значит, оценка не будет вообще зависеть от выборки.

\item Пусть $X_1, \ldots, X_n$ --- выборка из распределения $\poisd(\theta)$. Имеем совместную плотность
$$\rho(\mathbf{x} | t) = \frac{t^{\sum x_i}e^{-tn}}{\prod x_i!}.
$$
Какое распределение имеет плотность от $t$, которая содержит степени $t$ и экспоненту от $-t$? Конечно же гамма-распределение! Положим
\[
q(t) = \frac{\lambda^{\alpha} t^{\alpha - 1}}{\Gamma(\alpha)} e^{-\lambda t} I(t>0).
\]
В таком случае
\[
\rho_{\theta|\mathbf X}(t|\mathbf{x}) \sim t^{\alpha - 1 + \sum x_i} e^{-t(\lambda+n)}I(t > 0).
\]
Следовательно, апостериорным распределением является $\Gamma\left(\alpha + \sum x_i, \lambda + n\right)$. Тогда искомая байесовская оценка равна
\[
\me[](\theta|\mathbf X) = \frac{\alpha + \sum X_i}{\lambda + n}.
\]

\item Пусть $X_1, \ldots, X_n$ --- выборка из распределения $\mathcal{N}(\theta, 1)$. Имеем совместную плотность
$$\rho(\mathbf{x} | t) = \frac{1}{(2\pi)^{n/2}} \exp{\left(-\frac{1}{2} \sum (x_i - t)^2\right)} = \frac{1}{(2\pi)^{n/2}} \exp{\left(-\frac{1}{2} \sum x_i^2 + t\sum x_i - \frac{nt^2}{2}\right)}.$$
Какое распределение имеет плотность от $t$, которая содержит экспоненту с $t$ и $t^2$? Конечно же нормальное распределение! Положим
\[
q(t) = \frac{1}{\sqrt{2\pi\sigma^2}} \exp{\left(-\frac{1}{2\sigma^2} (t - a)^2\right)} = \frac{1}{\sqrt{2\pi\sigma^2}} \exp{\left(-\frac{1}{2\sigma^2} t^2 + \frac{a}{\sigma^2}t - \frac{a^2}{2\sigma^2}\right)}.
\]
В таком случае
\[
\rho_{\theta|\mathbf X}(t|\mathbf{x}) \sim \exp{\left[-\frac{1}{2}t^2\left(n+\frac{1}{\sigma^2}\right) + t\left(\sum x_i + \frac{a}{\sigma^2}\right)\right]}.
\]
Следовательно, для реализации выборки $\mathbf x$ апостериорным распределением является $\mathcal{N}\left(\widehat{a}(\mathbf x), \widehat{\sigma^2}(\mathbf x)\right)$. Осталось только понять, чему равны $\widehat{a}$ и $\widehat{\sigma^2}$. Как видно из записи плотности $q(t)$, коэффициент перед $t^2$ в плотности нормального распределения должен быть равен $-1/2\widehat{\sigma^2}$, а перед $t$ ---  $\widehat{a} / \widehat{\sigma^2}$. Это даёт нам следующую систему уравнений:
\[
\left\{
\begin{aligned}
&\frac{\widehat{a}}{\widehat{\sigma^2}} = \sum x_i + \frac{a}{\sigma^2},\\
&\frac{1}{\widehat{\sigma^2}} = n + \frac{1}{\sigma^2}.
\end{aligned}
\right.
\Longrightarrow
\widehat{a}(\mathbf x) = \frac{\sum x_i + \frac{a}{\sigma^2}}{n + \frac{1}{\sigma^2}}.
\]
Отсюда находим, что
\[
\me[](\theta|\mathbf X) = \frac{\sum X_i + a/\sigma^2}{n + 1/\sigma^2}.
\]

\item Пусть $X_1, \ldots, X_n$ --- выборка из распределения $\mathcal{N}(0, \theta)$. Имеем совместную плотность
$$\rho(\mathbf{x} | t) = \frac{1}{(2\pi t)^{n/2}} \exp{\left(-\frac{1}{2t} \sum x_i^2\right)}.$$
Какое распределение имеет плотность от $t$, которая содержит отрицательные степени $t$ и экспоненту от $1/t$? Конечно же обратное гамма-распределение!.. А, ну да, тут уже не совсем очевидно. Будем говорить, что величина имеет \textit{обратное гамма-распределение с параметрами $\lambda$ и $\alpha$}, если её плотность равна
\[
q(t) = \frac{\lambda^{\alpha} t^{-\alpha - 1}}{\Gamma(\alpha)} e^{-\lambda/t} I(t>0).
\]
Его и возьмём за априорное распределение. В таком случае
\[
\rho_{\theta|\mathbf X}(t|\mathbf{x}) \sim t^{-\alpha - 1 - n/2} \exp{\left[-\frac{1}{t}\left(\lambda + \frac{1}{2}\sum x_i^2\right)\right]} I(t > 0),
\]
и апостериорным распределением является $\text{Inv-Gamma}\left(\alpha + n / 2, \lambda + \frac{1}{2}\sum x_i^2\right)$. Давайте поймём, как выглядит матожидание у $\xi \sim \text{Inv-Gamma}(a, b)$:
\begin{gather*}
    \me[]\xi = \int_0^{+\infty} t \cdot \frac{b^{a} t^{-a - 1}}{\Gamma(a)} e^{-b/t}\,dt = \\
    = \int_0^{+\infty} \frac{b^{a} t^{-a +2} e^{-b/t}}{\Gamma(a)}\cdot \frac{1}{t^2}\,dt = \left[s = \frac{1}{t}\right] = \int_0^{+\infty} \frac{b^{a} s^{a - 2} e^{-bs}}{\Gamma(a)}\,ds =\\
    = \frac{b\Gamma(a-1)}{\Gamma(a)} \cdot \underbrace{\int_0^{+\infty} \frac{b^{a-1} s^{a - 2} e^{-bs}}{\Gamma(a-1)}\,ds}_{\text{интеграл плотности }\Gamma(a-1, b)} = \frac{b\Gamma(a-1)}{\Gamma(a)} = \frac{b}{a - 1}.
\end{gather*}
Значит, для $a = \alpha + n / 2$ и $b = \lambda + \frac{1}{2}\sum x_i^2$ имеем
\[
\me[](\theta|\mathbf X) = \frac{2\lambda + \sum X_i^2}{2\alpha + n - 2}.
\]
\end{itemize}
\end{example}

\subsubsection{Распределение Джеффриса}

В случае неимения каких-либо априорных знаний о параметре возникает логичное желание задать на $\Theta$ равномерное распределение. Да, с неограниченным носителем так не выйдет (ну, или почти не выйдет, см. пример \ref{improper}), но для ограниченных $\Theta$ это звучит вполне логично: если мы ничего не знаем о потенциальном параметре, то все возможные варианты равновероятны. Так делают, и это вполне допустимая практика, но этот способ имеет существенный недостаток, что иллюстрирует следующий известный

\begin{example}[парадокс Бертрана]
	Пусть наше семейство распределений параметризовано случайной хордой единичной окружности, и перед нами стоит задача задать на них какое-то априорное распределение. Работать непосредственно с хордами неудобно, легче задать их какими-то другими численными параметрами, на которые, в свою очередь, можно ввести равномерное распределение. Однако так можно сделать множеством способов (см. картинки):
	
	\begin{enumerate}
		\item Определить хорду через два конца, которые будут иметь равномерное распределение на окружности (левый рисунок);
		\item Определить хорду через радиус окружности и точку на нём, через которую пройдёт хорда, перпендикулярно радиусу. Радиус проведём к точке, равномерно взятой на окружности, а точка на радиусе будет взята с равномерным распределением на нём (выделен пунктиром на рисунке по центру);
		\item Определить хорду через её середину, которой зададим равномерное распределение на единичном круге (правый рисунок).
	\end{enumerate}
	
	\begin{figure}[H]
		\centering
		\includegraphics[width=0.8\textwidth]{pic/bertran/bertran.pdf}
	\end{figure}
	
	Во всех случаях хорда определяется через нечто, имеющее <<естественное>> равномерное распределение, однако, как несложно убедиться, во всех трёх случаях итоговое распределение на хордах получится своим. Выходит, задавая равномерное распределение, мы всё-таки вносим какую-то информацию о параметре, чего хотелось бы избежать.
\end{example}

Это является мотивацией к идее, что априорная плотность должна быть устойчива к замене переменной. Иными словами, априорное распределение нужно выбирать таким образом, чтобы при любой параметризации распределение на исходных параметрах было одним и тем же.

Рассмотрим одномерный случай. Напомним, что если к случайной величине $\xi$ с плотностью $\rho_{\xi}(x)$ применяется диффеоморфизм $\phi$, то плотность пересчитывается как
\[
\rho_{\phi(\xi)}(y) = \frac{1}{\left|\phi'(\phi^{-1}(y))\right|} \cdot \rho_{\xi}(\phi^{-1}(y)).
\]
И тут на сцене появляется информация Фишера. Зададимся вопросом: как поменяется информация Фишера $I_{\mathbf X}(\theta)$, если отныне параметром бы будем считать не $\theta$, а некоторую $\sigma = \phi(\theta)$? Ответ неожиданный и приятный:
\begin{gather*}
    I_{\mathbf X}(\sigma) = \me \left(\frac{\partial \ln{\rho_{\theta}(\mathbf X)}}{\partial \phi(\theta)} \right)^2 = \me \left(\frac{\partial \ln{\rho_{\theta}(\mathbf X)}}{\partial \theta}\cdot \frac{\partial \theta}{\partial \phi(\theta)} \right)^2 = \left(\frac{\partial \theta}{\partial \phi(\theta)}\right)^2 \me \left(\frac{\partial \ln{\rho_{\theta}(\mathbf X)}}{\partial \theta}\right)^2=\\
    = \frac{1}{\left(\frac{\partial \phi(\theta)}{\partial \theta}\right)^2} \cdot I_{\mathbf X}(\theta) = \frac{1}{\phi'(\theta)^2} \cdot I_{\mathbf X}(\theta) = \frac{1}{\phi'(\phi^{-1}(\sigma))^2} \cdot I_{\mathbf X}(\phi^{-1}(\sigma)).
\end{gather*}
Вот те раз! Прямо как в формуле плотности при замене переменной появляется производная в знаменателе, правда на этот раз в квадрате. Значит, если мы возьмём в качестве априорного распределения
\[
q(t) \sim \sqrt{I_{\mathbf X}(t)},
\]
то при смене параметризации информация Фишера поменяется так же, как и плотность, следовательно, распределение на $\theta$ всегда будет одним и тем же, даже если изначально в качестве параметра была взята $\sigma = \phi(\theta)$.

\begin{definition}
    \textit{Априорным распределением Джеффриса} называется распределение, плотность которого пропорциональна квадратному корню из информации Фишера (или в многомерном случае квадратному корню из определителя информационной матрицы).
\end{definition}

\begin{example}\label{improper_for_bin}
Рассмотрим всю ту же выборку $X_1, \ldots, X_n$ из распределения $\bernd(\theta)$. Посчитаем для неё информацию Фишера:
\begin{gather*}
    \rho_t(x) = t^x (1 - t)^{1 - x},\;\;\;
    \ln{\rho_{t}(x)} = x \cdot \ln{t} + \left(1 - x\right) \cdot \ln{(1 - t)},\\
    \frac{\partial}{\partial t} \ln{\rho_{t}(x)} = \frac{x}{t} - \frac{1-x}{1 - t} = \frac{x - t}{t(1 - t)},\\
    i(t) = \me \left(\frac{X_1 - t}{t(1 - t)}\right)^2 = (1 - t) \cdot \left(\frac{0 - t}{t(1 - t)}\right)^2 + t \cdot \left(\frac{1 - t}{t(1 - t)}\right)^2 = \frac{1}{t(1 - t)}.
\end{gather*}
Таким образом, $q(t)$ должна быть пропорциональна $\frac{1}{\sqrt{t(1 - t)}}$, то есть априорным распределением является $\betad\left(\frac{1}{2}, \frac{1}{2}\right)$, что не может не радовать, так как оно к тому же сопряженно распределению Бернулли.
\end{example}

Иногда бывает так, что $\sqrt{I_{\mathbf X}(\theta)} \notin L_1(\Theta)$ и, следовательно, не пропорционально никакой плотности. В этом случае априорное распределение Джеффриса будет мерой на $\Theta$ (но не вероятностной), и мы можем лишь надеяться, что апостериорное распределение окажется вероятностным.

\begin{definition}
    Невероятностные априорные распределения с $\int_{\Theta} q(t)dt = \infty$ называют \textit{несобственными} (англ. \textsf{improper prior}).
\end{definition}

\begin{example}\label{improper}
    Посмотрим, как ведут себя такие распределения и насколько адекватными получаются из них оценки.
    \begin{itemize}
        \item  Пусть $X_1, \ldots, X_n$ --- выборка из распределения $\poisd(\theta)$. Найдём информацию Фишера для распределения Пуассона:
    \[
    \rho_{t}(x) = \frac{t^xe^{-t}}{x!};\;\;\;\ln{\rho_{t}(x)} = x\ln{t} - t - \ln{x!};
    \]
    \[
    \frac{\partial}{\partial t} \ln{\rho_{t}(x)} = \frac{x}{t} - 1;\;\;\;i(t) = \va[t] \left(\frac{X_1}{t} - 1\right) = \frac{1}{t^2} \va[t] X_1 = \frac{1}{t}.
    \]
    Получается, что распределение Джеффриса имеет плотность 
    \[
    q(t) \sim \frac{1}{\sqrt{t}},
    \]
    что не интегрируемо на $(0; +\infty)$. Но при этом
    \[
    \rho_{\theta|\mathbf X}(t|\mathbf{x}) \sim t^{\sum x_i - 1/2} e^{-tn},
    \]
    то есть апостериорное распределение вполне себе определено, и равно $\Gamma\left(\sum x_i + 1/2, n\right)$. Итого, байесовская оценка равна
    \[
    \me[](\theta|\mathbf X) = \frac{\sum X_i + 1 / 2}{n}.
    \]
    \item Пусть теперь $X_1, \ldots, X_n$ -- выборка из распределения $\mathcal{N}(\theta, 1)$. Информацию Фишера позаимствуем из задачи \ref{fisher_norm}: $i(t) = 1 / \sigma^2 = 1$, то есть распределение Джеффриса будет равномерным распределением на $\R$ (следовательно, несобственным). В таком случае
    \[
    \rho_{\theta|\mathbf X}(t|\mathbf{x}) \sim \exp{\left(-\frac{n}{2}t^2 + t \sum x_i\right)},
    \]
    что есть $\mathcal{N}\left(\sum x_i / n, 1/n\right)$, откуда
    \[
    \me[](\theta|\mathbf X) = \frac{\sum X_i}{n}.
    \]
    \end{itemize}
    
\end{example}

    Как можно видеть, несмотря на то что затея с несобственными распределениями кажется неадекватной, она даёт нам довольно неплохие оценки. В последнем случае полученная байесовская оценка и вовсе совпала с оценкой максимального правдоподобия: в отличие от предыдущих оценок в ней нет никаких дополнительных сдвигов и добавок, который регуляризируют нашу оценку, исходя из наших априорных знаний. Это наталкивает на мысль, что полученное распределение является \textit{неинформативным}, то есть не вносящим никаких дополнительных знаний о параметре. 

    Аналогичными свойствами обладает несобственное распределение $q(t) = \frac{1}{t(1-t)}$ для выборки из $\bernd(\theta)$, которое формально можно толковать как $\betad(0, 0)$. Как мы убедились ранее, для априорного бета-распределения при пересчёте плотности первый параметр увеличивается на число единиц в выборке, а второй~--- на число нулей. Поэтому нули в качестве параметров априорного распределения можно понимать как отсутствие какой-либо информации об известных результатах~--- до проведения эксперимента мы не знаем ни про выпавшие единицы, ни про выпавшие нули.

\subsection{Связь с минимаксными оценками}

В контексте байесовского подхода полезно рассмотреть иной способ сравнения оценок, который тесно связан с текущим. Он, как и ранее, ранжирует функции риска с помощью одного числа. В байесовском подходе это была $L_1$-норма по некоторой вероятностному (или несобственному) распределению. Сейчас, дабы не утруждать себя выбором априорного распределения, предлагается взять $L_{\infty}$-норму.

\begin{definition}
	Пусть $\widehat{\theta}$ и $\theta^*$ --- оценки параметра $\theta$. Говорят, что оценка $\widehat{\theta}$ \textit{лучше оценки $\theta^*$ в минимаксном подходе}, если
	\[
	\sup_{\theta \in \Theta} R(\widehat\theta, \theta) \le \sup_{\theta \in \Theta} R(\theta^*, \theta).
	\]
	Оценка $\widehat{\theta}$ называется \textit{минимаксной}, если она лучше любой другой оценки в минимаксном подходе, то есть
	\[
	\widehat{\theta} = \argmin_{\theta^*} \sup_{\theta \in \Theta} R(\theta^*, \theta).
	\]
\end{definition}

\begin{wrapfigure}[10]{r}{0.3\textwidth}
	\vspace{-10pt}
	% \vspace{-\f@sizept}
    \includegraphics[width=0.3\textwidth]{pic/bayes_vs_minimax_pic/bayes_vs_minimax_pic.pdf}
\end{wrapfigure}

Может показаться, что такая метрика не совсем адекватна. Она штрафует оценки, которые могут сильно ошибаться при некоторых значениях параметра, даже если их в каком-то смысле не очень много, а при других значениях она показывает себя отлично. Например, на рисунке оценка $\widehat{\theta}(\mathbf X)$ будет лучше в байесовском подходе, если взять равномерное распределение на $\Theta$, потому что в среднем она ошибается незначительно. Но в минимаксном выиграет $\theta^*(\mathbf X)$, хотя всюду функция риска довольно велика. Впрочем, это не значит, что данный подход совсем не годен, уместность его использования зависит от конкретной ситуации. Байесовский подход на то и байесовский, что он минимизирует взвешенную ошибку, основанную на нашем представлении о том, как часто встречается то или иное значение параметра в природе. Минимаксный подход же удобен, когда никакой информации о параметре нет, и нам хотелось бы перестраховаться на самый неблагоприятный случай.

Несмотря на такое фундаментальное различие между данными подходами, между ними имеется тесная связь, позволяющая из байесовости оценки получать минимаксность. Ключевым наблюдением здесь будет тот факт, что для вероятностных мер $\|\cdot\|_{\infty} \ge \|\cdot\|_{1}$, отсюда появляется возможность оценить снизу произвольную оценку по минимаксной метрике.

\begin{theorem}[label=bayes_implies_minimax]{}{}
	Пусть $\widehat{\theta}(\mathbf X)$ --- наилучшая оценка в байесовском подходе относительно априорного вероятностного распределения $\mathsf{Q}$ и функции потерь $R$, причём $R(\widehat{\theta}, \theta) \equiv \const$. Тогда она является и минимаксной относительно этой функции потерь.
\end{theorem}

\begin{proof}
	Пусть $\theta^*(\mathbf X)$ --- произвольная оценка. Её минимаксную норму можно оценить снизу следующим образом:
	\[
	\sup_{\theta\in\Theta} R(\theta^*, \theta) \ge \int_{\Theta} R(\theta^*, \theta) \,\mathsf{Q}(d\theta) \ge \int_{\Theta} R(\widehat \theta, \theta) \,\mathsf{Q}(d\theta),
	\]
	где последнее неравенство следует из оптимальности оценки $\widehat{\theta}$ в байесовском подходе. Но так как её функция риска постоянна, то последнее выражение в точности равно $\sup_{\theta\in\Theta} R(\widehat\theta, \theta)$, откуда следует минимаксность оценки $\widehat{\theta}$.
\end{proof}

Таким образом, нам достаточно найти <<хорошее>> априорное распределение, которое выравнивает функцию риска, тогда байесовская оценка автоматически будет минимаксной.

\begin{example}
	Пусть $\mathbf{X} = (X_1, \ldots, X_n)$ --- выборка из $\bernd(\theta)$, найдём в этой модели минимаксную оценку при квадратичной функции потерь. Ранее мы уже поняли, что байесовская оценка легко считается при априорном распределении $\betad(\alpha, \beta)$: в таком случае оптимальная оценка равна
	$\widehat{\theta}(\mathbf X) = \frac{\alpha + \sum X_i}{\alpha + \beta + n}$
	
	Попробуем подобрать параметры $\alpha$ и $\beta$ так, чтобы $R(\widehat\theta, \theta) = \me (\widehat\theta - \theta)^2 \equiv \const$.
	\begin{gather*}
		\me (\widehat\theta - \theta)^2 = \va \widehat\theta + (\me \widehat\theta - \theta)^2 = \frac{\va \sum X_i}{(\alpha + \beta + n)^2} + \left(\frac{\alpha + n\theta}{\alpha + \beta + n} - \theta\right)^2 = \\
		= \frac{n\theta(1-\theta) + (\alpha(1-\theta) - \beta \theta)^2}{(\alpha + \beta + n)^2} \sim ((\alpha+\beta)^2-n)\theta^2 + (n - 2\alpha(\alpha+\beta))\theta + \alpha^2 \equiv \const \Longrightarrow \\
		\left\{\begin{aligned}
			&\alpha+\beta = \sqrt{n},\\
			&\alpha(\alpha+\beta) = \frac{n}{2}
		\end{aligned}\right. ; \;\;\;
		\alpha = \beta = \frac{\sqrt{n}}{2}.
	\end{gather*}
	
	Таким образом, по теореме \ref{bayes_implies_minimax} оценка
	\[
	\widehat{\theta}(\mathbf X) = \frac{\sqrt{n} / 2 + \sum X_i}{\sqrt{n} + n} = \frac{\overline{\mathbf X} + \frac{1}{2\sqrt{n}}}{1 + \frac{1}{\sqrt{n}}}
	\]
	является минимаксной при квадратичной функции потерь.
\end{example}

Полученная выше оценка называется \textit{оценкой Ходжеса-Лемана}. Несложно заметить, что она является выпуклой комбинацией обычного среднего и $1/2$, и поэтому она смещена.

%\subsection{Проверка гипотез}

% TODO Байесовская проверка гипотез

%\subsection{MCMC}

% TODO Методы сэмплирования

\subsection*{Задачи}

\begin{problem}
    Покажите, что знание о параметре может обновляться постепенно по мере поступления новых наблюдений. Более формально, пусть наблюдения $X_1, \ldots, X_n$ подаются по одному, и старая апостериорная плотность становится априорной, из которой посредством нового наблюдения $X_i$ получается новая апостериорная плотность. Докажите, что в итоге получится та же плотность, как если бы она была получена по всей выборке сразу.
    % \[
    % \pi_k(t|x_1, \ldots, x_k) = \frac{\pi_{k-1}(t|x_1, \ldots, x_{k-1}) \rho(x_k | t)}{\int_{\Theta} \pi_{k-1}(t|x_1, \ldots, x_{k-1}) \rho(x_k | t) \,d\mu(s)},
    % \]
\end{problem}

\begin{problem}
    Докажите, что байесовская оценка является функцией от достаточной статистики.
\end{problem}

\begin{problem}
    Докажите теорему \ref{bayes_is_the_best}.
\end{problem}

\begin{problem}
    Найдите семейство распределений, сопряжённое $\{\mathcal{N}(0, 1/\theta)\colon \theta > 0\}$.
\end{problem}

\begin{problem}
    В примере \ref{improper} для выборки $X_1, \ldots, X_n \sim \mathcal{N}(\theta, 1)$, $\theta \in \R$, неинформативное распределение дало нам обычное выборочное среднее в качестве байесовской оценки. Докажите, что если взять честное вероятностное распределение в качестве $\mathsf{Q}$, то такой байесовской оценки получиться не может.
\end{problem}

\begin{problem}
    В модели масштаба $X_1, \ldots, X_n \sim \mathcal{N}(0, \theta^2)$, $\theta > 0$, придумайте неинформативное распределение для параметра масштаба $\theta$. Аргументируйте ваш выбор. 
\end{problem}




 
