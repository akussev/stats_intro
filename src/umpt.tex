\section{Равномерно наиболее мощные критерии}

Среди всевозможных критериев с заданным уровнем значимости $\alpha$, как было замечено выше, разумнее всего брать те, что имеют как можно большую мощность. Во многих случаях нельзя точно сказать, какой критерий лучше: при разных альтернативах предпочтительнее могут оказаться разные критерии. Поэтому ситуации, когда можно выделить один критерий, умеющий переплюнуть любой другой, представляют особый интерес.

\begin{definition}
    Критерий $R$ уровня значимости $\alpha$ называется \textit{равномерно наиболее мощным (или сокращённо р.н.м.к.) уровня значимости $\alpha$}, если он мощнее любого другого критерия уровня значимости $\alpha$.
\end{definition}

%\begin{wrapfigure}{r}{0.4\textwidth}
%    \includegraphics[width=0.4
%    \textwidth]{pic/most_powerful_pic/most_powerful_pic.pdf}
%\end{wrapfigure}

\begin{wrapfigure}{r}{0.35\textwidth}
    \includegraphics[width=0.35\textwidth]{pic/most_powerful_pic/most_powerful_pic.pdf}
\end{wrapfigure}

\begin{example}
Пусть $\mathbf X = (X_1, \ldots, X_n)$ --- выборка из равномерного распределения на отрезке $[0; \theta]$, $\theta > 0$. Нам предстоит голыми руками построить р.н.м.к. уровня значимости $\alpha$ для проверки гипотезы $H_0\colon \theta = \theta_0$ против альтернативы $H_1\colon \theta \ne \theta_0$.

Очевидно, что в случае, когда $X_{(n)} > \theta_0$, гипотеза $H_0$ однозначно неверна, поэтому такие выборки следует отнести в критическое множество. Также понятно, что слишком маленькое значение $X_{(n)}$ является серьёзным доводом для отвержения гипотезы $H_0$. Итого, давайте возьмём в качестве критерия множество
\[
R = \{\mathbf{x} \in \R^n\colon x_{(n)} > \theta_0\} \cup \{\mathbf{x}\in\R^n\colon x_{(n)} \le c\},
\]
где $c = c_{\alpha}$ мы подберём так, чтобы размер $R$ был в точности $\alpha$:
\[
\alpha = \pth[\theta_0](\mathbf X \in R) = \pth[\theta_0](X_{(n)} \le c) = \pth[\theta_0](X_{1} \le c)^n = \frac{c^n}{\theta_0^n} \Longrightarrow c = \theta_0 \sqrt[n]{\alpha}.
\]

%\begin{figure}[H]
%    \centering
%    \includegraphics[width=0.35\textwidth]{pic/most_powerful_pic/most_powerful_pic.pdf}
%\end{figure}

Докажем, что он и будет р.н.м.к.

Для $\theta \le c$ всё очевидно: критерий полностью покрывает носитель плотности, то есть при таких $\theta$ у нас $\pth(\mathbf X \in R) = 1$, и больше уже и не сделаешь.

Возьмём $c < \theta < \theta_0$. Пусть существует критерий $S$ с большей мощностью для данной $\theta$, то есть $\pth(\mathbf X \in S) > \pth(\mathbf X \in R)$. Но тогда
\begin{gather*}
    \pth[\theta_0](\mathbf X \in S) = \int_{S} \rho_{\theta_0}(\mathbf{x})\,d\mathbf{x} = \int\limits_{S\cap\{0 \le x_i \le \theta_0\}} \frac{d\mathbf{x}}{\theta_0^n} \ge \frac{\theta^n}{\theta_0^n} \cdot \int\limits_{S\cap\{0 \le x_i \le \theta\}} \frac{d\mathbf{x}}{\theta^n} = \frac{\theta^n}{\theta_0^n} \cdot \pth(\mathbf X \in S) >\\ > \frac{\theta^n}{\theta_0^n} \cdot \pth(\mathbf X \in R) = \frac{\theta^n}{\theta_0^n} \int_{R} \rho_{\theta}(\mathbf{x})\,d\mathbf{x} = \frac{\theta^n}{\theta_0^n} \int\limits_{R \cap \{0 \le x_i \le \theta\}} \frac{d\mathbf{x}}{\theta^n} = \int\limits_{R \cap \{0 \le x_i \le \theta_0\}} \frac{d\mathbf{x}}{\theta_0^n} = \pth[\theta_0](\mathbf X \in R) = \alpha,
\end{gather*}
то есть критерий $S$ априори не может иметь требуемый уровень значимости.

Случай $\theta > \theta_0$ аналогичен предыдущему: мы захотим получить множество большей мощности по $\theta$, но это непременно приведёт к увеличению мощности по $\theta_0$, то есть размера критерия, в силу пропорциональности этих вероятностей и выбора множества $R$.
\end{example}

Однако чаще всего р.н.м.к. просто нет, и в зависимости от ситуации нужно подбирать наиболее подходящий критерий. Правда, доказательство отсутствия р.н.м.к. иногда представляет собой непростую задачу.

{\small
\begin{example}
Пусть $\mathbf X = (X_1, \ldots, X_n)$ --- выборка из распределения $\bernd(\theta)$. Будем проверять выполнимость гипотезы о равенстве параметра фиксированному числу:
\[
H_0\colon \theta = \theta_0 \vs H_1\colon \theta \ne \theta_0
\]
Вообще говоря, в некоторых вырожденных случаях р.н.м.к. существует. Действительно, например, положим $\theta_0 = 1/2$, а $\alpha < 2^{-n}$. Тогда пустой критерий будет единственным с допустимым уровнем значимости, а значит, он автоматически р.н.м.к. Докажем, что для фиксированных $\theta_0$ и $\alpha$ р.н.м.к. не существует для достаточного большого $n$.

Пусть существует р.н.м.к. $R$. Рассмотрим критерии вида $S_1 = \left\{\mathbf{x}\colon \sum x_i \ge c_1\right\}$ и $S_2 = \left\{\mathbf{x}\colon \sum x_i \le c_2\right\}$, где константы $c_1$ и $c_2$ мы подберём <<впритык>> так, чтобы они имели уровень значимости $\alpha$. Так как $R$ --- р.н.м.к., то его мощность должна быть больше мощностей этих критериев при любых $\theta \ne \theta_0$. Рассмотрим первый из них при $\theta \to 1-0$.

Выберем $\theta$ настолько близкой к единице, чтобы произвольное наблюдение с $k$ единицами из $n$ было вероятнее, чем все возможные наблюдения с меньшим количеством единиц, то есть
\[
\pth\left(\mathbf X = (\underbrace{\ldots\ldots}_{k\text{ единиц}})\right) > \pth\left(\sum X_i < k\right).
\]
Так сделать можно: в правой части не больше $2^n$ слагаемых с вероятностью не большей $\theta^{k-1}(1-\theta)^{n-k+1}$, а вероятность слева равна $\theta^{k}(1-\theta)^{n-k}$, то есть отношение левой части к правой не меньше $\frac{\theta}{1-\theta}\cdot 2^{-n}$, что при фиксированном $n$ можно сделать сколь угодно большим.

Спрашивается: а зачем нам это всё? Из этого следует, что критерий $R$ \textit{обязан} содержать $S_1$ как подмножество. Действительно, выберем максимальный $k$ такой, что $R$ не содержит какой-то вектор с $k \ge c_1$ единицами. Но тогда чтобы вероятность $R$ была больше вероятности $S_1$ при выбранном $\theta$, надо взять другие наблюдения с меньшим числом единиц, что всё равно не позволит получить нужную вероятность по выбору $\theta$ -- противоречие. Аналогично $S_2 \subset R$.

А теперь вспомним, что константы для $S_1$ и $S_2$ мы выбирали так, чтобы они тютелька в тютельку были с нужным уровнем значимости. Поэтому если мы возьмём настолько большое $n$, чтобы $\pth[\theta_0]\left(\sum X_i = k\right) < \alpha / 2$ для всех $k$, то $S_1$ и $S_2$ будут иметь уровень значимости больше $\alpha / 2$. И вправду: если бы, например, $\pth[\theta_0](\mathbf X \in S_1) \le \alpha / 2$, то $c_1$ можно было бы уменьшить на единичку, что не сильно бы увеличило уровень значимости по выбору $n$. Таким образом, так как $S_1 \cup S_2 \subset R$, то либо $S_1 \cap S_2 \ne \varnothing$, и $R$ есть все исходы и, стало быть, имеет размер 1, либо $S_1 \cap S_2 = \varnothing$, и $R$ имеет минимальный уровень значимости больше, чем $\alpha$ -- противоречие.
\end{example}
}

\subsection{Простые гипотезы и лемма Неймана-Пирсона}

В подавляющем большинстве ситуаций р.н.м.к. просто не существует, особенно если речь идёт о \textit{двусторонних} гипотезах, которые проверяют равенство параметра определённому значению против альтернативы неравенства. Но для игрушечных гипотез такой можно явно предъявить.

\begin{definition}
Гипотеза $H\colon \pth[] \in \mathcal{P}$ называется \textit{простой}, если множество предполагаемых распределений состоит из единственного кандидата: $\mathcal{P} = \{\pth[]\}$. Иначе она называется \textit{сложной}.
\end{definition}

Предположим, нам надо столкнуть лбами две простые гипотезы:
\[
H_0\colon \pth[] = \pth[0] \vs H_1\colon \pth[] = \pth[1],
\]
причём оба кандидата $\pth[0]$ и  $\pth[1]$ абсолютно непрерывны относительно некоторой меры $\mu$ и имеют по ней плотности $\rho_0(t)$ и $\rho_1(t)$ соответственно.

\begin{theorem}{лемма Неймана-Пирсона}{}
Рассмотрим критерий $R_{\lambda} = \{\mathbf x\in \mathcal{X}\colon \rho_1(\mathbf x) - \lambda \rho_0(\mathbf x) \ge 0\}$, где $\lambda > 0$. Если его размер равен $\alpha$, то есть $\pth[0](X \in R_{\lambda}) = \alpha$, то он является несмещённым р.н.м.к. уровня значимости $\alpha$.
\end{theorem}

\begin{proof}
	Пусть $S$ --- произвольный критерий уровня значимости $\alpha$, то есть с $\pth[0](\mathbf X \in S) \le \alpha = \pth[0](\mathbf X \in R_{\lambda})$. Рассмотрим функцию $f\colon \mathcal{X} \to \R$, определённую как
	\[
	f(\mathbf x) = (I(\mathbf x \in R_{\lambda}) - I(\mathbf x \in S)) \cdot (\rho_1(\mathbf x) - \lambda \rho_0(\mathbf x)).
	\]
	Заметим, что она неотрицательна на всём $\mathcal{X}$: для $\mathbf x \in R_{\lambda}$ обе скобки неотрицательные, а для $\mathbf x \notin R_{\lambda}$ --- неположительные. Тогда
	\begin{gather*}
		0 \le \int_{\mathcal{X}} f(\mathbf x) \, \mu(d\mathbf x) = \pth[1](\mathbf X \in R_{\lambda}) - \pth[1](\mathbf X \in S) - \lambda(\underbrace{\pth[0](\mathbf X \in R_{\lambda}) - \pth[0](\mathbf X \in S)}_{{} \ge 0}) \le \\
		\le \pth[1](\mathbf X \in R_{\lambda}) - \pth[1](\mathbf X \in S),
	\end{gather*}
	откуда $\pth[1](\mathbf X \in R_{\lambda}) \ge \pth[1](\mathbf X \in S)$, то есть критерий $R_{\lambda}$ оказался мощнее. Теперь покажем несмещённость. Обозначим ошибку II рода за $\gamma$. С одной стороны,
	\[
	\alpha = \int_{R_{\lambda}} \rho_0(\mathbf x)\,\mu(d\mathbf x) \le \frac{1}{\lambda}\int_{R_{\lambda}} \rho_1(\mathbf x)\,\mu(d\mathbf x) = \frac{1-\gamma}{\lambda}.
	\]
	С другой стороны, аналогично получаем
	\[
	1 - \alpha = \int_{\overline{R_{\lambda}}} \rho_0(\mathbf x)\,\mu(d\mathbf x) \ge \frac{1}{\lambda}\int_{\overline{R_{\lambda}}} \rho_1(\mathbf x)\,\mu(d\mathbf x) = \frac{\gamma}{\lambda}.
	\]
	Таким образом,
	\[
	\frac{\gamma}{1-\alpha} \le \lambda \le \frac{1-\gamma}{\alpha},
	\]
	откуда $\pth[0](\mathbf X \in R_{\lambda}) = \alpha \le 1 - \gamma = \pth[1](\mathbf X \in R_{\lambda})$, что и требовалось.
\end{proof}

\begin{wrapfigure}{r}{0.35\textwidth}
    \includegraphics[width=0.35\textwidth]{pic/np_example/np_example.pdf}
\end{wrapfigure}

\begin{example}
Пусть $X_1$ -- выборка размера 1. Рассмотрим гипотезы
\[
H_0\colon X_1 \sim \ud(0, 1) \vs H_1\colon X_1 \sim \expd(1).
\]
Построим р.н.м.к. для проверки $H_0$ против $H_1$.

%\begin{center}
%    \includegraphics{pic/np_example/np_example.pdf}
%\end{center}
Из монотонности $\rho_1(t) = e^{-t}$ (см. рис.) легко понять, что р.н.м.к. здесь будет
\[
R_{\lambda} = \{x \in \R\colon \rho_1(x) \ge \lambda\rho_0(x)\} = (-\infty; c] \cup [1; +\infty],
\]
где $c$ удовлетворяет равенствам $\lambda = e^{-c}$ и $\alpha = \pth[0](\mathbf X \in R_{\lambda}) = c$, то есть $\lambda  = e^{-\alpha}$. Отсюда также несложно посчитать мощность нашего критерия:
\[
\beta(R_{\lambda}) = \pth[1](\mathbf X \in R_{\lambda}) = 1 - \int_c^1 \rho_1(t)\,dt = 1 +\left. e^{-t}\right|_c^1 = 1 + e^{-1} - e^{-\alpha}.
\]
\end{example}

\begin{example}
Пусть $X_1, \ldots, X_n$ --- выборка из распределения $\mathcal{N}(0, \sigma^2)$. Построим р.н.м.к. уровня значимости $\alpha$ для проверки гипотезы $H_0\colon \sigma^2 = \sigma^2_0$ против альтернативы $H_1\colon \sigma^2 = \sigma^2_1$.

По лемме выше для подходящего $\lambda$ критерий
\[
R_{\lambda} = \left\{\mathbf{x}\in\R^n\colon \frac{\rho_1(\mathbf{x})}{\rho_0(\mathbf{x})} \ge \lambda\right\} = \left\{\mathbf{x}\colon \left(\frac{\sigma^2_0}{\sigma^2_1}\right)^{n/2}\cdot \exp{\left[-\frac{1}{2}\left(\frac{1}{\sigma^2_1}-\frac{1}{\sigma^2_0}\right)\sum x_i^2\right]} \ge \lambda\right\}
\]
будет удовлетворять условию. Осталось сделать так, чтобы размер критерия был в точности равен $\alpha$. Без потери общности скажем, что $\sigma^2_0 > \sigma^2_1$. Тогда 
\begin{gather*}
    R_{\lambda} = \left\{\mathbf{x}\in\R^n\colon \exp{\left[-\frac{1}{2}\left(\frac{1}{\sigma^2_1}-\frac{1}{\sigma^2_0}\right)\sum x_i^2\right]} \ge \lambda\left(\frac{\sigma^2_1}{\sigma^2_0}\right)^{n/2}\right\} = \\
    = \left\{\mathbf{x}\colon -\frac{1}{2}\left(\frac{1}{\sigma^2_1}-\frac{1}{\sigma^2_0}\right)\sum x_i^2 \ge \ln{\lambda} + \frac{n}{2}\ln\frac{\sigma^2_1}{\sigma^2_0}\right\} = \\
    = \left\{\mathbf{x}\colon \frac{1}{\sigma^2_0}\sum x_i^2 \le \frac{\sigma^2_1}{\sigma_1^2 - \sigma^2_0}\left(2\ln{\lambda} + n\ln\frac{\sigma^2_1}{\sigma^2_0}\right)\right\}.
\end{gather*}
В силу независимости элементов выборки при верности $H_0$ выполнено $\sum X_i^2 \sim \sigma^2_0 \chi^2_n$, поэтому $\lambda$ и $\alpha$ связывает следующее соотношение:
\[
\frac{\sigma^2_1}{\sigma_1^2 - \sigma^2_0}\left(2\ln{\lambda} + n\ln\frac{\sigma^2_1}{\sigma^2_0}\right) = \chi^2_{n,\alpha},
\]
где $\chi^2_{n,p}$ --- $p$-квантиль соответствующего распределения. Отсюда
\[
\lambda = \left(\frac{\sigma^2_0}{\sigma^2_1}\right)^{n/2}\cdot \exp{\left[-\frac{1}{2}\left(\frac{\sigma^2_0}{\sigma^2_1}-1\right)\chi^2_{n,\alpha}\right]}.
\]
В случае $\sigma^2_0 < \sigma^2_1$ формула останется прежней за исключением замены $z_{\alpha}$ на $z_{1-\alpha}$ (подумайте, почему).
\end{example}

\subsection{Сложные гипотезы и монотонное отношение правдоподобия}

Как и ранее, будем предполагать, что все потенциальные распределения $\pth$ (как из $\mathcal{P}_0$, так и из $\mathcal{P}_1$) имеют плотность $\rho_{\theta}$ относительно некоторой меры. Введём следующее

\begin{definition}
Говорят, что семейство $\{\pth\colon \theta \in \Theta\}$ обладает \textit{монотонным отношением правдоподобия по статистике $T(\mathbf{x})$}, если для всех $\theta_0$ и $\theta_1$ из $\Theta$ таких, что $\theta_0 < \theta_1$, функция $\dfrac{\rho_{\theta_1}(\mathbf{x})}{\rho_{\theta_0}(\mathbf{x})}$ является монотонной по $T(\mathbf{x})$ с одним и тем же типом монотонности (для уточнения этот тип монотонности добавляют в название, например, неубывающее/невозрастающее отношение правдоподобия).
\end{definition}

\begin{theorem}[label=mon_frac]{о монотонном отношении правдоподобия}{}
Пусть $\{\pth\colon \theta \in \Theta\}$ -- семейство с неубывающим отношением правдоподобия по статистике $T(\mathbf{x})$. Поставим проблему проверки
\[
H_0\colon \theta \le \theta_0 \vs H_1\colon \theta > \theta_0.
\]
Если существует некоторое $c$ такое, что $\pth[\theta_0](T(\mathbf X) \ge c) = \alpha$, то критерий $R = \{\mathbf{x}\colon T(\mathbf{x}) \ge c\}$ является р.н.м.к. с уровнем значимости $\alpha$.
\end{theorem}

\begin{remark}
В условии теоремы основную гипотезу можно поставить и как $H_0\colon \theta = \theta_0$.
\end{remark}

\begin{example}
Пусть $X_1, \ldots, X_n$ --- выборка из распределения $\mathcal{N}(\theta, 1)$. Построим р.н.м.к. уровня значимости $\alpha$ для проверки следующих гипотез:
\begin{itemize}
    \item $H_0\colon \theta \le \theta_0 \vs H_1\colon \theta > \theta_0$. Распишем отношение совместных плотностей:
    \begin{gather*}
    \frac{\rho_{\theta_2}(\mathbf{x})}{\rho_{\theta_1}(\mathbf{x})} = \exp{\left[\frac{1}{2}\sum (x_i - \theta_1)^2-\frac{1}{2}\sum (x_i - \theta_2)^2\right]} =\\ =\exp{\left[\frac{n}{2}(\theta_1^2 - \theta_2^2) + (\theta_2-\theta_1)\sum x_i\right]}\text{ --- возрастает по $\sum x_i$ при } \theta_2 > \theta_1
\end{gather*}
Так как $\sum X_i \sim \mathcal{N}(n\theta_0, n)$ при верности $H_0$, то $\left(\sum X_i - n\theta_0\right)/\sqrt{n} \sim \mathcal{N}(0, 1)$, и требуемым критерием будет являться
$$R = \left\{\mathbf{x}\colon \left.\left(\sum x_i - n\theta_0\right)\right/\sqrt{n} \ge z_{1-\alpha}\right\} = \left\{\mathbf{x}\colon \sum x_i \ge n\theta_0 + \sqrt{n} z_{1-\alpha}\right\},$$
где $z_{p}$ -- $p$-квантиль распределения $\mathcal{N}(0, 1)$.

    \item $H_0 \colon \theta \ge \theta_0 \vs H_1\colon \theta < \theta_0$. Введём параметр $\mu := -\theta$. Тогда плотность будет иметь вид
    \[
    \rho_{\mu}(t) = \frac{1}{\sqrt{2\pi}}e^{-(t + \mu)^2/2}.
    \]
    Отношение совместных плотностей для $\mu_2 > \mu_1$ есть
    \[
    \frac{\rho_{\mu_2}(\mathbf{x})}{\rho_{\mu_1}(\mathbf{x})} = \exp{\left[\frac{1}{2}\sum (x_i + \mu_1)^2-\frac{1}{2}\sum (x_i + \mu_2)^2\right]} = \exp{\left[\frac{n}{2}(\mu_1^2 - \mu_2^2) + (\mu_1-\mu_2)\sum x_i\right]},
    \]
    что является возрастающей по $-\sum x_i$ функцией. Опять же, имеем $\sum X_i \sim \mathcal{N}(n\theta_0, n)$ при верности $H_0$, откуда получаем р.м.н.к.
    $$R = \left\{\mathbf{x}\colon \left.-\left(\sum x_i - n\theta_0\right) \right/ \sqrt{n} \ge z_{1 - \alpha}\right\} = \left\{\mathbf{x}\colon \sum x_i \le n\theta_0 + \sqrt{n}z_{\alpha}\right\}.$$
\end{itemize}
\end{example}

\begin{example}
Пусть $X_1, \ldots, X_n$ --- выборка из распределения $\expd(\lambda)$. Будем строить р.н.м.к. для основной гипотезы  $H_0\colon \lambda = \lambda_0$ на уровне значимости $\alpha$ против односторонних альтернатив.

\begin{itemize}
    \item $H_1\colon \lambda > \lambda_0$. Для $\lambda_2 > \lambda_1$ имеем
    \[
    \frac{\rho_{\lambda_2}(\mathbf{x})}{\rho_{\lambda_1}(\mathbf{x})} = 
    \left(\frac{\lambda_2}{\lambda_1}\right)^n \exp{\left[(\lambda_1 - \lambda_2)\sum x_i\right]},
    \]
    поэтому семейство распределений обладает неубывающим отношением правдоподобия по $-\sum x_i$. Из независимости $X_i$ получаем, что если $H_0$ верна, то $\sum X_i \sim \Gamma(n, \lambda_0)$. Тогда по теореме выше р.н.м.к. будет критерий
    $$R = \left\{\mathbf{x}\colon -\sum x_i \ge -x_{\alpha}\right\} = \left\{\mathbf{x}\colon \sum x_i \le y_{\alpha}\right\},$$
    где $y_{p}$ --- $p$-квантиль распределения $\Gamma(n, \lambda_0)$.

    \item $H_1\colon \lambda < \lambda_0$. Сведём задачу к теореме выше введением иного параметра $\nu := -\lambda$. Тогда $\rho_{\nu}(t)=-\nu e^{\nu t}$, и гипотезы перепишутся как
    \[
    H_0\colon \nu = \nu_0 \vs H_1\colon \nu > \nu_0.
    \]
    Рассмотрим отношение совместных плотностей для $\nu_2 > \nu_1$:
    \[
    \frac{\rho_{\nu_2}(\mathbf{x})}{\rho_{\nu_1}(\mathbf{x})} = 
    \left(\frac{-\nu_2}{-\nu_1}\right)^n \exp{\left[(\nu_2 - \nu_1)\sum x_i\right]},
    \]
    что есть возрастающая функция от $\sum x_i$, то есть новое семейство распределений обладает неубывающим отношением правдоподобия. Таким образом, по теореме \ref{mon_frac} $R = \left\{\mathbf{x}\colon\sum x_i \ge y_{1-\alpha}\right\}$ будет р.н.м.к.
\end{itemize}
\end{example}

\subsection*{Задачи}

\begin{problem}
	Найдите р.н.м.к. в модели сдвига $X_1, \ldots, X_n \sim \expd(1, \theta)$ для проверки гипотезы $H_0\colon \theta = \theta_0$ против альтернативы $H_1\colon \theta \ne \theta_0$.
\end{problem}

\begin{problem}
	Предложите достаточное условие, при котором р.н.м.к. из леммы Неймана-Пирсона будет единственным с точностью до $\mu$-п.н.
\end{problem}

\begin{problem}
    Докажите, что в модели сдвига $X_1, \ldots, X_n \sim \mathcal{N}(\theta, 1)$, $\theta \in \R$, не существует р.н.м.к. для проверки гипотезы
    \[
    H_0\colon \theta = 0 \vs H_1\colon \theta \ne 0.
    \]
\end{problem}





