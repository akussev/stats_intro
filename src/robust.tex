\section{Робастность}

Выделим в отдельный параграф важное свойство оценок, упоминаемое в обсуждении метода выборочных квантилей. Мотивация его такова: в реальном мире данные не обязаны подстраиваться под нашу идеальную модель. Вероятнее всего наблюдения подчиняются несколько иному распределению, которое немного отклоняется от наших предположений. Нам бы хотелось, чтобы получаемые статистические результаты не сильно от этого страдали.

Цель этого параграфа --- понять, как можно измерить устойчивость оценки при <<шевелении>> истинного распределения и какие статистики лучше всего справляются с такого рода проблемами.  Статистики с подобными свойствами называют \textit{робастными}. Неформально робастные оценки~--- это такие оценки, которые устойчивы при небольшом отклонении от предположений выбранной модели. Попробуем дать математически точное, формальное описание этого термина.

Пусть $\mathcal{P}$ --- множество всех распределений на пространстве $(\mathcal{X}, \mathcal{B}(\mathcal{X}))$ (обычно мы будем рассматривать одномерный случай $(\R, \mathcal{B}(\R))$). Начнём с того, а как вообще понимать, когда распределения близки, а когда --- не очень? Для этого можно явно задать метрику на $\mathcal{P}$, но проще вести дело с окрестностями: для каждого распределения $\pth[] \in \mathcal{P}$ можно ввести его $\epsilon$-окрестность $B_{\epsilon}(\mathsf{P}) \subset \mathcal{P}$, содержимое которой мы и будем понимать как распределения, <<близкие>> к $\mathsf{P}$. Один из подходов --- брать окрестности, порождающие топологию слабой сходимости. Например, в одномерном случае зачастую рассматривают \textit{расстояние Леви}, чьи окрестности на языке функций распределения имеют вид
\[
\mathcal{L}_{\epsilon}(F_0) = \{F \in \mathcal{P} \,|\, \forall x\in \R \colon F_0(x-\epsilon) - \epsilon \le F(x) \le F_0(x+\epsilon) + \epsilon\}.
\]
%или, что чуть сильнее слабой сходимости, равномерную метрику:
%\[
%\mathcal{U}_{\epsilon}(F_0) = \{F \in \mathcal{P} \,|\, \sup_{x \in \R } |F(x) - F_0(x)| < \epsilon\}.
%\]

Отклонение от распределения можно понимать и по-другому. Распространённый случай~--- загрязнение выборки, когда небольшая доля наблюдений, которые называют \textit{выбросами}, приходит не из истинного распределения $\mathsf{P}_0$, а произвольного мусорного $\mathsf{Q}$. Если считать, что вероятность появления выброса равна $\epsilon$, то итоговое распределение будет равно $\mathsf{P}' = (1-\epsilon)\mathsf{P}_0 + \epsilon \mathsf{Q}$. Таким образом, окрестность загрязнения можно определить как
\[
\mathcal{C}_{\epsilon}(\mathsf{P}_0) = \{\mathsf{P} \in \mathcal{P} \,|\, \exists \mathsf{Q} \in \mathcal{P}\colon  \mathsf{P} = (1-\epsilon)\mathsf{P}_0 + \epsilon \mathsf{Q}\}.
\]

Впрочем, в контексте сходимости распределений данное расстояние не совсем интуитивное. Например, если в качестве $\mathsf{P}_0$ взять дискретное распределение на прямой, то для любого $\epsilon < 1$ окрестность $\mathcal{C}_{\epsilon}(\mathsf{P}_0)$ не будет содержать непрерывные распределения, хотя $\mathsf{P}_0$ можно легко представить как слабый предел непрерывных распределений.

Пусть $G$ --- некоторый функционал на множестве $\mathcal{P}$. Мы хотим понять, насколько plug-in оценка $\widehat{\theta} = G(\widehat{\mathsf{P}}_n)$ устойчива при оценивании параметра $G(\mathsf{P}_0)$. Полезной может оказаться следующая характеристика, которая показывает, насколько сильно может в теории поменяться значение функционала, если в пределах разумного пошевелить распределение:
\[
b_{\pth[0]}(\epsilon) = \sup_{\pth[] \in B_{\epsilon}(\pth[0])} |G(\pth[]) - G(\pth[0])|,
\]
где $B_{\epsilon}(\pth[0])$ --- окрестность в каком-то из смыслов выше (будем указывать тип окрестности в верхнем индексе, например, $b_{\pth[0]}^{\mathcal{C}}(\epsilon)$, если это неясно из контекста).

Отметим, что для $\epsilon = 1$ загрязнённое распределение будет целиком состоять из мусора, и тогда величина $b_{\pth[0]}^{\mathcal{C}}(\epsilon)$ будет показывать максимальное отклонение от искомой статистики $G(\pth[0])$ --- хуже уже не будет. 

Самое базовое требование от робастной plug-in оценки --- непрерывность функционала, её породившего.

\begin{definition}
	Оценку $G(\widehat{\pth[]})$ называют \textit{качественно робастной} при $\pth[] = \pth[0]$, если функционал $G$ непрерывен в точке $\pth[0]$ относительно слабой сходимости, то есть $b_{\pth[0]}^{\mathcal{L}}(\epsilon) \to 0$ при $\epsilon \to 0$.
\end{definition}

Иногда вместо слабой сходимости указывают равномерную сходимость функций распределения, что, впрочем, то же самое в случае непрерывного распределения $\pth[0]$.

\begin{example}\label{qualitative_robustness_example}
	Функционал среднего $G(\pth[]) = \int x\,\pth[](dx)$ не обладает качественной робастностью. Действительно, для $\pth[\epsilon] = (1-\epsilon)\mathsf{P}_0 + \epsilon \delta_x$, где $\delta_x$ --- распределение, сконцентрированное в точке $x$, имеем слабую сходимость $\pth[\epsilon] \stackrel{d}{\to} \pth[0]$, при этом для каждого конкретного $\epsilon$ величину $G(\pth[\epsilon])$ можно сделать сколь угодно большой при подходящем выборе $x$.
	
	С другой стороны, функционал медианы $\mu(\pth[])$ таким недугом не обладает, потому что если у распределения $\pth[0]$ медиана определена однозначно, то из слабой сходимости следует сходимость медиан.
\end{example}

Такое определение робастности уже позволяет отсеивать бесперспективные варианты по типу интегральных функционалов, однако не отвечает на вопрос, насколько сильное отклонение мы можем себе позволить. Хотелось бы количественно оценить доступный <<запас прочности>> у оценки, что позволяет сделать следующее

\begin{definition}
\textit{Пороговым значением (точкой)} (англ. \textsf{breakdown point}) функционала $G(\widehat{\pth[]})$ в точке $\pth[0]$ называют величину
$$\epsilon^{*} = \sup\{\epsilon \in [0; 1]\colon b^{\mathcal C}_{\pth[0]}(\epsilon) < b_{\pth[0]}^{\mathcal C}(1)\}.$$

 Оценку $G(\widehat{\pth[]})$ называют \textit{количественно робастной} при $\pth[] = \pth[0]$, если пороговое значение в этой точке больше 0.
\end{definition}

Как было отмечено выше, $\epsilon = 1$ соответствует полному хаосу и наибольшему отклонению функционала, таким образом, пороговое значение показывает, какая доля выборки может быть загрязнена, чтобы получить результаты чуть лучше, чем полностью случайные.

\begin{example}
	Из рассуждений примера \ref{qualitative_robustness_example} следует, что для функционала среднего $G(\pth[]) = \int x\,\pth[](dx)$ и любого $\epsilon > 0$ выполнено $b_{\pth[]}(\epsilon) = \infty$ --- даже если общая доля выбросов незначительна, можно сделать среднее сколь угодно большим, устремляя размер выброса к бесконечности. Таким образом, пороговое значение для среднего равно 0, и оценка не робастна.
	
	Разберёмся с медианой. Если $\epsilon > 1/2$, то очевидно $b(\epsilon) = \infty$: можно взять сколь угодно большой $x \in \R$, тогда для $\pth[\epsilon] = (1-\epsilon)\pth[0] + \epsilon \delta_{x} \in b_{\pth[0]}(\epsilon)$ справедлива оценка $F_{\pth[\epsilon]}(x-0) = (1-\epsilon)F_{\pth[0]}(x-0) < 1/2$, значит, $\mu(\pth[\epsilon]) \ge x \to \infty$. Теперь пусть $\epsilon < 1/2$, и $F_{\epsilon} = (1-\epsilon)F_{0} + \epsilon H$ для некоторой функции распределения $H$. Оценим значение $F^{-1}_{\epsilon}(1/2)$ (как обычно принято, $F^{-1}(x) = \inf\{y\colon F(y) \ge x\}$). Заметим, что для точки $x < F^{-1}\left(\frac{1-2\epsilon}{2(1-\epsilon)}\right)$ верна оценка
	\[
	F_{\epsilon}(x) = (1-\epsilon)F_{0}(x) + \epsilon H(x) < (1-\epsilon) \cdot \frac{1-2\epsilon}{2(1-\epsilon)} + \epsilon \cdot 1 = \frac{1}{2},
	\]
	поэтому $\mu(F_{\epsilon}) \ge F^{-1}\left(\frac{1-2\epsilon}{2(1-\epsilon)}\right)$. Аналогично показывается, что $\mu(F_{\epsilon}) \le F^{-1}\left(\frac{1}{2(1-\epsilon)}\right)$, причём несложно убедиться, что подходящим выбором $H$ можно добиться значения медианы, сколько угодно близкого к полученным границам. Итого,
	\[
	b_{F_0}(\epsilon) = \max\left\{\mu(F_0) - F^{-1}\left(\frac{1-2\epsilon}{2(1-\epsilon)}\right), F^{-1}\left(\frac{1}{2(1-\epsilon)}\right) - \mu(F_0)\right\} < \infty \;\;\;\text{при $\epsilon < 1/2$},
	\]
	и пороговое значение равно $\epsilon^*(\mu) = 1/2$. Аналогично показывается, что функционал $G_p(F) = F^{-1}(p)$~--- $p$-квантиль распределения~--- имеет пороговое значение $\min(p, 1-p)$.
\end{example}

\subsection{Функция влияния}

Пороговое значение раскрывает функционал с глобальной точки зрения, показывая, насколько сильно можно испортить выборку. Но к сожалению, оно не конкретизирует поведение plug-in оценки при меньшем загрязнении выборки: полезно было бы оценить меру ухудшения оценки, когда доля выбросов достаточно мала. В этом нам поможет следующая важная величина, которая имеет множество приложений в непараметрической статистике.

\begin{definition}
	\textit{Производная по Гато} функционала $G$ в точке $\mathsf{P}$ по направлению $\mathsf{Q}$ определяется как
	\[
	L_{\mathsf{P}}(\mathsf{Q}) = \lim_{\epsilon \to 0} \frac{G((1-\epsilon)\mathsf{P} + \epsilon\mathsf{Q}) - G(\mathsf{P})}{\epsilon}.
	\]
	\textit{Функцией влияния} функционала $G$ в точке $\mathsf{P}$ называют функцию $I_{\mathsf{P}}\colon x \mapsto L_{\mathsf{P}}(\delta_x)$.
\end{definition}

Таким образом, функция влияния, оправдывая своё название, показывает асимптотическое изменение оценки при появлении в выборке большого размера выброса $x$.

\subsection{Симметричные распределения}

% TODO Симметричные распределения


