\setcounter{problem}{0}
\section{Доверительные интервалы}

Конечно же, точечные оценки, которые мы составляли ранее, почти наверное не совпадут с истинным значением параметра. Но нам ведь этого и не надо: достаточно того, чтобы они различались не очень сильно. Можно подойти к этой проблеме иначе: локализовать параметр в некотором интервале, куда он попадёт с некоторой высокой фиксированной вероятностью.

\begin{definition}
    \textit{Доверительным интервалом уровня доверия $\gamma$} для параметра $\theta$ называется пара статистик $(T_1(X), T_2(X))$, такая, что для любого $\theta \in \Theta$
    \[
    \pth (T_1(X) < \theta < T_2(X)) \ge \gamma.
    \]
    Если выполнено равенство $\pth (T_1(X) < \theta < T_2(X)) = \gamma$, то доверительный интервал называется \textit{точным}.
\end{definition}

Не всегда получается легко построить такие интервалы, чтобы вероятность попадания в них была априори выше нужного числа. Но можно лишь потребовать, чтобы неравенство выполнялось в пределе, что в случае большой выборки не будет нас сильно ограничивать.

\begin{definition}
    Если
    \[
    \varliminf_{n \to \infty} \pth (T_1^{(n)}(X) < \theta < T_2^{(n)}(X)) \ge \gamma,
    \]
то $(T_1(X), T_2(X))$ называется \textit{асимптотическим доверительным интервалом уровня доверия $\gamma$}. Аналогично предыдущему определению, интервал называется $\textit{точным}$, если предел в точности равен $\gamma$.
\end{definition}

Хотя формально нет никаких условий на длину интервала, имеет смысл выбирать $T_1$, $T_2$ такими, чтобы длина интервала была как можно меньше, в частности, $T_2^{(n)}(X) - T_1^{(n)}(X)$ должно стремиться к 0 для всех $\theta$ (если это возможно).
Приведём два самых простых метода нахождения обычного и асимптотического доверительного интервала.

\textbf{Метод 1. Использование центральной статистики}

\begin{definition}
    Функция $G(\mathbf{x}, \theta)$ называется $\textit{центральной статистикой}$, если
    \begin{enumerate}
        \item распределение $G(X, \theta)$ не зависит от $\theta$ для всех $\theta \in \Theta$;
        \item при каждом $\mathbf{x} \in \R^n$ функция $g(\mathbf{x},\theta)$ непрерывна и строго убывает (возрастает) по $\theta$.
    \end{enumerate}
\end{definition}

Обозначим $p$-квантиль распределения $G(X,\theta)$ через $x_p$. Возьмем $0 \le p_1 < p_2 \le 1$ такие, что $p_2 - p_1 =\gamma$. Определим $T_1(x)$ и $T_2(x)$ как решения относительно $\theta$ соответственно уравнений $G(X,\theta) = x_{p_1}$ и $G(X,\theta) = x_{p_2}$. Наличие решения гарантируется определением выше. Тогда из монотонности $G(X, \theta)$ получаем, что $\pth(T_1(X) < \theta < T_2(X)) = \pth(x_{p_1} < G(X, \theta) < x_{p_2}) = p_2 - p_1 = \gamma.$ Удобно брать $p_2 = \frac{1+\gamma}{2}$ и $p_1 = \frac{1-\gamma}{2}$ (в таком случае интервал называется \textit{центральным}), особенно когда распределение $G(X, \theta)$ симметрично относительно начала координат.

В последних задачах мы познакомимся с универсальным способом построения центральной статистики для непрерывных распределений.

\textbf{Метод 2. Использование асимптотически нормальных оценок}

Допустим на нас с неба свалилась асимптотически нормальная оценка $\theta^*_n$, то есть $\sqrt{n}(\theta^*_n-\theta) \stackrel{d}{\to}\mathcal{N}(0, \sigma^2(\theta))$ при $n\to\infty$. Потребуем, чтобы асимптотическая дисперсия $\sigma^2(\theta)$ была положительна и непрерывна при всех $\theta \in \Theta$. Рассмотрим
\[
\frac{\sqrt{n}(\theta^*_n-\theta)}{\sigma(\theta^*_n)} = \frac{\sqrt{n}(\theta^*_n-\theta)}{\sigma(\theta)} \cdot \frac{\sigma(\theta)}{\sigma(\theta^*_n)}
\]
Первый множитель сходится к стандартно нормально распределённой случайной величине при $n \to \infty$. Разберёмся со вторым множителем. Так как $\theta^*_n$ асимптотически нормальна, то она состоятельна, то есть $\theta^*_n \stackrel{\pth}{\to} \theta$. Тогда из непрерывности асимптотической дисперсии $\sigma(\theta^*_n) \stackrel{\pth}{\to} \sigma(\theta)$, то есть $\frac{\sigma(\theta)}{\sigma(\theta^*_n)} \stackrel{\pth}{\to} 1$. Отсюда из леммы Слуцкого получаем, что всё произведение сходится к чему-то нормальному. Если обозначить за $x_p$ $p$-квантиль для $\mathcal{N}(0, 1)$, то из сходимости по распределению следует
\[
\pth\left(\theta^*_n -\frac{x_{(1+\gamma)/2} \sigma(\theta^*_n)}{\sqrt{n}} < \theta < \theta^*_n + \frac{x_{(1+\gamma)/2} \sigma(\theta^*_n)}{\sqrt{n}}\right) = \pth\left(\left|\sqrt{n}\cdot\frac{\theta^*_n - \theta}{\sigma(\theta^*_n)}\right| < x_{(1+\gamma)/2}\right) \to \gamma.
\]

Обратите внимание, что тут мы используем квантили с одинаковым индексом $x_{(1+\gamma)/2}$, но при этом знаки перед ними в левой и правой части неравенства разные. Правильным будет также написать интервал как
\[
\left(\theta^*_n -\frac{x_{(1+\gamma)/2} \sigma(\theta^*_n)}{\sqrt{n}}; \theta^*_n - \frac{x_{(1-\gamma)/2} \sigma(\theta^*_n)}{\sqrt{n}}\right),
\]
так как в силу симметричности распределения $x_{(1-\gamma)/2} = -x_{(1+\gamma)/2}$. Чаще всего для симметричных распределений мы будем расписывать интервалы через одинаковые квантили, потому что эстетически так красивее.

\begin{problem}
    По выборке из распределения $U(0, \theta)$ постройте точный доверительный интервал уровня доверия $\gamma$ для параметра $\theta$, границы которого являются функциями от $X_{(n)}$. Посчитайте асимптотику длины интервала при $n \to\infty$.
\end{problem}

\begin{solution}
    Рассмотрим функцию $G(X, \theta) = \frac{X_{(n)}}{\theta}$. Она будет центральной статистикой, поскольку для $t\in[0, 1]$ $\pth(G(X, \theta) \le t) = \pth(X_{(n)} \le t\theta) = \frac{(t\theta)^n}{\theta^n} = t^n$, а значит, её распределение не зависит от $\theta$. Из этого представления легко найти квантиль распределения: $x_p = \sqrt[n]{p}$. Таким образом,
    \[
    \pth\left(\frac{X_{(n)}}{\sqrt[n]{\frac{1+\gamma}{2}}} < \theta < \frac{X_{(n)}}{\sqrt[n]{\frac{1-\gamma}{2}}}\right) = \pth\left(\sqrt[n]{\frac{1-\gamma}{2}} < \frac{X_{(n)}}{\theta} < \sqrt[n]{\frac{1+\gamma}{2}}\right) = \gamma.
    \]
    Примем для простоты $\alpha = \frac{1-\gamma}{2}$, $\beta = \frac{1 + \gamma}{2}$. Длина интервала может быть высчитана как 
    \[
    X_{(n)}(\alpha^{-1/n} - \beta^{-1/n}) \approx \theta \left(1 - \frac{\ln{\alpha}}{n} - 1 + \frac{\ln{\beta}}{n}\right) = \frac{\theta}{n} \ln{\frac{\beta}{\alpha}}
    \]
\end{solution}

\begin{problem}
    По выборке из распределения Коши с плотностью $\rho_{\theta}(x) = \frac{1}{\pi(1 + (x - \theta)^2)}$ постройте точный асимптотический доверительный интервал для $\theta$ уровня доверия $\gamma$.
\end{problem}

\begin{solution}
    Как мы знаем, медиана $\mu$ для распределения Коши является асимптотически нормальной оценкой параметра $\theta$:
    \[
    \sqrt{n}(\mu - \theta) \stackrel{d}{\to} \mathcal{N}\left(0, \frac{1}{4\rho_{\theta}^2(\theta)}\right) = \mathcal{N}\left(0, \frac{\pi^2}{4}\right).
    \]
    Таким образом, по методу 2 мы получаем точный асимптотический доверительный интервал:
    \[
    \pth\left(\mu - \frac{x_{(1+\gamma)/2}\pi}{2\sqrt{n}} < \theta < \mu + \frac{x_{(1+\gamma)/2}\pi}{2\sqrt{n}}\right) \to \gamma,
    \]
    где $x_p$ -- $p$-квантиль для стандартного нормального распределения.
\end{solution}

\begin{problem}
    По выборке из распределения $\Gamma(\alpha, \gamma)$ постройте доверительный интервал уровня доверия $\gamma$ для параметра $\lambda$, если $\alpha$ известно.
\end{problem}

\begin{solution}
    Заметим, что если $X_i \sim \Gamma(\alpha, \lambda)$, то $\lambda X_i \sim \Gamma(\alpha, 1)$. Это значит, что $\lambda\sum X_i$ является центральной статистикой с распределением $\Gamma(n\alpha, 1)$. Поэтому 
    \[
    \pth[\lambda]\left(\frac{y_{(1-\gamma)/2}}{\sum X_i} < \lambda < \frac{y_{(1+\gamma)/2}}{\sum X_i}\right) = \gamma,
    \]
    где $y_p$ -- $p$-квантиль распределения $\Gamma(n\alpha, 1)$.
\end{solution}

\begin{problem}
    
Дана выборка из распределения $\mathcal{N}(a, \sigma^2)$.

\textbf{(а)} Проверьте, что $\frac{ns^2}{\sigma^2} \sim \chi^2(n-1)$.

\textbf{(б)} Найдите точную доверительную область уровня доверия $\gamma$ для вектора параметров $\theta = (a, \sigma^2)$.
\end{problem}

\begin{solution}
    \textbf{(а)} Представим $X_i = a + \sigma\xi_i$, где $\xi_i \sim \mathcal{N}(0, 1)$. Распишем выборочную дисперсию:
    \begin{gather*}
        \frac{ns^2}{\sigma^2} = \frac{1}{\sigma^2}\sum \left(X_i - \overline{X}\right)^2 = \frac{1}{\sigma^2}\sum \left(a+\sigma\xi_i - \overline{a + \sigma \xi}\right)^2 = \sum \left(\xi_i - \overline{\xi}\right)^2 =\\
    =\sum \xi_i^2 - \frac{1}{n}\left(\sum \xi_i\right)^2 = \sum \xi_i^2 - \left(\sum \frac{\xi_i}{\sqrt{n}}\right)^2.
    \end{gather*}
    
    \textbf{Способ I.} Докажем сперва следующее 
    \begin{proposition*}
        Если $\xi_1 \ind \xi_2$, и $\xi_1 \sim \chi^2(n)$, $\xi_1 + \xi_2 \sim \chi^2(n+m)$, то $\xi_2 \sim \chi^2(m)$.
    \end{proposition*}
    
    \begin{proof}
        Из свойства хар. функций: $\phi_{\xi_1}(t)\cdot \phi_{\xi_2}(t) = \phi_{\xi_1+\xi_2}(t)$, поэтому $\phi_{\xi_2}(t) = \frac{\phi_{\xi_1+\xi_2}(t)}{\phi_{\xi_1}(t)}$. Но так как $\chi^2(n) = \Gamma\left(\frac{n}{2}, \frac{1}{2}\right)$, то в равенство выше можно подставить хар. функцию от гамма-распределения (напомним, что для $\zeta\sim \Gamma(\alpha, \lambda)$ она равна $\phi_{\zeta}(t)=\left(1 - \frac{it}{\lambda}\right)^{-\alpha}$):
        \[
        \phi_{\xi_2}(t) = \frac{\left(1 - 2it\right)^{-\frac{n+m}{2}}}{\left(1 - 2it\right)^{-\frac{n}{2}}} = \left(1 - 2it\right)^{-\frac{m}{2}},
        \]
        что есть хар. функция для $\Gamma\left(\frac{m}{2}, \frac{1}{2}\right) = \chi^2(m)$. Значит, по теореме о единственности $\xi_2$ имеет в точности распределение $\chi^2(m)$.
    \end{proof}
    
    Осталось осознать, что $\eta = \left(\sum \frac{\xi_i}{\sqrt{n}}\right) \sim \mathcal{N}(0, 1)$ (а значит, $\eta^2 \sim \chi^2(1)$), $ns^2/\sigma^2 + \eta^2 = \sum \xi_i^2 \sim \chi^2(n)$, а $ns^2/\sigma^2 \ind \eta^2$ по задаче \ref{indep} из предыдущего листка.
    
    \textbf{Способ II.} Рассмотрим такую ортогональную матрицу $A$ (то есть $AA^T=1$), что первая её строчка равна $(\frac{1}{\sqrt{n}}, \ldots, \frac{1}{\sqrt{n}})$. Очевидно, этот вектор можно дополнить до ортонормированного базиса, а стало быть такая $A$ существует. Тогда $\eta = A\xi$, где $\xi=(\xi_1,\ldots, \xi_n)^T$ и $\eta=(\eta_1,\ldots, \eta_n)^T$, является гауссовым вектором с нулевым матожиданием и матрицей ковариаций $AEA^T=E$, то есть $\eta_i$ -- независимые и стандартно нормально распределены. При этом в силу ортогональности длина вектора не меняется, что есть $\sum \xi_i^2 = \sum \eta_i^2$. Таким образом, выборочная дисперсия выше перепишется как
    \[
    \frac{ns^2}{\sigma^2} = \sum_{i=1}^n \xi_i^2 - \left(\sum_{i=1}^n \frac{\xi_i}{\sqrt{n}}\right)^2 = \sum_{i=1}^n \eta_i^2 - \eta_1^2 = \sum_{i=2}^{n} \eta_i^2 \sim \chi^2(n-1).
    \]
    
    \textbf{(б)} Теперь у нас есть две статистики, распределения которых не зависят от вектора параметров $\theta$ -- это $\frac{ns^2}{\sigma^2} \sim \chi^2(n-1)$ и $\frac{\sqrt{n}(\overline{X} - a)}{\sigma} \sim \mathcal{N}(0, 1).$ Из задачи \ref{indep} предыдущего листка следует, что эти статистики будут независимыми, а стало быть вероятность попадания в окрестность этих статистик равна произведению вероятностей. Это и даёт нам нужную область:
    \begin{gather*}
    \gamma = \sqrt{\gamma}\sqrt{\gamma} = \pth\left(x_{(1-\sqrt{\gamma})/2} < \frac{\sqrt{n}(\overline{X} - a)}{\sigma} < x_{(1+\sqrt{\gamma})/2}\right) \pth\left(z_{(1-\sqrt{\gamma})/2} < \frac{ns^2}{\sigma^2} < z_{(1+\sqrt{\gamma})/2}\right) =\\
    =
    \pth\left(\overline{X} - \frac{\sigma x_{(1+\sqrt{\gamma})/2}}{\sqrt{n}} < a <\overline{X} + \frac{\sigma x_{(1+\sqrt{\gamma})/2}}{\sqrt{n}},\,\,\frac{ns^2}{z_{(1+\sqrt{\gamma})/2}} < \sigma^2 < \frac{ns^2}{z_{(1-\sqrt{\gamma})/2}}\right).
    \end{gather*}
\end{solution}

\begin{problem}\label{uniform}
    Дана выборка $X_1, \ldots, X_n$ из семейства распределений с непрерывными функциями распределения $F_{\theta}(x)$. Убедитесь, что
    \[
    G(X, \theta) = - \sum_{i=1}^n \ln{F_{\theta}(X_i)} \sim \Gamma(n, 1),
    \]
    и, как следствие, является центральной статистикой.
\end{problem}

\begin{solution}
    Убедимся, что $F_{\theta}(X_i)$ распределена как $U(0, 1)$.
    Для $t \notin (0, 1)$ равенство их функций распределения очевидно. Иначе
    \[
    \pth(F_{\theta}(X_i) \le t) = \pth(X_i \le F_{\theta}^{-1}(t)) = F_{\theta}(F_{\theta}^{-1}(t)) = t,
    \]
    где в качестве $F_{\theta}^{-1}(t)$ можно взять любую точку из прообраза $t$ при действии $F_{\theta}$ (он не пуст в силу непрерывности $F_{\theta}$). Под действием $\phi(t) = -\ln{t}$ распределение становится экспоненциальным. Действительно, если раньше $\rho(t) = I(0 < t < 1)$, то теперь плотность равна $\tilde \rho(x) = |(\phi^{-1}(x))'|\rho(\phi^{-1}(x)) = e^{-x}I(0 < e^{-x} < 1) = e^{-x}I(x > 0)$, то есть $-\ln{F_{\theta}(X_i)} \sim Exp(1) = \Gamma(1, 1)$. Отсюда $G(X, \theta)$ как сумма независимых случайных величин распределена как $\Gamma(n, 1)$.
\end{solution}

\begin{problem}
    Дана выборка из распределения $Pareto(\theta, 1)$, $\theta > 0$. Постройте точный доверительный интервал уровня доверия $\gamma$ для параметра $\theta$.
\end{problem}

\begin{solution}
    Просто применяем предыдущую задачу. Для распределения Парето функция распределения имеет вид $F_{\theta}(t) = 1 - t^{-\theta}$, $t \ge 1$. Для упрощения заметим, что $1-F_{\theta}(X_i)$ в силу симметричности распределена также равномерно на $[0, 1]$, поэтому статистика
    \[
    G(X, \theta) = - \sum_{i=1}^n \ln{(1-F_{\theta}(X_i))} = \theta \sum_{i=1}^n \ln{X_i}
    \]
    является центральной и распределена как $\Gamma(n, 1)$. Поэтому если принять $u_p$ за $p$-квантиль такого распределения, то
    \[
    \pth\left(\frac{u_{(1-\gamma)/2}}{\sum \ln{X_i}} < \theta < \frac{u_{(1+\gamma)/2}}{\sum \ln{X_i}}\right) = \pth\left(u_{(1-\gamma)/2} < G(X, \theta) < u_{(1+\gamma)/2} \right) = \gamma.
    \]
\end{solution}

