\section{Критерии однородности}\label{homogeneity}

Вообще говоря, критерии однородности проверяют нулевую гипотезу о том, правда ли, что две данные выборки пришли нам из одного и того же распределения. Впрочем, в этой главе будут рассмотрены и другие двухвыборочные критерии, которые проверяют равенство средних, дисперсий или медиан. Их объединяет умение проверять наличие эффекта: верно ли, что влияние некоторых факторов меняет распределение, или они не вносят существенного вклада в поведение наблюдаемых величин? Обычно нас будут интересовать следующие две ситуации:
\begin{enumerate}[label=]
    \renewcommand{\labelenumi}{\textbf{Ind}}
    \item\label{ind} Выборки $(X_1, \ldots, X_n)$ и $(Y_1, \ldots, Y_m)$ независимы;
    \renewcommand{\labelenumi}{\textbf{Rel}}
    \item\label{rel} Выборки $(X_1, \ldots, X_n)$ и $(Y_1, \ldots, Y_n)$ связаны, то есть $(X_1, Y_1), \ldots, (X_n, Y_n)$ --- независимые случайные векторы.
\end{enumerate}

Примером случая \ref{ind} могут служить выборки, которые описывают поведение некоторых метрик при A/B-тестировании, когда испытуемые делятся на две \textit{независимые} группы: контрольную и экспериментальную, причём над последней проводят некоторые преобразования (дают новый препарат, открывают доступ к новым возможностям приложения и т.д.), и критерий должен показать, имеет ли место быть влияние сего преобразования. Иллюстрацией случая \ref{rel} служат показатели \textit{одних и тех же} испытуемых, с которыми случилась некоторая метаморфоза между замерами: это может быть температура до и после принятия лекарства или успеваемость класса с течением времени. Также встречаются выборки, которые формально не связаны и могут иметь разный размер, но имеют зависимости. Например, результаты социологических опросов: не всегда спрашивают одних и тех же людей, но при этом среди них могут попадаться одинаковые.

Самым простым способом проведения теста на равенство средних является критерий Вальда, который ранее упоминался в разделе \ref{wald_test}. Напомним, что в его основе лежит асимптотически нормальная оценка некоторого параметра, который мы хотим проверить на равенство каком-то числу. В качестве такого параметра можно взять разность средних $\delta = \mu_1 - \mu_2$, где $\mu_1 = \me[]X_1$ и $\mu_2 = \me[]Y_1$, то есть проверяется гипотеза
\[
H_0\colon \delta = \mu_1 - \mu_2 = 0 \vs H_1\colon \delta \ne 0.
\]
В частности,
\begin{itemize}
    \item В случае \ref{ind} в качестве оценки параметра $\delta$ можно взять $\widehat{\delta} = \widehat{\mu}_1 - \widehat{\mu}_2$, где, предсказуемо, $\widehat{\mu}_1 = \overline{\mathbf X}$ и $\widehat{\mu}_2 = \overline{\mathbf Y}$. В силу независимости выборок дисперсия такой оценки равна 
    \[
    \va[]\widehat{\delta} = \va[]\widehat{\mu}_1 + \va[]\widehat{\mu}_2 = \frac{\va[]X_1}{n} + \frac{\va[]Y_1}{m},
    \]
    причём $\va[]X_1$ и $\va[]Y_1$ оцениваются с помощью несмещённых выборочных дисперсий $S^2(\mathbf X)$ и $S^2(Y)$ соответственно. Таким образом, имеется сходимость
    \[
    W(\mathbf X, \mathbf Y) = \frac{\overline{\mathbf X} - \overline{\mathbf Y}}{\sqrt{\frac{S^2(\mathbf X)}{n} + \frac{S^2(\mathbf Y)}{m}}} \stackrel{d}{\longrightarrow} \mathcal{N}(0, 1)
    \]
    и асимптотический критерий на уровне значимости $\alpha$
    \[
    R_{\alpha} = \left\{(\mathbf{x}, \mathbf{y})\colon \left|W(\mathbf{x}, \mathbf{y})\right| \ge z_{1-\alpha/2} \right\}.
    \]
    Напомним также о возможности модификации данного теста для односторонней альтернативы. Например, если $H_0$ проверяется против $H_2\colon \delta > 0$ (то есть рассматривается возможность только лишь увеличения среднего), критерий на уровне значимости $\alpha$ будет иметь вид $R_{\alpha}' = \left\{(\mathbf{x}, \mathbf{y})\colon W(\mathbf{x}, \mathbf{y}) \ge z_{1-\alpha}\right\}$.
    \item В случае \ref{rel} логично рассмотреть величины $D_i = X_i - Y_i$: для $i$-ого испытуемого она показывает изменение в наблюдаемой метрике. При верности гипотезы $H_0$ имеем $\me[]D_i = \me[]X_i - \me[]Y_i = \mu_1 - \mu_2 = 0$, поэтому в качестве оценки $\delta$ можно взять $\overline{\mathbf D}$. Дисперсия такой оценки по независимости испытуемых равна $n^{-1}\va[]D_1$, которую можно оценить несмещённой выборочной дисперсией $S^2(\mathbf D)$. Итого, получается следующий асимптотический критерий уровня значимости $\alpha$ для проверки $H_0$ против $H_1$:
    \[
    R_{\alpha} = \left\{\sqrt{n}\cdot\left|\frac{\overline{\mathbf D}}{S^2(\mathbf D)}\right| \ge z_{1-\alpha/2}\right\}.
    \]
\end{itemize}

Такой способ крайне прост, однако обладает лишь асимптотическими свойствами, и возможно в конкретной ситуации будет иметь крайне большие вероятности ошибок I и II рода. Далее в этой главе мы опишем более мощные критерии.

\subsection{Тесты для нормальных выборок}\label{ttest}

Статистики критериев Вальда, которые были рассмотрены выше, можно немного видоизменить, уточнив их распределение, если сделать допущение о нормальности наших данных. Будем работать в парадигме \ref{ind}, а также добавим, что $(X_1, \ldots, X_n)$ есть выборка из $\mathcal{N}(\mu_1, \sigma^2)$, а $(Y_1, \ldots, Y_m)$ --- выборка из $\mathcal{N}(\mu_2, \sigma^2)$, то есть параметры сдвига и масштаба нам неизвестны, но мы знаем, что данные распределены нормально и с одинаковой дисперсией. Проверим гипотезу
\[
H_0\colon \mu_1 = \mu_2 \vs H_1\colon\mu_1 \ne \mu_2.
\]

При верности основной гипотезы $\overline{\mathbf X} - \overline{\mathbf Y} \sim \mathcal{N}(0, \sigma^2(1/n + 1/m))$, то есть
\begin{equation}\label{ttest_mean}
    \sqrt{\frac{nm}{n+m}}\cdot \frac{\overline{\mathbf X} - \overline{\mathbf Y}}{\sigma} \sim \mathcal{N}(0, 1).
\end{equation}

Воспользуемся идеей раздела \ref{norm_intervals}, где похожую случайную величину мы делили на корень из оценки дисперсии, чтобы неизвестная $\sigma$ сократилась, а полученное отношение имело распределение Стьюдента. Выборочные дисперсии $s^2(\mathbf X)$ и $s^2(\mathbf Y)$ независимы как функции от независимых выборок, поэтому $ns^2(\mathbf X)/\sigma^2$ и $ms^2(\mathbf Y)/\sigma^2$, как величины с распределением хи-квадрат, в сумме дают
\begin{equation}\label{ttest_var}
    \frac{ns^2(\mathbf X) + ms^2(\mathbf Y)}{\sigma^2} \sim \chi^2_{n+m-2}.
\end{equation}
Выборочные среднее и дисперсия для разных выборок, очевидно, независимы, как и для одной выборки, что было показано в примере \ref{ind_of_stat_for_norm}. Таким образом, величины из \eqref{ttest_mean} и \eqref{ttest_var} независимы, поэтому
\begin{equation}\label{t-statistic-two-sample}
	T(\mathbf X, \mathbf Y) = \sqrt{\frac{nm}{n+m}}\cdot \frac{\overline{\mathbf X} - \overline{\mathbf Y}}{S} \sim T_{n+m-2},\text{   где   } S = \sqrt{\frac{ns^2(\mathbf X) + ms^2(\mathbf Y)}{n+m-2}}.
\end{equation}
\textit{t-критерий}, основанный на сей статистике, будет иметь вид
\[
R_{\alpha} = \left\{(\mathbf{x}, \mathbf{y})\colon |T(\mathbf{x}, \mathbf{y})| \ge T_{n+m-2,1-\alpha/2}\right\}.
\]
Как можно заметить, в ходе рассуждений существенно используется равенство дисперсий, что не всегда получается знать априори. Первый вариант решения проблемы заключается в проверке гипотезы равенства дисперсий. Пусть независимы выборки $\mathbf X$ и $\mathbf Y$ пришли из распределения $\mathcal{N}(\mu_1, \sigma_1^2)$ и $\mathcal{N}(\mu_2, \sigma_2^2)$ соответственно, проверим гипотезу $H_0\colon \sigma_1 = \sigma_2$. Воспользуемся независимыми статистиками $ns^2(\mathbf X)/\sigma^2_1 \sim \chi^2_{n-1}$ и $ms^2(\mathbf Y)/\sigma^2_2 \sim \chi^2_{m-1}$. При верности нулевой гипотезы дисперсии равны, поэтому если мы поделим одно на другое, то неизвестная $\sigma$ сократится. Полученное распределение имеет специальное название, в честь которого назван и сам критерий.
\begin{definition}
Пусть независимые случайные величины $\xi$ и $\eta$ таковы, что $\xi \sim \chi^2_{a}$, $\eta \sim \chi^2_{b}$, где $a, b\in \N$. Тогда говорят, что случайная величина
\[
\zeta = \frac{\xi / a}{\eta / b}
\]
имеет \textit{распределение Фишера со степенями свободы $a$ и $b$}. Обозначается $\zeta \sim F_{a, b}$
\end{definition}
Итого, получаем
\[
\frac{\frac{n}{n-1}\cdot s^2(\mathbf X)}{\frac{m}{m-1}\cdot s^2(\mathbf Y)} = \frac{S^2(\mathbf X)}{S^2(\mathbf Y)} \sim F_{n-1,m-1},
\]
где $S^2$ --- несмещённая оценка дисперсии. На основании этой статистики можно построить так называемый \textit{F-критерий Фишера}, который имеет вид
\[
R_{\alpha} = \left\{(\mathbf{x}, \mathbf{y})\colon \frac{S^2(\mathbf{x})}{S^2(\mathbf{y})} \in (f_{\alpha/2}, f_{1-\alpha/2})\right\},
\]
где $f_p$ --- $p$-квантиль распределения $F_{n-1,m-1}$.

Если же сей критерий отверг нулевую гипотезу, то можно воспользоваться \textit{критерием Аспина-Уэлча}, который чуть менее мощный, чем $t$-критерий выше. Теперь уже выборки $\mathbf X$ и $\mathbf Y$ приходят из распределения $\mathcal{N}(\mu_1, \sigma_1^2)$ и $\mathcal{N}(\mu_2, \sigma_2^2)$ соответственно, то есть дисперсии могут различаться. Во главе критерия стоит статистика
\[
W(\mathbf X, \mathbf Y) = \frac{\overline{\mathbf X} - \overline{\mathbf Y}}{\sqrt{\frac{S^2(\mathbf X)}{n} + \frac{S^2(\mathbf Y)}{m}}},
\]
которая встречалась нам ранее в критерии Вальда. Если $H_0\colon \mu_1 = \mu_2$ верна, то эта статистика приблизительно распределена как $T_K$, где
\begin{equation}\label{k_for_aw}
    K = \left(\frac{S^2(\mathbf X)}{n} + \frac{S^2(\mathbf Y)}{m}\right)^2 \cdot \left(\frac{S^4(\mathbf X)}{n^2(n-1)} + \frac{S^4(\mathbf Y)}{m^2(m-1)}\right)^{-1}.
\end{equation}

Откуда появляется такое причудливое число степеней свобод? Причина в следующем: по аналогии с $t$-критерием нам хотелось бы представить статистику $W(\mathbf X, \mathbf Y)$ как отношение $\mathcal{N}(0, 1)$ к $\sqrt{\chi^2_K/K}$ для некоторого $K$. Если нормировать числитель, получится
\[
W(\mathbf X, \mathbf Y) = \underbrace{\frac{\overline{\mathbf X} - \overline{\mathbf Y}}{\sqrt{\sigma^2_1/n + \sigma^2_2/m}}}_{\sim \mathcal{N}(0, 1)} \left/ \sqrt{\lefteqn{\phantom{\frac{S^2(\mathbf X)/n + S^2(\mathbf Y)/m}{\sigma^2_1/n + \sigma^2_2/m}}} \smash{\underbrace{\frac{S^2(\mathbf X)/n + S^2(\mathbf Y)/m}{\sigma^2_1/n + \sigma^2_2/m}}_{\approx \chi^2_K/K?}}}\right. .
\]
В связи с таким представлением нужно подобрать параметр $K$ таким образом, чтобы выделенная статистика максимально сильно походила на $\chi^2_K/K$. Так как с ростом степеней свободы хи-квадрат становится всё больше похожим на нормальное, то достаточно приравнять их среднее и дисперсию, что уже даст достаточно точное приближение. Их средние и так совпадают, так как $S^2(\mathbf X)$ и $S^2(\mathbf Y)$ несмещённо оценивают $\sigma^2_1$ и $\sigma^2_2$ соответственно. Приравнивание дисперсий и решение полученного уравнения дадут нам выражение $K$ через параметры $\sigma^2_1$ и $\sigma^2_2$, что при замене на их состоятельные оценки приводит к статистике~\eqref{k_for_aw}.

\subsection{Предположение нормальности/независимости и метод бакетов}

Изложенное выше может показаться совершенно бесполезным, так как довольно редко встречаются выборки, распределённые непременно нормально. Однако, несмотря на сей факт, данное предположение часто допускают и всё равно используют критерий Стьюдента и иже с ним. Отчего же так?

	Если коротко, то всему виной ЦПТ: для большого объёма данных в силу предельных теорем выборочные характеристики распределены почти что нормально, отчего многие результаты выше остаются в силе. Тем более распределение Стьюдента, в соответствии с коим распределена статистика $t$-критерия, с ростом $n$ приближается к нормальному, и критерий вырождается в обычный критерий Вальда, который справедлив в куда большем числе случаев.
	
	Впрочем, и для малых $n$ стьюдентовское приближение порой бывает состоятельным. Если говорить опять неформально, то распределение Стьюдента, в отличие от нормального, обладает <<тяжёлыми хвостами>>, что вполне характерно для суммы случайных величин с распределением, отличным от нормального.
	
	Чуть более строго, присмотримся внимательно к статистике (\ref{t-statistic-two-sample}). Чтобы она имела распределение Стьюдента, необходимы три вещи: 1) распределение числителя нормально; 2) распределение содержимого корня в знаменателе есть хи-квадрат; 3) числитель и знаменатель независимы. В асимптотическом плане первые два пункта гарантирует ЦПТ, ведь выборочные среднее и дисперсия асимптотически нормальны, а хи-квадрат с ростом степеней свобод само по себе почти что нормально. Третий пункт даже асимптотически верен не всегда, но в широком наборе случае и он имеет место (см. задачу \ref{emp_mean_and_var_are_almost_ind}). Таким образом, даже в отсутствии честной нормальности данных использование $t$-критерия бывает предпочтительнее обычного критерия Вальда.
	
	Куда более опасным и незаметным 

% \subsection{Ранговые и знаковые критерии}

% TODO Ранговые критерии

% To be continued...

\subsection{Модернизации критериев согласия}

Видоизменив критерии согласия, озвученные в параграфе \ref{simple_goodness_of_fit_tests}, можно получить аналогичные критерии, проверяющие гипотезу о равенстве двух распределений против общей альтернативы в случае \ref{ind}. Здесь мы приведём краткую сводку.

\paragraph{Критерий Колмогорова-Смирнова} в качестве статистики рассматривает наибольшее отклонение у двух эмпирических распределений:
\[
D_{n, m}(\mathbf X, \mathbf Y) = \sup_{z \in \R} |\widehat{F}_n(z) - \widehat{G}_m(z)|,
\]
где $\widehat{F}_n$ и $\widehat{G}_m$ --- эмпирические функции распределения, построенные по независимым выборкам $\mathbf X = (X_1, \ldots, X_n)$ и $\mathbf Y = (Y_1, \ldots, Y_m)$ соответственно. Как и в теореме Колмогорова, можно найти предельное распределение данной статистики, определив тем самым асимптотический критерий.

\begin{theorem}{}{}
	Пусть $F$ и $G$ --- непрерывные распределения, из которых пришли выборки $\mathbf X$ и $\mathbf Y$ соответственно. Тогда
	\[
	\sqrt{\frac{nm}{n+m}} \cdot D_{n, m}(\mathbf X, \mathbf Y) \stackrel{d}{\longrightarrow} K, \;\;\;n, m \to \infty,
	\]
	где $K$ --- распределение Колмогорова, определяемое функцией распределения \eqref{kolmogorov_cdf}.
\end{theorem}

Таким образом, в условиях теоремы имеется критерий уровня значимости $\alpha$ вида
\[
R_{\alpha} = \left\{(\mathbf x, \mathbf y)\colon \sqrt{\frac{nm}{n+m}} \cdot D_{n, m}(\mathbf x, \mathbf y) > k_{1-\alpha}\right\},
\]
который реализован в функции \href{https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.ks\_2samp.html}{\texttt{scipy.stats.ks\_2samp}}.

\paragraph{Критерий Розенблатта} же является модернизацией критерия Крамера-фон Мизеса-Смирнова, в котором рассматривается $L_2$-норма разности распределений. Только если в оригинальном критерии интеграл брался по теоретическому распределению, то в этот раз берётся эмпирическое совместное распределение: каждому наблюдению в двух выборках приписывается вес $\frac{1}{n+m}$. Формально такую функцию распределения можно записать так:
\[
\widehat{H}_{n,m}(x) = \frac{n}{n+m}\widehat{F}_n(x) + \frac{m}{n+m}\widehat{G}_m(x).
\]

Статистика критерия имеет вид
\[
\omega^2_{n,m}(\mathbf X, \mathbf Y) = \int_{\R} \left(\widehat{F}_n(x) - \widehat{G}_m(x)\right)^2\,d\widehat{H}_{n,m}(x).
\]

При верности нулевой гипотезы $H_0\colon F = G$ и $n, m \to \infty$ статистика $\frac{nm}{n+m}\omega^2_{n,m}$ стремится к распределению $F_1$ из раздела \ref{omega2_tests}, к которому стремится и статистика критерия Крамера-фон Мизеса-Смирнова. В классических библиотеках данный критерий не реализован, поэтому полезной будет следующая альтернативная формула для статистики критерия:
\begin{equation}\label{alternative_formula_for_rosenblatt}
	\omega^2_{n,m}(\mathbf X, \mathbf Y) = \frac{1}{nm}\left(\frac{1}{6} + \frac{1}{m}\sum_{i=1}^n (R_i - i)^2 + \frac{1}{n}\sum_{j=1}^m (S_j - j)^2\right) - \frac{2}{3},
\end{equation}
где $R_i$ и $S_j$ --- ранги наблюдений $X_{(i)}$ и $Y_{(j)}$ в объединённом вариационном ряду.

\paragraph{Критерий Андерсона-Дарлинга} устроен несколько по-другому: он берёт не отклонение эмпирических распределений между собой, а отклонение каждого из них от совместного эмпирического распределения. Это позволяет обобщить задачу на случай нескольких выборок. Конкретнее, рассмотрим $k$ независимых выборок $\mathbf X_1, \ldots, \mathbf X_k$ размера $n_1, \ldots, n_k$ соответственно. Пусть $\widehat F_{i}$ --- эмпирическая функция распределения, построенная по $\mathbf X_i$, а $\widehat H$ --- по совокупности всех выборок. Введём статистику
\[
\Omega^2(\mathbf X_1, \ldots, \mathbf X_k) = \sum_{i=1}^k n_i \int_{A} \frac{(\widehat F_i(x) - \widehat H(x))^2}{\widehat H(x)(1-\widehat H(x))} \, d\widehat H(x),
\]
где $A = \{x\colon H(x) < 1\}$, чтобы интеграл был конечным. При верности гипотез, что все распределения выборок одинаковы, с ростом $n_i$ распределение статистики $\Omega^2$ стремится к некоторому фиксированному распределению. Не будем опять же вдаваться в подробности его устройства, ведь для проверки гипотезы имеется удобная функция \href{https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.anderson\_ksamp.html}{\texttt{scipy.stats.anderson\_ksamp}}.

\paragraph{Критерий однородности $\chi^2$} можно получить как частный случай параметрического критерия $\chi^2$ или критерия отношения правдоподобий, остановимся на первом варианте.

Пусть всё также имеется $k$ независимых выборок $\mathbf X_1, \ldots, \mathbf X_k$ из категориальной модели, то есть наблюдения принадлежат некоторому дискретному множеству $\{1, \ldots, m\}$. В общем случае для каждой выборки вероятность выпадения конкретного признака своя, а именно $p_{ij} = \pth[](X_{i1} = j)$. Вектор параметров модели $\{p_{ij}\}_{i=1,\ldots, k}^{j=1, \ldots, m}$ полностью описывается $m-k$ числами $p_{ij}$, $i=1,\ldots, k-1$, $j=1,\ldots, m$, так как величины $p_{kj}$ однозначно восстанавливаются по остальным вероятностям. Таким образом, общее пространство параметров имеет размерность $m(k-1)$.

Нулевая гипотеза $H_0$ же состоит в том, что на самом деле $p_{1j} = p_{2j} = \ldots = p_{kj}$ для всех $j=1,\ldots, m$. В таком случае множество параметров имеет размерность $k-1$, так как $p_{11}, \ldots, p_{1(k-1)}$ можно взять произвольными, а остальные $p_{ij}$ выражаются через них. Таким образом, статистика \eqref{complex_chi2} параметрического критерия $\chi^2$ будет сходится к распределению хи-квадрат с $\dim(\Theta) - \dim(\Theta_0) = (mk-m)-(k-1) = (m-1)(k-1)$ степенями свободы.

ОМП для параметров модели при верности $H_0$ находится довольно просто: функция правдоподобия в таком случае будет равна
\[
f(\mathbf x_1, \ldots, \mathbf x_k) = \prod_{i=1}^k\prod_{j=1}^m p_{ij}^{\nu_{ij}} = \prod_{j=1}^m p_{1j}^{\nu_{\bullet j}},
\]
где $\nu_{ij}$ --- количество признаков $j$ в реализации выборки $\mathbf x_i$, $\nu_{\bullet j} = \sum_i \nu_{ij}$. Максимизируя полученную функцию, получаем оценки $\widehat p_{ij} = \nu_{\bullet j} / n$, где $n = \sum_j \nu_{\bullet j}$ --- общее количество элементов в выборках. Итого, статистика примет вид
\[
\chi^2(\mathbf X_1, \ldots, \mathbf X_k) = \sum_{i=1}^k \sum_{m=1}^j \frac{(\nu_{ij} - \nu_{i\bullet} \widehat{p}_{ij})^2}{\nu_{i\bullet} \widehat{p}_{ij}} = \sum_{i=1}^k \sum_{m=1}^j \frac{(\nu_{ij} - \nu_{i\bullet} \nu_{\bullet j} / n)^2}{\nu_{i\bullet} \nu_{\bullet j} / n},
\]
где $\nu_{i\bullet} = \sum_j \nu_{ij}$ --- количество наблюдений в $i$-ой выборке. Заметим, что и статистика, и её предельный закон совпадает с аналогичной статистикой \eqref{chi2_contingency_stat} для проверки коррелированности двух признаков: здесь роль второго признака играет номер выборки, из которого пришло наблюдение. Дополнительное удобство ещё и в том, что для проверки можно использовать ту же самую библиотечную функцию.

\begin{example}
	Весной 2024 года на курсе мат. логики Даниил Владимирович по объективным причинам задержал выдачу последнего домашнего задания и выдал его в канун экзаменов. Многим студентам показалось, что это негативно скажется на его решаемости, а стало быть и на итоговых результатах семестра. Проверим это статистически.
	
	Возьмём \href{https://docs.google.com/spreadsheets/d/1z4qx7f4orruuMmBidFwpLw7IWZ3LgdYEI9zYjj71T_0/edit?usp=sharing}{табличку} с ведомостью, нас будет интересовать распределение итоговых баллов (целое число от 0 до 4) за 2024 и 2023 года (ранние данные брать не будем, потому что тогда оценка была от 0 до 3). Запишем данные в таблицу сопряжённости:
	\begin{center}
		\begin{tabular}{|c|c|c|c|c|c|}
		\hline
			Год {\textbackslash} Кол-во баллов & 0 & 1 & 2 & 3 & 4\\
			\hline
			2023 & 32 & 63 & 64 & 25 & 18\\
			\hline
			2024 & 17 & 63 & 49 & 31 & 13\\
			\hline
		\end{tabular}
	\end{center}
	
	Проверим на уровне значимости $0.05$ гипотезу о том, что распределение не поменялось. Вызовем соответствующую функцию и посмотрим на pvalue.
	\begin{minted}{python}
arr = np.array([
    [32, 63, 64, 25, 18],
    [17, 63, 49, 31, 13]
])
sps.chi2_contingency(arr).pvalue
	\end{minted}
	\begin{lstlisting}
0.21264668380037094
	\end{lstlisting}
	
	Фактический уровень значимости оказался недостаточно малым, поэтому можно сделать вывод о том, что нет статистически значимых отличий между распределениями баллов разных годов.
\end{example}

\subsection*{Задачи}

\begin{problem}
	Докажите состоятельность критерия Колмогорова-Смирнова для общей альтернативы $H_1\colon F \ne G$.
\end{problem}

\begin{problem}
	Докажите формулу \eqref{alternative_formula_for_rosenblatt}.
\end{problem}



