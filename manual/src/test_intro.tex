\section{Введение в теорию проверки гипотез}

На практике часто возникает необходимость делать выводы о неизвестном распределении, из которого пришла наблюдаемая выборка. Рассмотрим некоторые примеры.
\begin{itemize}
    \item Вы исследуете на работоспособность некоторое лекарство. Для этого вы предлагаете больным принять его и смотрите, как поменялись показатели здоровья у испытуемых (температура, давление и т.д.). Нужно понять, есть ли эффект от лекарства: достаточно ли сильно поменялись эти показатели, чтобы судить о действенности средства?
    \item Вы разработчик приложения, который хочет привнести некоторое нововведение, и вам нужно понять, не ломает ли оно его работу. Для измерения качества приложения имеется множество метрик (например, среднее время сессии, частота клика на определённый элемент и т.д.), которые крайне желательно не ухудшать. Для этого проводится так называемое \textit{AB-тестирование}, при котором часть пользователей (тестовая, экспериментальная выборка) получает новую функциональность, а у другой части (контрольной выборки) всё остаётся по-старому. Вам известны значения метрик у обеих выборок, и необходимо понять, есть ли значимые отличия между ними (в худшую сторону), или можно предположить, что разница не так велика?
    \item Вы аналитик поиска, который борется с так называемым <<фродом>>. Мошенники могут с помощью ботов задавать одни и те же запросы в поисковике, чтобы увеличить трафик своего сомнительного сайта. Можно предположить, что распределения по времени у обычного частотного запроса и спама отличаются: первый задаётся равномерно, а второй -- примерно в одно и то же время залпом (крайне идеализированная картина, взято для примера). Отсюда появляется потребность для каждого частотного запроса в проверке гипотезы о том, что распределение по времени запроса равномерное.
\end{itemize}

Во всех этих ситуациях имеется некоторое предположение относительно неизвестного распределения, и ему зачастую в противовес даётся альтернатива, относительно которой нужно проверить состоятельность основного предположения: либо оно допустимо (модель из нулевой гипотезы достаточно хорошо описывает данные), либо есть серьёзные основания считать его неверным (значения наблюдений нетипичны для такой модели). Задача сего раздела --- математически строго формализовать процесс принятия решения о том, отвергать ли выдвигаемую гипотезу или нет.

\begin{definition}
\textit{Статистической гипотезой} $H$ называют предположение о принадлежности истинного распределения $\pth[]$ некоторому классу $\mathcal{P}$. Обозначается как $H\colon \pth[] \in \mathcal{P}$.
\end{definition}

Часто класс распределений задаётся некоторыми параметрами:
$\mathcal{P} = \{\pth\colon \theta \in \Theta\}$. В таком случае гипотезу можно сформулировать в терминах принадлежности некоторому подмножеству $\Theta_0 \subset \Theta$, что записывается как $H_0 \colon \theta \in \Theta_0$.

Предположим, что истинное распределение данных лежит в некотором семействе распределений $\mathcal{P}$, в котором имеются два непересекающихся подмножества $\mathcal{P}_0$ и $\mathcal{P}_1$ -- это и есть наши догадки. Мы подвергаем сомнению, что имеет место принадлежность к классу $\mathcal{P}_0$, и в качестве противовеса берём класс $\mathcal{P}_1$.

\begin{definition}
В таком случае гипотеза $H_0\colon \pth[] \in \mathcal{P}_0$ называется \textit{основной (нулевой) гипотезой}, а гипотеза $H_1\colon \pth[] \in \mathcal{P}_1$ --- \textit{альтернативой}. Обозначается как
\[
H_0\colon \pth[] \in \mathcal{P}_0 \vs H_1\colon \pth[] \in \mathcal{P}_1.
\]
\end{definition}

\begin{remark}
	Далеко не всегда стоит брать гипотезы такие, что $\mathcal{P}_0 \sqcup \mathcal{P}_1 = \mathcal{P}$. Это может быть вызвано отсутствием интереса к некоторым альтернативам или желанием найти более оптимальные способы проверки гипотезы: во многих ситуациях лучше хорошо отклонять основную гипотезу в частных случаях, чем отклонять средне при всех возможных.
\end{remark}

Очевидно, принятие решения о том, отвергать ли $H_0$ или нет, должно зависеть только от реализации выборки $\mathbf X$, поэтому выбор определяется некоторым измеримым множеством $R \subset \mathcal{X}$, при попадании в которое мы должны отвергнуть основную гипотезу:
\[
\begin{aligned}
\mathbf X \in R &\Longrightarrow \text{ отвергаем } H_0\\
\mathbf X \notin R &\Longrightarrow \text{ не отвергаем } H_0.
\end{aligned}
\]

\begin{definition}
Множество $R$, попадание в которое равносильно отвержению основной гипотезы, называется \textit{критическим} или \textit{критерием}.
\end{definition}

Зачастую, это множество можно задать как прообраз луча для некоторой статистики:
\[
R = \{\mathbf{x} \in \R^n\colon T(\mathbf{x}) \ge c\}.
\]
В таком случае $T(\mathbf X)$ называется \textit{статистикой критерия}, а порог $c$ --- \textit{критическим значением}. Тогда отвержение основной гипотезы равносильно выполнению $T(\mathbf X) \ge c$, то есть принятию статистикой критерия слишком экстремального значения, не свойственного основной гипотезе.

Важно подчеркнуть, что <<не отвергаем>> и <<безоговорочно принимаем>> $H_0$ --- разные вещи. Если мы не смогли найти весомый довод против основной гипотезы, то это вовсе не значит, что она верна. Возможно, это не так, но из-за каких-то причин (плохой критерий, неудачная выборка и т.д.) мы не смогли её отвергнуть. Надо помнить, что \textit{наша ключевая цель -- найти весомые косвенные доказательства неверности $H_0$ в пользу $H_1$}, а если таковых не нашлось, то мы либо принимаем гипотезу на веру (куда деваться?), либо подбираем другие критерии в надежде её опровергнуть. Удачное сравнение можно встретить в книге \cite{wasserman}: основная гипотеза своего рода <<подсудимый>>, и по презумпции невиновности она считается невиновной, то есть верной. Тогда проверка гипотезы есть судебный процесс, на котором мы играем роль прокурора. Наша задача --- найти доказательства против $H_0$ в лице <<потерпевшей>> $H_1$. Если мы их не обнаружили, это не значит, что $H_0$ и вправду <<невиновна>>.

Отметим ещё одну особенность процедуры проверки гипотез. Хотя формально постановка задачи симметрична, часто мы подразумеваем неравнозначность гипотез. Это можно проиллюстрировать следующим хрестоматийным примером.

\begin{example}
Предположим, что вы работаете в госпитале и проводите анализы на присутствие в организме раковых клеток. По сути, вы по реализации выборки из различных показателей (кровь, рентген, МРТ и т. д.) должны проверить гипотезу $H_0\colon\textit{пациент болен раком}$ против альтернативы $H_1\colon\textit{пациент здоров}$. Если вы верно поставили диагноз, то всё хорошо. Иначе вы можете совершить одну из двух ошибок:

\begin{center}
    \begin{tabular}{|c|c|c|}
\hline
 & Принимаем $H_0$ & Отвергаем $H_0$\\
\hline
$H_0$ верна& Мы молодцы! & Ошибка I рода\\
\hline
$H_1$ верна& Ошибка II рода & Мы молодцы!\\
\hline
\end{tabular}
\end{center}

В случае \textit{ошибки I рода} вы не окажете помощь больному человеку и обречёте его на смерть, а в случае \textit{ошибки II рода} вы будете лечить здорового и потеряете много денег. Обе ситуации неприятны, но с точки зрения морали первая куда хуже. Выбор гипотезы о том, что пациент болен, в качестве основной, а не наоборот, согласуется со сказанным выше: мы стараемся найти действительно убедительные свидетельства того, что пациент здоров (то есть неверна $H_0$), ибо в случае беспочвенного опровержения верной гипотезы мы буквально похороним пациента, и если таковых нет, то мы (может и с некоторым скепсисом) примем её. Впрочем, в других задачах может представляться логичным минимизировать ошибку II рода, что зависит от предметной области.

Можно привести и такой пример: как известно, законы Ньютона не являются исчерпывающим описанием Вселенной и не работают корректно как в макро-, так и в микромире, то есть гипотеза $H\colon\textit{Выполняются законы Ньютона }$ неверна, при этом её часто принимают на веру. Это происходит не из-за того, что физики глупые, а потому что она вполне допустима для несложных физических моделей. Так и в общем случае: если гипотеза достаточно хорошо описывает происходящее, то её можно принять, даже несмотря на то, что в действительности она неверна. 
\end{example}

Как же понять, когда критерий хороший, а когда не очень? Полезной можно найти следующую характеристику:
\begin{definition}
\textit{Функцией мощности критерия $R$} называется функция $$\beta(\pth[], R) = \pth[](\mathbf X \in R).$$
\end{definition}

Понятно, что в случае верности основной гипотезы $H_0$ (то есть когда $\pth[] \in \mathcal{P}_0$) вероятность попадания в критическое множество должна быть низкой, а если верна $H_1$ -- как можно больше. Возникает вопрос -- как минимизировать одно и максимизировать другое? В контексте примера выше более верным представляется следующий подход: сначала надо поставить некое маленькое заранее оговоренное ограничение сверху на функцию мощности для $\pth[] \in \mathcal{P}_0$, чтобы вероятность ошибки I рода была меньше фиксированного числа. В связи с этим важным является следующее
\begin{definition}
\textit{Размером критерия R} называется
\[
\sup_{\pth[] \in \mathcal{P}_0} \beta(\pth[], R).
\]
Говорят, что критерий $R$ \textit{имеет уровень значимости $\alpha$}, если его размер не превышает $\alpha$.
\end{definition}

Обычно в качестве $\alpha$ берут число 0.05, то есть в таком случае мы позволяем себе ошибку I рода в $5\%$, однако в разных отраслях используют и другие, меньшие уровни значимости в зависимости от того, насколько катастрофичны последствия ошибки I рода.

Отныне мы работаем с критериями, у которых можно явно задать уровень значимости $\alpha$. Среди таковых надо подобрать критерий с как можно меньшей ошибкой II рода, то есть с максимальной функцией мощности. Тут, как это было при сравнении оценок, возникает проблема сравнения двух функций (как понять, какая лучше?). Возможное решение аналогично: уметь сравнивать только те критерии, мощность одного из которых мажорирует мощность другого.

\begin{definition}
Говорят, что \textit{критерий $R_1$ мощнее критерия $R_2$}, если $\forall \pth[] \in \mathcal{P}_1\colon \beta(\pth[], R_1) \ge \beta(\pth[], R_2)$.
\end{definition}

Также бывает полезным проверять потенциальный критерий на наличие следующих естественных свойств.
\begin{definition}
Критерий $R$ для проверки
\[
H_0\colon \pth[] \in \mathcal{P}_0 \vs H_1\colon \pth[] \in \mathcal{P}_1
\]
называется \textit{несмещённым}, если
\[
\sup_{\pth[] \in \mathcal{P}_0} \beta(\pth[], R) \le \inf_{\pth[] \in \mathcal{P}_1} \beta(\pth[], R).
\]
Последовательность критериев $R_n$ для выборки $\mathbf X = (X_1, \ldots, X_n)$ называется \textit{состоятельной}, если $\forall \pth[] \in \mathcal{P}_1\colon \beta(\pth[], R_n) \to 1$ при $n \to \infty$ (то есть ошибка II рода постепенно исчезает).
\end{definition}

\begin{example}
Рассмотрим модель сдвига $X_i \sim \mathcal{N}(\theta, 1)$. Предположим, в наших расчётах удобно полагать $\theta = \theta_0$, но нам хотелось бы убедиться, что это допущение состоятельно по сравнению с альтернативой $\theta > \theta_0$. Таким образом, перед нами встала проблема проверки \textit{односторонней} гипотезы
\[
H_0 \colon \theta = \theta_0 \vs H_1\colon \theta > \theta_0.
\]
Логично использовать критерий, основанный на статистике $T(\mathbf X) = \overline{\mathbf X}$, а именно: если мы попадаем в множество $R=\{\mathbf{x}\colon T(\mathbf{x}) \ge c\}$ для некоторого $c$, то среднее слишком велико, и скорее всего предположение $H_0$ неверно, иначе оно вполне допустимо. Подберём число $c$ так, чтобы наш критерий имел уровень значимости $\alpha$, то есть
\[
\alpha = \pth[\theta_0](\overline{\mathbf X} \ge c) = \pth[\theta_0](\underbrace{\sqrt{n}(\overline{\mathbf X} - \theta_0)}_{\sim \mathcal{N}(0, 1)} \ge \sqrt{n}(c - \theta_0)) \Longrightarrow \sqrt{n}(c - \theta_0) = z_{1-\alpha},
\]
где $z_p$ -- $p$-квантиль для $\mathcal{N}(0, 1)$. Таким образом, $c = \theta_0 + z_{1-\alpha}/\sqrt{n}$ доставляет нам критерий с требуемым уровнем значимости. Посмотрим, как выглядит функция мощности для $\theta > \theta_0$:
\[
\beta(\theta) = \pth\left(\overline{\mathbf X} \ge c\right) = \pth\left(\sqrt{n}(\overline{\mathbf X} - \theta) \ge \sqrt{n}(\theta_0 - \theta) + z_{1-\alpha}\right) = 1 - \Phi\left(\sqrt{n}(\theta_0 - \theta) + z
_{1-\alpha}\right) \eqcirc
\]
где $\Phi$ -- функция распределения $\mathcal{N}(0, 1)$. Из её симметричности имеем
\[
\eqcirc \,\Phi\left(\sqrt{n}(\theta - \theta_0) - z_{1-\alpha}\right).
\]
В силу возрастания $\Phi$ функция мощности $\beta(\theta)$ будет также возрастать, поэтому $\forall \theta > \theta_0\colon \beta(\theta) \ge \alpha$, и критерий $R$ будет несмещённым. Также при $n \to \infty$ аргумент функции $\Phi$ стремится к $+\infty$, поэтому $\forall \theta > \theta_0\colon \beta(\theta) \to 1$, а значит, критерий ещё и состоятелен.
\end{example}

\subsection{Критерий Вальда}\label{wald_test}

В данном разделе мы рассмотрим, наверное, один из самых простых способов проверки \textit{двусторонних} гипотез, то есть гипотез вида
\[
H_0\colon \theta = \theta_0 \vs H_1\colon \theta \ne \theta_0.
\]

Другой его особенностью является тот факт, что точного распределения статистики критерия мы знать не будем, мы в курсе лишь её предельного распределения, отчего и уровень значимости будет устанавливаться лишь в пределе.

\begin{definition}
Критерий $R$ для проверки гипотезы $H_0\colon \pth[] = \pth[0]$ называется \textit{асимптотическим критерием уровня значимости $\alpha$}, если
\[
\varlimsup_{n \to \infty} \pth[0](R) \le \alpha.
\]
\end{definition}

Это вызывает некоторые проблемы, так как настоящие размер и мощность критерия могут отличаться от теоретических, особенно при малом размере выборки, однако обычно такие критерии просты, и искать их гораздо проще точных.

Для построения критерия нам понадобится асимптотически нормальная оценка $\widehat{\theta}$, то есть такая оценка, что
\[
\sqrt{n} \cdot \frac{\widehat{\theta} - \theta}{\sigma(\theta)} \stackrel{d}{\longrightarrow} \mathcal{N}(0, 1),
\]
где $\sigma^2(\theta)$ -- асимптотическая дисперсия оценки $\widehat{\theta}$. Если мы имеем дело с какой-то сложной моделью, то получить точную формулу для $\sigma^2(\theta)$ может быть довольно сложно, поэтому вместо неё будем использовать состоятельную оценку $\widehat{\sigma}$ для $\sigma(\theta)$. В силу состоятельности отношение сих величин сходится по вероятности (а значит, и слабо) к 1, и по лемме Слуцкого:
\[
T_{\theta}(\mathbf X) = \sqrt{n} \cdot \frac{\widehat{\theta} - \theta}{\widehat{\sigma}} = 
\sqrt{n} \cdot \frac{\widehat{\theta} - \theta}{\sigma(\theta)} \cdot \frac{\sigma(\theta)}{\widehat{\sigma}} \stackrel{d}{\longrightarrow} \mathcal{N}(0, 1).
\]

Вернёмся к проверке гипотезы. При верности $H_0$ имеем $T_{\theta_0}(\mathbf X) \stackrel{d_{\theta_0}}{\longrightarrow} \mathcal{N}(0, 1)$, а значит, критерий
\[
R = \{\mathbf{x}\colon |T_{\theta_0}(\mathbf{x})| > z_{1 - \alpha/2} \}
\]
будет иметь асимптотический уровень значимости $\alpha$ (здесь $z_p$ -- $p$-квантиль $\mathcal{N}(0, 1)$). Действительно, если за $\Phi$ обозначить функцию распределения для $\mathcal{N}(0, 1)$, то
\begin{gather*}
    \pth[\theta_0](|T_{\theta_0}(\mathbf X)| > z_{1 - \alpha/2}) =\\
    =\pth[\theta_0](T_{\theta_0}(\mathbf X) > z_{1 - \alpha/2}) + \pth[\theta_0](T_{\theta_0}(\mathbf X) < z_{\alpha/2}) \xrightarrow[\textit{из слаб. сх-ти}]{} (1 - \Phi(z_{1 - \alpha/2})) + \Phi(z_{\alpha/2}) = \\
    = 1 - (1 - \alpha/2) + \alpha/2 = \alpha.
\end{gather*}

Теперь изучим критерий на предмет мощности. Предположим, что истинное значение $\theta$ не равно $\theta_0$. Тогда
\[
    \beta(\theta) = \pth(|T_{\theta_0}(\mathbf X)| > z_{1 - \alpha/2}) =
\]
\[
    =\pth\left(\sqrt{n} \cdot \frac{\widehat{\theta} - \theta_0}{\widehat{\sigma}} > z_{1 - \alpha/2}\right) + \pth\left(\sqrt{n} \cdot \frac{\widehat{\theta} - \theta_0}{\widehat{\sigma}} < - z_{1 - \alpha/2}\right) =
\]
\[
    = \pth\left(\sqrt{n} \cdot \frac{\widehat{\theta} - \theta}{\widehat{\sigma}} > z_{1 - \alpha/2} + \sqrt{n} \cdot \frac{\theta_0 - \theta}{\widehat{\sigma}}\right) + \pth\left(\sqrt{n} \cdot \frac{\widehat{\theta} - \theta}{\widehat{\sigma}} < - z_{1 - \alpha/2} + \sqrt{n} \cdot \frac{\theta_0 - \theta}{\widehat{\sigma}}\right) \approx
\]
\[
    \approx 1 - \Phi\left(z_{1 - \alpha/2} + \sqrt{n} \cdot \frac{\theta_0 - \theta}{\widehat{\sigma}}\right) + \Phi\left(- z_{1 - \alpha/2} + \sqrt{n} \cdot \frac{\theta_0 - \theta}{\widehat{\sigma}}\right).
\]

Так как $\theta \ne \theta_0$, то содержимое в скобках стремится к $\pm \infty$, а значит, значения $\Phi$ либо примерно 1, либо примерно 0, отчего мощность близка к единице. Причём из написанного выше видно, что мощность тем больше, чем больше размер выборки и чем дальше от $\theta_0$ находится рассматриваемый параметр из альтернативы.

\begin{example}\label{small_p_value}
По данным Интернет-опроса за одного из кандидатов собирались проголосовать 3\% избирателей. По официальным данным за этого кандидата в итоге проголосовали 4661075 из 5818955 избирателей. Нулевая гипотеза заключается в согласованности этих данных, которую мы хотим проверить на уровне значимости $\alpha = 0.01$ (для надёжности).

Каждому избирателю с номером $i$ можно поставить в соответствие случайную величину $X_i \sim \bernd(p)$, которая равна 1, если избиратель проголосовал за данного кандидата, и 0 иначе. Гипотезу в таком случае можно записать как
\[
H_0\colon p = p_0 = 0.03.
\]
По ЦПТ имеется асимптотически нормальная оценка $\widehat{p} = \overline{\mathbf X}$, асимптотическую дисперсию которой можно выразить точно и без оценивания: это просто дисперсия одного наблюдения, то есть $\sigma^2(p) = \va[p] X_i = p(1 - p)$. Итого, критерий имеет вид
    \[
    R = \left\{\mathbf{x}\colon \sqrt{n} \cdot \frac{\overline{\mathbf{x}} - p_0}{\sqrt{p_0(1-p_0)}} > z_{1-\alpha/2}\right\}
    \]
    Посчитаем статистику критерия для приведённой реализации выборки $\mathbf x_0$:
    \[
    T(\mathbf x_0) = \sqrt{5818955} \cdot \frac{\frac{4661075}{5818955} - 0.03}{\sqrt{0.03 \cdot(1-0.03)}} \approx 10902.83.
    \]

    Критическое значение при данном уровне значимости равняется $z_{1 - 0.01/2} \approx 2.58$, то есть статистика значительно опережает этот порог, посему гипотезу $H_0$ следует отвергнуть. 
\end{example}

Критерий Вальда подходит и для проверки односторонних гипотез, например:
\[
H_0\colon \theta = \theta_0 \vs H_1\colon \theta > \theta_0.
\]
В таких случаях критерий логично переформулировать так:
\[
R_{+} = \{\mathbf{x} \colon T_{\theta_0}(\mathbf{x}) > z_{1-\alpha}\}.
\]
На асимптотический уровень значимости это не повлияет, зато мы увеличим мощность: теперь мы можем забыть про <<левый хвост>> нормального распределения и больше уделить внимания правому, попадание в который более вероятно для $\theta > \theta_0$. Аналогично, если альтернатива имеет вид $H_1\colon \theta < \theta_0$, то в такой ситуации лучше взять критерий
\[
R_{-} =  \{\mathbf{x} \colon T_{\theta_0}(\mathbf{x}) < -z_{1-\alpha}\}.
\]

\begin{example}
Посетители ТРЦ Рио ходили по магазинам в среднем $1$ час, стандартное отклонение равнялось $0.5$. Потом на втором этаже появился детский паровозик, а на следующий день оказалось, что по выборке из 35 посетителей среднее время шоппинга составило $6/5$ часа. Требуется проверить на уровне значимости $0.01$ гипотезу о пользе паровозика.

Выдвинем на проверку
\[
H_0\colon \text{Паровозик не повлиял} \vs H_1\colon \text{Паровозик помог}
\]
Если верна $H_0$, то с появлением паровозика ничего не поменялось, поэтому среднее и отклонение распределения остались прежними, то есть $1$ и $0.5$ соответственно. Попробуем применить односторонний критерий Вальда (было бы странно в альтернативу, утверждающую, что паровозик помог, запихивать случай, когда среднее уменьшилось):
\[
T(\mathbf x_0) = \sqrt{35}\cdot \frac{1.2 - 1}{0.5} \approx 2.366.
\]
В то же время критическое значение равняется $z_{1 - 0.01} \approx 2.326$, что меньше значения статистики, поэтому основная гипотеза отвергается, то есть паровозик статистически значимо увеличил среднюю продолжительность покупок. Заметим, что если бы мы применяли двусторонний критерий, то критическое значение бы равнялось $z_{1 - 0.01/2} \approx 2.58$, и поэтому гипотеза $H_0$ бы не отвергалась.
\end{example}

Следует понимать, что односторонний критерий берётся только в случае достоверного понимания, что <<вторая сторона>> не может реализоваться. На практике такое встречается довольно редко, да и исследователям важно отслеживать изменение в обе стороны. Однако недобросовестные аналитики могут воспользоваться этим трюком, искажая уровень значимости критерия (см. задачу \ref{oneside_test_problem}).

Критерий Вальда также очень удобен для построения \textit{двухвыборочных критериев}, которые более подробно будут изучены в главе \ref{homogeneity}. Обычно они проверяют, нет ли каких-либо общих свойств у распределений двух выборок. Покажем пример работы критерия Вальда в случае проверки равенства средних, что можно использовать для проверки наличия эффекта.

\begin{example}
Пусть $X_1, \ldots , X_n$ --- выборка из распределения $\poisd(\lambda_1)$, $Y_1, \ldots, Y_m$ --- выборка из распределения $\poisd(\lambda_2)$, причём выборки независимы. Проверим гипотезу $H_0\colon \lambda_1 = \lambda_2$. Её можно переформулировать так:
\[
H_0\colon \delta := \lambda_1 - \lambda_2 = 0.
\]
Таким образом, можно протестировать гипотезу о том, что параметр $\delta$ равен нулю. За оценку сего параметра логично взять $\widehat{\delta} = \overline{\mathbf X} - \overline{\mathbf Y}$, то есть разность выборочных средних $X$ и $Y$ (её асимптотическая нормальность следует из теоремы о наследовании асимптотической нормальности). В силу независимости выборок дисперсия данной оценки равна
	\[
    \va[]\widehat{\delta} = \va[]\overline{\mathbf X} + \va[]\overline{\mathbf Y} = \frac{\lambda_1}{n} + \frac{\lambda_2}{m},
    \]

Сами параметры $\lambda_1$ и $\lambda_2$ мы не знаем, поэтому придётся заменить честные значения на их состоятельные оценки:
\[
\widehat{\va[]\widehat{\delta}}(\mathbf X, \mathbf Y) = \frac{\overline{\mathbf X}}{n} + \frac{\overline{\mathbf Y}}{m}.
\]

Возьмём от всего этого дела корень, чтобы получить стандартное отклонение, и запишем итоговую статистику критерия, которая с ростом $n$ и $m$ сходится к $\mathcal{N}(0, 1)$:
\[
W(\mathbf X, \mathbf Y) = \frac{\overline{\mathbf{X}} - \overline{\mathbf{Y}}}{\sqrt{\frac{\overline{\mathbf X}}{n} + \frac{\overline{\mathbf Y}}{m}}}.
\]

Для общей альтернативы $H_1\colon \delta \ne 0$ подойдёт критерий

\[
R_{\alpha} = \left\{(\mathbf{x}, \mathbf{y})\colon \left|W(\mathbf x, \mathbf y)\right| > z_{1-\alpha/2}\right\}.
\]
\end{example}

\subsection{p-value}

Как было видно по примерам выше, превышение критического значения могло быть разным: где-то оно было небольшим, а где-то --- многократным. Однако распределение статистики критерия каждый раз разное, поэтому не всегда очевидно, насколько сильное отклонение от нулевой гипотезы мы получили в очередной раз. В этом контексте крайне удобна следующая характеристика, которая показывает, насколько сильно мы можем быть уверены в отклонении гипотезы.

\begin{definition}
    Пусть для проверки гипотезы $H_0\colon \pth[] \in \mathcal{P}_0$ на уровне значимости $\alpha$ имеется критерий $R_{\alpha}$. Назовём \textit{p-value} или \textit{фактическим уровнем значимости} следующую статистику:
    \[
    \text{p-value}(\mathbf X) = \inf \{\alpha\colon \mathbf X \in R_{\alpha}\}.
    \]
\end{definition}

\begin{wrapfigure}[17]{r}{0.35\textwidth}
    \includegraphics[width=0.35
    \textwidth]{pic/reject_pic/reject_pic.pdf}
    \caption{Критерии для разных уровней значимости}\label{fig:pvalue_pic}
\end{wrapfigure}

Поясним, что тут происходит. Для каждого $\alpha$ у нас в рукаве имеется критерий $R_{\alpha}$ с размером $\alpha$. С уменьшением $\alpha$ мы становимся более консервативными и боимся отвергать гипотезу, поэтому критическое множество уменьшается. На рисунке \ref{fig:pvalue_pic} выделены три критерия с размерами $\alpha_1 > \alpha_2 > \alpha_3$. При $\alpha_3$ критерий достаточно мал, и туда выборка не попадает, а при $\alpha_1$ и $\alpha_2$ критерии довольно жирные, отчего выборка там лежит. Таким образом, мы смотрим, при каких $\alpha$ реализация выборки $X$ попала в критическое множество $R_{\alpha}$, то есть при каких $\alpha$ нам следовало бы отвергнуть гипотезу, а потом берём по ним инфимум (например, на картинке p-value будет равняться $\alpha_2$).

То есть p-value -- это \textit{минимальный уровень значимости, на котором мы должны отвергнуть гипотезу}. Таким образом,
\[
H_0\text{ отвергается} \Longleftrightarrow \mathbf X \in R_{\alpha} \Longleftrightarrow \text{p-value} \le \alpha.
\]

Более наглядно смысл p-value виден в случае, когда критерий задаётся некоторой статистикой: $R_{\alpha} = \{\mathbf x\colon T(\mathbf x) \ge c_{\alpha}\}$, где $\alpha$ -- размер критерия. Предположим, что реализовалась значение выборки $\mathbf x$ и наблюдаемое значение статистики критерия $T(\mathbf x)$ равно $t$. Тогда p-value можно переписать так:
\begin{gather*}
    \text{p-value}(\mathbf x) = \inf \{\alpha\colon t \ge c_{\alpha}\} = \alpha(t),
\end{gather*}
где $c_{\alpha(t)} = t$ (при уменьшении $\alpha$ граница $c_{\alpha}$ лишь увеличивается, поэтому инфимум достигается при $t = c_{\alpha}$). Вспоминая определение размера критерия, получаем, что
\[
\text{p-value}(\mathbf x) = \alpha(t) = \sup_{\pth[] \in \mathcal{P}_0} \pth[](T(\mathbf X) \ge c_{\alpha(t)}) = \sup_{\pth[] \in \mathcal{P}_0} \pth[](T(\mathbf X) \ge t) = \sup_{\pth[] \in \mathcal{P}_0} \pth[](T(\mathbf X) \ge T(\mathbf x)).
\]

Если распределение статистики одно и то же при любом $\pth[] \in \mathcal{P}_0$ (в частности, когда гипотеза простая), то супремум берётся по одному элементу. В таком случае можно переформулировать
\begin{definition}
    p-value -- это вероятность наблюдать статистику критерия такую же или даже более экстремальную, чем она есть на самом деле, при условии верности $H_0$.
\end{definition}

Это можно проиллюстрировать следующими картинками, на которых изображена плотность статистики $T(\mathbf X)$, если $H_0$ верна.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.95\textwidth]{pic/pvalue_pic/pvalue_pic.pdf}
\end{figure}

На левом рисунке значение статистики оказалось достаточно маленьким, и соответствующее p-value (что есть площадь под графиком, выделено зелёным) больше, чем заявленный уровень значимости $\alpha$ (выделен красным). Значит, гипотеза не отвергается. На правом же рисунке статистика $T(\mathbf X)$ приняла весьма экстремальное значение и попала в <<критическую зону>>. Отсюда делаем вывод о необходимости отвергнуть $H_0$.

Заметим, что p-value очень просто считается: достаточно знать функцию распределения статистики критерия:
\[
\text{p-value}(\mathbf x) = \pth[0](T(\mathbf X) \ge T(\mathbf x)) = 1 - F_{T(\mathbf X)}(T(\mathbf x)).
\]

Также следует выделить следующее важное свойство p-value, придающее этой величине универсальный характер.
\begin{theorem}{}{}
    Пусть статистика $T(\mathbf X)$ имеет непрерывное распределение, которое одинаково при всех $\pth[] \in \mathcal{P}_0$. Тогда $\text{p-value}(\mathbf X)$ распределено равномерно на отрезке $[0; 1]$.
\end{theorem}

\begin{proof}
    Так как функция распределения $F$ статистики $T(\mathbf X)$ непрерывна, то по утверждению \ref{f_to_uniform} величина $F(T(\mathbf X))$ распределена равномерно на отрезке $[0; 1]$. Тогда по выведенному выше, если $\mathbf x$ --- наблюдаемое значение выборки, то
    \[
    \text{p-value}(\mathbf x) = \pth[](T(\mathbf X) \ge T(\mathbf x)) = \pth[]\bigl[\underbrace{F(T(\mathbf X))}_{\sim\ud[0; 1]} \ge F(T(\mathbf x))\bigr] = 1 - F(T(\mathbf x)),
    \]
    то есть $\text{p-value}(\mathbf X) = 1 - F(T(\mathbf X)) \sim \ud[0; 1]$.
\end{proof}

Таким образом, p-value можно рассматривать как степень уверенности в отклонении $H_0$. Если оно близко к нулю, то по версии $H_0$ произошло очень маловероятное событие, что и заставляет нас отклонить её. То есть чем меньше p-value, тем более мы спокойны о нашем решении в отвержении $H_0$. С другой стороны, высокое p-value не свидетельствует о верности $H_0$. Вполне возможно, что на самом деле верна альтернатива $H_1$, но критерий оказался недостаточно мощным для обнаружения несоответствия с основной гипотезой. 

\subsection*{Задачи}

\begin{problem}[\textsf{The Permanent Illusion}, \cite{cohen1994earth}]
	Случайно равновероятно возьмём $M$ --- произвольного человека с планеты Земля и поставим на проверку гипотезу $H_0\colon \text{$M$ --- американец}$. Критерий предлагается построить на основе его профессии, а именно возьмём множество $R = \{m \in \text{Земля}\colon \text{$m$ --- конгрессмен}\}$. Очевидно, при верности $H_0$ вероятность $\pth[0](M \in R)$ крайне мала, поэтому данный критерий обладает разумным уровнем значимости, например, $\alpha = 0.01$. Таким образом, если случайный человек оказался конгрессменом, то в соответствии с критерием мы должны отклонить гипотезу $H_0$. Всё ли корректно в данной процедуре? Стоит ли её применять в реальной жизни?
\end{problem}

\begin{problem}
	Партия в преферанс предназначена для трёх игроков, каждому из которых раздаётся случайным образом по 10 карт, а остальные 2 карты скидываются в прикуп (итого, 32 карты --- от семёрок до тузов). Двое игроков заметили, что третьему за 100 партий на руки выпал хотя бы один туз 87 раз. На уровне значимости $0.01$ проверьте гипотезу о том, что он играет честно, против альтернативы, что он подмешивает себе тузов.
\end{problem}

\begin{problem}\label{oneside_test_problem}
    Имеется выборка $X_1, \ldots, X_n \sim \mathcal{N}(\mu, 1)$. Проверяется гипотеза $H_0\colon \mu = 0$ с помощью стандартной статистики Вальда $T(\mathbf X) = \overline{\mathbf X}$. Чтобы повысить мощность критерия, аналитик решил схитрить: сначала он смотрит на знак полученного среднего, и если значение получилось положительным, то он берёт правосторонний критерий $\{T(\mathbf{x}) \ge c_{\alpha}\}$ уровня $\alpha$ против альтернативы $H_1\colon \mu > 0$. В ином случае он проверяет гипотезу левосторонним критерием $\{T(\mathbf{x}) \le c_{\alpha}\}$, который обычно используют при альтернативе $H_2\colon \mu < 0$. Насколько корректна данная процедура? Какая ошибка I рода может достигаться при таком алгоритме проверки?
\end{problem}

\begin{problem}
    Пусть $X_1, \ldots, X_n$ --- выборка из $\bernd(\theta)$, и ставится на проверку гипотеза $H_0\colon \theta = 1/2$. Представим, что данные не имеются сразу на руках, а подаются последовательно. Нетерпеливый аналитик не хочет долго ждать, поэтому он осуществляет проверку следующим образом: после получения очередного элемента $X_k$ он строит критерий Вальда уровня значимости $\alpha$ для выборки $X_1, \ldots, X_k$ и отвергает $H_0$, если для этого критерия имеет место отвержение. Если же после получения всей выборки отвержений так и не было, то $H_0$ принимается. Контролируется ли в данной процедуре ошибка I рода на уровне~$\alpha$? К чему будет стремиться ошибка I рода при $n \to \infty$?
\end{problem}

\begin{problem}
	Пусть $X_1, \ldots , X_n$ --- выборка из распределения $\mathcal{N}(a_1, \sigma^2_1)$, $Y_1, \ldots, Y_m$ --- выборка из распределения $\mathcal{N}(a_2, \sigma^2_2)$, причём выборки независимы. Предложите асимптотический критерий для проверки гипотезы $H_0\colon \sigma^2_1 = \sigma^2_2$.
\end{problem}



