\section{Бутстреп}

Как мы могли убедиться ранее, порой не всегда обычная точечная оценка $T_n(\mathbf X) = T_n(X_1, \ldots, X_n)$ даст нам полноценную информацию о значении неизвестного параметра. Немаловажную роль также играет значение дисперсии нашей статистики $\va[] T_n(\mathbf X)$, так как её высокое значение может свидетельствовать о нашей неуверенности в результате. Однако не всегда эту дисперсию можно легко посчитать аналитически или даже приблизить. 

Во-первых, что очевидно, значение дисперсии может зависеть от значения неизвестного параметра, который мы собственно и хотим оценить. Во-вторых, в большинстве случаев мы вовсе не знаем, как параметризовать семейство: не всегда у нас имеется хоть какая-нибудь априорная информация о неизвестном распределении, которому подчиняется выборка. Иногда нам может повести, и оценка $T_n(\mathbf X)$ окажется асимптотически нормальной с известной асимптотической дисперсией:
\[
\sqrt{n}(T_n(\mathbf X) - \theta) \stackrel{d_{\theta}}{\longrightarrow} \mathcal{N}(0, \sigma^2),
\]
откуда можно сделать вывод, что дисперсию $\va T_n(\mathbf X)$ якобы можно приблизить значением $\sigma^2 / n$. Но сходимость по распределению --- вещь ненадёжная, требующая достаточного числа данных, и даже для относительно больших выборок приближение нормальным распределением может оказаться несостоятельным, а оценки дисперсии --- тем более.

\subsection{Принцип работы}

На помощь приходит новый, по истине волшебный инструмент, предложенный Брэдли Эфроном в \cite{efron1979bootstrap}, и имя ему --- \textit{бутстреп} (\textsf{bootstrap}). Он сочетает в себе две идеи:
\begin{itemize}
    \item Раз уж исходное распределение выборки мы не знаем, давайте заменим его на эмпирическое, то есть будем искать не дисперсию оригинальной статистики
    $$\va[\mathsf{P}] T_n = \va[] T_n(X_1, \ldots, X_n),\;\;\;X_1, \ldots, X_n \sim \mathsf{P} \in \mathcal{P},$$
    а дисперсию статистики от выборки из эмпирического распределения
    $$\va[\widehat{\mathsf{P}}] T_n = \va[] T_n(X_1^*, \ldots, X_n^*),\;\;\;X_1^*, \ldots, X_n^* \sim \widehat {\mathsf{P}},$$
    где, напомним, эмпирическое распределение $\widehat {\mathsf{P}}$ задаётся функцией распределения
    \[
    \widehat{F_n}(x) = \sum_{i=1}^n \frac{I(x \le X_{i})}{n}.
    \]
    \item Оценим дисперсию $\va[\widehat{\mathsf{P}}] T_n$ с помощью \textit{метода Монте-Карло}, который в общем случае выглядит так: если нам надо оценить $\me[] g(\mathbf X)$, где $X \sim F$, то можно смоделировать $B$ случайных величин $X_1, \ldots, X_B \sim F$, чьё среднее будет стремиться к оцениваемому числу по закону больших чисел:
    \[
    \overline{h(\mathbf X)} = \frac{1}{B} \sum_{i=1}^B h(X_i) \stackrel{\mathsf{P}}{\longrightarrow} \me[] h(\mathbf X).
    \]
    Очень похоже на метод моментов за тем лишь исключением, что на этот раз выборка не приходит к нам сверху, а генерируется нами самостоятельно. В частности, дисперсия оценивается выборочным аналогом:
    \[
    \frac{1}{B} \sum_{i=1}^B (X_i - \overline{X})^2 = \frac{1}{B} \sum_{i=1}^B X_i^2 - \left(\frac{1}{B}\sum_{i=1}^B X_i\right)^2 \stackrel{\mathsf{P}}{\longrightarrow} \me[] X_1^2 - (\me[] X_1)^2 = \va[] X_1. 
    \]
\end{itemize}

Эти два простых шага удачно дополняют друг друга, и в общем случае нельзя избавиться от одного из них:
\begin{itemize}
    \item Без первого шага нам пришлось бы семплировать из неизвестного распределения $\mathsf{P}$ вместо $\widehat{\mathsf{P}}$, что чаще всего не представляется возможным.
    \item Без второго шага нам пришлось бы аналитически вычислять $\va[\widehat{\mathsf{P}}] T_n$, которая, вообще говоря, равна монструозной сумме по $n$ индексам, $i$-ый из которых соответствует $i$-ому наблюдению $X_i^*$, который может равновероятно принимать значения из $(X_1, \ldots, X_n)$:
    \begin{gather*}
        \va[\widehat{\mathsf{P}}] T_n(X_1^*, \ldots, X_n^*) = \\
        = \int T_n^2(x_1, \ldots, x_n)\,d\widehat F_n(x_1)\ldots d\widehat F_n(x_n) - \left(\int T_n(x_1, \ldots, x_n)\,d\widehat F_n(x_1)\ldots d\widehat F_n(x_n)\right)^2 = \\
        = \frac{1}{n^n} \sum_{i_1=1}^n \ldots \sum_{i_n=1}^n T^2(X_{i_1}, \ldots, X_{i_n}) - \left(\frac{1}{n^n} \sum_{i_1=1}^n \ldots \sum_{i_n=1}^n T(X_{i_1}, \ldots, X_{i_n})\right)^2,
    \end{gather*}
    что само по себе вызывает отвращение, не говоря уже о необходимости считать порядка $n^n$ слагаемых.
\end{itemize}

Бутстреп избавляет нас от этих проблем: Монте-Карло позволяет не вычислять какие-либо интегралы, приближая их многократным семплированием, а замена $\mathsf{P}$ на $\widehat{\mathsf{P}}$ даёт возможность это семплирование осуществить. Действительно, как нам вообще смоделировать случайную величину $X$ с распределением $\widehat{F_n}$? Так как сие распределение дискретно и придаёт каждому элементу выборки $X_1, \ldots, X_n$ вероятностную массу $1/n$, то достаточно просто равновероятно выбрать какой-нибудь элемент выборки, то есть если случайный индекс $j$ берётся равномерно из множества $\{1, \ldots, n\}$, то величина $X_j$ будет иметь искомое распределение. 

Итого, алгоритм нахождения оценки дисперсии $v_{\text{boot}}(T_n)$ таков:
\begin{itemize}
    \item Для каждого $i = 1,\ldots, B$, где $B$ достаточно велико:
    \begin{itemize}
        \item Выбираем случайные индексы $j_1, \ldots, j_n$ равновероятно и независимо из множества $\{1, \ldots, n\}$;
        \item Получаем выборку $X^{*(i)} = (X_1^{*(i)}, \ldots, X_n^{*(i)})$, где $X_k^{*(i)} = X_{j_k} \sim \widehat{\mathsf{P}}$.
    \end{itemize}
    \item По сгенерированным выборкам считаем статистики $T_{n, i}^* = T_{n}\bigl(X^{*(i)}\bigr)$;
    \item В качестве оценки дисперсии берём
    \[
        v_{\text{boot}}(T_n) = \frac{1}{B} \sum_{i=1}^B \left(T_{n, i}^* - \overline{T_n^*}\right)^2.
    \]
\end{itemize}

Данная процедура на самом деле предлагает нам нечто большее: на втором шаге мы получаем целую выборку $\mathbf T_n^* = (T_{n,1}^*, \ldots, T_{n,B}^*)$ из распределения, которое в силу предложения о близости $F$ и $\widehat F_n$ само близко к истинному распределению $T_n(\mathbf X)$. Отсюда мы можем получить оценки для куда более широкого класса характеристик, например, квантилей, коэффициентов асимметрии/эксцесса и т.д.

Впрочем не всегда бутстреповское распределение так уж хорошо приближает настоящее. Стоит помнить, что эмпирическое распределение $\widehat F$ сильно отличается от истинного $F$ своей дискретностью и конечностью носителя, поэтому некоторые оценки могут вести себя слишком предсказуемо при сэмплировании из $\widehat F$ и не давать никакой информации о её настоящем распределении.

\begin{example}
	Пусть $X_1, \ldots, X_n \sim F$ --- данная нам свыше выборка, для которой нам хотелось бы оценить бутстрепом распределение максимума $X_{(n)}$. В отличие от, например, среднего, которое в каком-то смысле <<смешивает>> свои компоненты между собой, максимум выборки из дискретного распределения $\widehat F_n$ всегда равен какой-то точке из его носителя. Более того, распределение бутстреповского максимума, грубо говоря, не зависит от самой выборки: легко показать, что для фиксированного $i$ выполнено $\pth[](X_{(n)}^{*} = X_{(n-i)}) \to e^{-i} - e^{-i-1}$.
\end{example}

\subsection{Бутстрепные доверительные интервалы}

Знание распределения оценки (в том числе асимптотического) помогало нам ранее строить доверительные интервалы для оцениваемых параметров. Сейчас, когда у нас появился мощный инструмент, дающий большее понимание в поведении оценок, мы можем ввести новые способы в построении доверительных интервалов, основанных на бутстреповской выборке оценок. Мы не будем углубляться в их состоятельность и корректность, больше деталей про них можно прочитать в \cite[tibshirani1993introduction].

% TODO Бутстреп


\begin{problem}
	Для выборки $(X_1, \ldots, X_n)$, значения в которой будем предполагать различными, существует всего $n^n$ возможных реализаций бутстреповской выборки. Однако почти все разумные статистики не используют порядок в выборке. Сколько же тогда реализаций будет, если порядок не учитывать?
\end{problem}

\begin{problem}
	Для некоторых статистик бутстреповскую дисперсию можно посчитать аналитически, не используя метод Монте-Карло (такие оценки ещё называют \textit{идеальными бутстреповскими}). Посчитайте идеальную бутстреповскую оценку дисперсии выборочного среднего $\overline{g(\mathbf X)}$.
\end{problem}


